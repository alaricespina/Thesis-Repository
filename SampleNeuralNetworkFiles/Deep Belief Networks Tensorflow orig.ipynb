{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Belief Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries & Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf \n",
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import tensorflow as tf #Deep learning Library\n",
    "import numpy as np #Matrix Algebra Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom tensorflow.examples.tutorials.mnist import input_data\\n\\n#Loading in the mnist data\\nmnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=False)\\ntrX, trY, teX, teY = mnist.train.images, mnist.train.labels, mnist.test.images,    mnist.test.labels\\n'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Getting the MNIST data provided by Tensorflow\n",
    "'''\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "#Loading in the mnist data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=False)\n",
    "trX, trY, teX, teY = mnist.train.images, mnist.train.labels, mnist.test.images,\\\n",
    "    mnist.test.labels\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000,) (10000, 28, 28) (10000,)\n",
      "(60000, 784) (60000,) (10000, 784) (10000,)\n"
     ]
    }
   ],
   "source": [
    "#Getting the MNIST data provided by Tensorflow\n",
    "from tensorflow import keras \n",
    "mnist = keras.datasets.mnist\n",
    "\n",
    "#Loading in the mnist data\n",
    "(trX, trY) , (teX, teY) = mnist.load_data()\n",
    "print(trX.shape, trY.shape, teX.shape, teY.shape)\n",
    "trX = trX.reshape(trX.shape[0], trX.shape[1] * trX.shape[2])\n",
    "teX = teX.reshape(teX.shape[0], teX.shape[1] * teX.shape[2])\n",
    "print(trX.shape, trY.shape, teX.shape, teY.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restricted Boltzmann Machines\n",
    "\n",
    "RBMs are the building blocks of deep belief nets. If you are not familiar with RBMs please check out my post describing how the RBM functions https://github.com/JosephGatto/Simplified-Restricted-Boltzmann-Machines "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RBM(object):\n",
    "    def __init__(self, input_size, output_size, learning_rate, batch_size):\n",
    "        self.input_size = input_size #Size of the input layer\n",
    "        self.output_size = output_size #Size of the hidden layer\n",
    "        self.epochs = 5 #How many times we will update the weights \n",
    "        self.learning_rate = learning_rate #How big of a weight update we will perform \n",
    "        self.batch_size = batch_size #How many images will we \"feature engineer\" at at time \n",
    "        self.new_input_layer = None #Initalize new input layer variable for k-step contrastive divergence \n",
    "        self.new_hidden_layer = None\n",
    "        self.new_test_hidden_layer = None\n",
    "        \n",
    "        #Here we initialize the weights and biases of our RBM\n",
    "        #If you are wondering, the 0 is the mean of the distribution we are getting our random weights from. \n",
    "        #The .01 is the standard deviation.\n",
    "        self.w = np.random.normal(0,.01,[input_size,output_size]) #weights\n",
    "        self.hb = np.random.normal(0,.01,[output_size]) #hidden layer bias\n",
    "        self.vb = np.random.normal(0,.01,[input_size]) #input layer bias (sometimes called visible layer)\n",
    "        \n",
    "        \n",
    "        #Calculates the sigmoid probabilities of input * weights + bias\n",
    "        #Here we multiply the input layer by the weights and add the bias\n",
    "        #This is the phase that creates the hidden layer\n",
    "    def prob_h_given_v(self, visible, w, hb):\n",
    "        return tf.nn.sigmoid(tf.matmul(visible, w) + hb)\n",
    "        \n",
    "        #Calculates the sigmoid probabilities of input * weights + bias\n",
    "        #Here we multiply the hidden layer by the weights and add the input layer bias\n",
    "        #This is the reconstruction phase that recreates the original image from the hidden layer\n",
    "    def prob_v_given_h(self, hidden, w, vb):\n",
    "        return tf.nn.sigmoid(tf.matmul(hidden, tf.transpose(w)) + vb)\n",
    "    \n",
    "    #Returns new layer binary values\n",
    "    #This function returns a 0 or 1 based on the sign of the probabilities passed to it\n",
    "    #Our RBM will be utilizing binary features to represent the images\n",
    "    #This function just converts the features we have learned into a binary representation \n",
    "    def sample_prob(self, probs):\n",
    "        return tf.nn.relu(tf.sign(probs - tf.random_uniform(tf.shape(probs))))\n",
    "    \n",
    "    def train(self, X, teX):\n",
    "        #Initalize placeholder values for graph\n",
    "        #If this looks strange to you, then you have not used Tensorflow before\n",
    "        _w = tf.placeholder(tf.float32, shape = [self.input_size, self.output_size])\n",
    "        _vb = tf.placeholder(tf.float32, shape = [self.input_size])\n",
    "        _hb = tf.placeholder(tf.float32, shape = [self.output_size])\n",
    "        print(f\"Shapes: _w = {_w.shape} _vb = {_vb.shape} _hb = {_hb.shape}\")\n",
    "        \n",
    "        \n",
    "        #initalize previous variables\n",
    "        #we will be saving the weights of the previous and current iterations\n",
    "        pre_w = np.random.normal(0,.01, size = [self.input_size,self.output_size])\n",
    "        pre_vb = np.random.normal(0, .01, size = [self.input_size])\n",
    "        pre_hb = np.random.normal(0, .01, size = [self.output_size])\n",
    "        \n",
    "        #initalize current variables\n",
    "        #we will be saving the weights of the previous and current iterations\n",
    "        cur_w = np.random.normal(0, .01, size = [self.input_size,self.output_size])\n",
    "        cur_vb = np.random.normal(0, .01, size = [self.input_size])\n",
    "        cur_hb = np.random.normal(0, .01, size = [self.output_size])\n",
    "               \n",
    "        #Plaecholder variable for input layer\n",
    "        v0 = tf.placeholder(tf.float32, shape = [None, self.input_size])\n",
    "         \n",
    "        #pass probabilities of input * w + b into sample prob to get binary values of hidden layer\n",
    "        h0 = self.sample_prob(self.prob_h_given_v(v0, _w, _hb ))\n",
    "        \n",
    "        #pass probabilities of new hidden unit * w + b into sample prob to get new reconstruction\n",
    "        v1 = self.sample_prob(self.prob_v_given_h(h0, _w, _vb))\n",
    "        \n",
    "        #Just get the probailities of the next hidden layer. We wont need the binary values. \n",
    "        #The probabilities here help calculate the gradients during back prop \n",
    "        h1 = self.prob_h_given_v(v1, _w, _hb)\n",
    "        \n",
    "        \n",
    "        #Contrastive Divergence\n",
    "        positive_grad = tf.matmul(tf.transpose(v0), h0) #input' * hidden0\n",
    "        negative_grad = tf.matmul(tf.transpose(v1), h1) #reconstruction' * hidden1\n",
    "        #(pos_grad - neg_grad) / total number of input samples \n",
    "        CD = (positive_grad - negative_grad) / tf.to_float(tf.shape(v0)[0]) \n",
    "        \n",
    "        #This is just the definition of contrastive divergence \n",
    "        update_w = _w + self.learning_rate * CD\n",
    "        update_vb = _vb + tf.reduce_mean(v0 - v1, 0)\n",
    "        update_hb = _hb + tf.reduce_mean(h0 - h1, 0)\n",
    "        \n",
    "        #MSE - This is our error function\n",
    "        err = tf.reduce_mean(tf.square(v0 - v1))\n",
    "        \n",
    "        #Will hold new visible layer.\n",
    "        errors = []\n",
    "        hidden_units = []\n",
    "        reconstruction = []\n",
    "        \n",
    "        test_hidden_units = []\n",
    "        test_reconstruction=[]\n",
    "        \n",
    "        \n",
    "        #The next four lines of code intitalize our Tensorflow graph and create mini batches\n",
    "        #The mini batch code is from cognitive class. I love the way they did this. Just giving credit! \n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            for epoch in range(self.epochs):\n",
    "                for start, end in zip(range(0, len(X), self.batch_size), range(self.batch_size, len(X), self.batch_size)):\n",
    "                    batch = X[start:end] #Mini batch of images taken from training data\n",
    "                    \n",
    "                    #Feed in batch, previous weights/bias, update weights and store them in current weights\n",
    "                    cur_w = sess.run(update_w, feed_dict = {v0:batch, _w:pre_w , _vb:pre_vb, _hb:pre_hb})\n",
    "                    cur_hb = sess.run(update_hb, feed_dict = {v0:batch, _w:pre_w , _vb:pre_vb, _hb:pre_hb})\n",
    "                    cur_vb = sess.run(update_vb, feed_dict = {v0:batch, _w:pre_w , _vb:pre_vb, _hb:pre_hb})\n",
    "                    \n",
    "                    #Save weights \n",
    "                    pre_w = cur_w\n",
    "                    pre_hb = cur_hb\n",
    "                    pre_vb = cur_vb\n",
    "                \n",
    "                #At the end of each iteration, the reconstructed images are stored and the error is outputted \n",
    "                reconstruction.append(sess.run(v1, feed_dict={v0: X, _w: cur_w, _vb: cur_vb, _hb: cur_hb}))        \n",
    "                print('Learning Rate: {}:  Batch Size: {}:  Hidden Layers: {}: Epoch: {}: Error: {}:'.format(self.learning_rate, self.batch_size, \n",
    "                                                                                                             self.output_size, (epoch+1),\n",
    "                                                                                                            sess.run(err, feed_dict={v0: X, _w: cur_w, _vb: cur_vb, _hb: cur_hb})))\n",
    "            \n",
    "            #Store final reconstruction in RBM object\n",
    "            self.new_input_layer = reconstruction[-1]\n",
    "            \n",
    "            #Store weights in RBM object\n",
    "            self.w = pre_w\n",
    "            self.hb = pre_hb\n",
    "            self.vb = pre_vb\n",
    "    \n",
    "    #This is used for Contrastive Divergence.\n",
    "    #This function makes the reconstruction your new input layer. \n",
    "    def rbm_output(self, X):\n",
    "        input_x = tf.constant(X)\n",
    "        _w = tf.constant(self.w)\n",
    "        _hb = tf.constant(self.hb)\n",
    "        _vb = tf.constant(self.vb)\n",
    "        \n",
    "        out = tf.nn.sigmoid(tf.matmul(input_x, _w) + _hb)\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            return sess.run(out)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Belief Networks\n",
    "\n",
    "Deep belief nets are, in my opinion, pretty easy to understand if you have a solid grasp of RBMs. Remember, the RBM's goal is to reconstruct the original image with its hidden layer representation. The deep belief network is just a chain of RBMs. Once the first RBM has completed the image reconstruction process, a new RBM is created. The input layer of the new RBM is now the hidden layer representation of the previous RBM. We now, repeat this process as many times as we like to produce a DBN. DBNs can often give you higher level feature abstractions and produce very high quality features.\n",
    "\n",
    "Below is an example of how to use multiple RBMs to create a DBN. Here we will make 3 RBMs of hidden layer size [600 > 500 > 100]. Feel free to extract the new_hidden_layer from any of the RBMs to see how they perform as features in a lienar classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RBM_hidden_size = [600,500,100] #Three hidden layer sizes for our three layer DBN\n",
    "learning_rate = .01 \n",
    "input_size = trX.shape[1] #input layer size of original image data\n",
    "\n",
    "rbm_list = [] #This will hold all of the RBMs used in our DBN\n",
    "\n",
    "#Creates 3 RBMs\n",
    "for layer in RBM_hidden_size:\n",
    "    rbm_list.append(RBM(input_size, layer, learning_rate, 32))\n",
    "    input_size = layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Shape:  (60000, 784)\n",
      "Layer:  1\n",
      "Shapes: _w = (784, 600) _vb = (784,) _hb = (600,)\n",
      "Learning Rate: 0.01:  Batch Size: 32:  Hidden Layers: 600: Epoch: 1: Error: 7217.080078125:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Alaric\\Documents\\Code\\Thesis-Repository\\SampleNeuralNetworkFiles\\Deep Belief Networks Tensorflow orig.ipynb Cell 11\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Alaric/Documents/Code/Thesis-Repository/SampleNeuralNetworkFiles/Deep%20Belief%20Networks%20Tensorflow%20orig.ipynb#X11sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mInput Shape: \u001b[39m\u001b[39m'\u001b[39m, inpX\u001b[39m.\u001b[39mshape)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Alaric/Documents/Code/Thesis-Repository/SampleNeuralNetworkFiles/Deep%20Belief%20Networks%20Tensorflow%20orig.ipynb#X11sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mLayer: \u001b[39m\u001b[39m'\u001b[39m,(i\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m))\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Alaric/Documents/Code/Thesis-Repository/SampleNeuralNetworkFiles/Deep%20Belief%20Networks%20Tensorflow%20orig.ipynb#X11sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m rbm\u001b[39m.\u001b[39;49mtrain(inpX, teX)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Alaric/Documents/Code/Thesis-Repository/SampleNeuralNetworkFiles/Deep%20Belief%20Networks%20Tensorflow%20orig.ipynb#X11sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m inpX \u001b[39m=\u001b[39m rbm\u001b[39m.\u001b[39mrbm_output(inpX)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Alaric/Documents/Code/Thesis-Repository/SampleNeuralNetworkFiles/Deep%20Belief%20Networks%20Tensorflow%20orig.ipynb#X11sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m test_inpx \u001b[39m=\u001b[39m rbm\u001b[39m.\u001b[39mrbm_output(test_inpx)\n",
      "\u001b[1;32mc:\\Users\\Alaric\\Documents\\Code\\Thesis-Repository\\SampleNeuralNetworkFiles\\Deep Belief Networks Tensorflow orig.ipynb Cell 11\u001b[0m line \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Alaric/Documents/Code/Thesis-Repository/SampleNeuralNetworkFiles/Deep%20Belief%20Networks%20Tensorflow%20orig.ipynb#X11sZmlsZQ%3D%3D?line=102'>103</a>\u001b[0m batch \u001b[39m=\u001b[39m X[start:end] \u001b[39m#Mini batch of images taken from training data\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Alaric/Documents/Code/Thesis-Repository/SampleNeuralNetworkFiles/Deep%20Belief%20Networks%20Tensorflow%20orig.ipynb#X11sZmlsZQ%3D%3D?line=104'>105</a>\u001b[0m \u001b[39m#Feed in batch, previous weights/bias, update weights and store them in current weights\u001b[39;00m\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/Alaric/Documents/Code/Thesis-Repository/SampleNeuralNetworkFiles/Deep%20Belief%20Networks%20Tensorflow%20orig.ipynb#X11sZmlsZQ%3D%3D?line=105'>106</a>\u001b[0m cur_w \u001b[39m=\u001b[39m sess\u001b[39m.\u001b[39;49mrun(update_w, feed_dict \u001b[39m=\u001b[39;49m {v0:batch, _w:pre_w , _vb:pre_vb, _hb:pre_hb})\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Alaric/Documents/Code/Thesis-Repository/SampleNeuralNetworkFiles/Deep%20Belief%20Networks%20Tensorflow%20orig.ipynb#X11sZmlsZQ%3D%3D?line=106'>107</a>\u001b[0m cur_hb \u001b[39m=\u001b[39m sess\u001b[39m.\u001b[39mrun(update_hb, feed_dict \u001b[39m=\u001b[39m {v0:batch, _w:pre_w , _vb:pre_vb, _hb:pre_hb})\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Alaric/Documents/Code/Thesis-Repository/SampleNeuralNetworkFiles/Deep%20Belief%20Networks%20Tensorflow%20orig.ipynb#X11sZmlsZQ%3D%3D?line=107'>108</a>\u001b[0m cur_vb \u001b[39m=\u001b[39m sess\u001b[39m.\u001b[39mrun(update_vb, feed_dict \u001b[39m=\u001b[39m {v0:batch, _w:pre_w , _vb:pre_vb, _hb:pre_hb})\n",
      "File \u001b[1;32mc:\\Users\\Alaric\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\client\\session.py:968\u001b[0m, in \u001b[0;36mBaseSession.run\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    965\u001b[0m run_metadata_ptr \u001b[39m=\u001b[39m tf_session\u001b[39m.\u001b[39mTF_NewBuffer() \u001b[39mif\u001b[39;00m run_metadata \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    967\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 968\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run(\u001b[39mNone\u001b[39;49;00m, fetches, feed_dict, options_ptr,\n\u001b[0;32m    969\u001b[0m                      run_metadata_ptr)\n\u001b[0;32m    970\u001b[0m   \u001b[39mif\u001b[39;00m run_metadata:\n\u001b[0;32m    971\u001b[0m     proto_data \u001b[39m=\u001b[39m tf_session\u001b[39m.\u001b[39mTF_GetBuffer(run_metadata_ptr)\n",
      "File \u001b[1;32mc:\\Users\\Alaric\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\client\\session.py:1191\u001b[0m, in \u001b[0;36mBaseSession._run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1188\u001b[0m \u001b[39m# We only want to really perform the run if fetches or targets are provided,\u001b[39;00m\n\u001b[0;32m   1189\u001b[0m \u001b[39m# or if the call is a partial run that specifies feeds.\u001b[39;00m\n\u001b[0;32m   1190\u001b[0m \u001b[39mif\u001b[39;00m final_fetches \u001b[39mor\u001b[39;00m final_targets \u001b[39mor\u001b[39;00m (handle \u001b[39mand\u001b[39;00m feed_dict_tensor):\n\u001b[1;32m-> 1191\u001b[0m   results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_run(handle, final_targets, final_fetches,\n\u001b[0;32m   1192\u001b[0m                          feed_dict_tensor, options, run_metadata)\n\u001b[0;32m   1193\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1194\u001b[0m   results \u001b[39m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\Alaric\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\client\\session.py:1371\u001b[0m, in \u001b[0;36mBaseSession._do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1368\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_tf_sessionprun(handle, feed_dict, fetch_list)\n\u001b[0;32m   1370\u001b[0m \u001b[39mif\u001b[39;00m handle \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1371\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m   1372\u001b[0m                        run_metadata)\n\u001b[0;32m   1373\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1374\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_do_call(_prun_fn, handle, feeds, fetches)\n",
      "File \u001b[1;32mc:\\Users\\Alaric\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\client\\session.py:1378\u001b[0m, in \u001b[0;36mBaseSession._do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1376\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_do_call\u001b[39m(\u001b[39mself\u001b[39m, fn, \u001b[39m*\u001b[39margs):\n\u001b[0;32m   1377\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1378\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs)\n\u001b[0;32m   1379\u001b[0m   \u001b[39mexcept\u001b[39;00m errors\u001b[39m.\u001b[39mOpError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m   1380\u001b[0m     message \u001b[39m=\u001b[39m compat\u001b[39m.\u001b[39mas_text(e\u001b[39m.\u001b[39mmessage)\n",
      "File \u001b[1;32mc:\\Users\\Alaric\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\client\\session.py:1361\u001b[0m, in \u001b[0;36mBaseSession._do_run.<locals>._run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1358\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_fn\u001b[39m(feed_dict, fetch_list, target_list, options, run_metadata):\n\u001b[0;32m   1359\u001b[0m   \u001b[39m# Ensure any changes to the graph are reflected in the runtime.\u001b[39;00m\n\u001b[0;32m   1360\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_extend_graph()\n\u001b[1;32m-> 1361\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m   1362\u001b[0m                                   target_list, run_metadata)\n",
      "File \u001b[1;32mc:\\Users\\Alaric\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\client\\session.py:1454\u001b[0m, in \u001b[0;36mBaseSession._call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1452\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call_tf_sessionrun\u001b[39m(\u001b[39mself\u001b[39m, options, feed_dict, fetch_list, target_list,\n\u001b[0;32m   1453\u001b[0m                         run_metadata):\n\u001b[1;32m-> 1454\u001b[0m   \u001b[39mreturn\u001b[39;00m tf_session\u001b[39m.\u001b[39;49mTF_SessionRun_wrapper(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_session, options, feed_dict,\n\u001b[0;32m   1455\u001b[0m                                           fetch_list, target_list,\n\u001b[0;32m   1456\u001b[0m                                           run_metadata)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Initalize input layer variables \n",
    "inpX = trX                \n",
    "test_inpx = teX\n",
    "\n",
    "#This loop is the DBN. Each rbm is trained here.\n",
    "#At the end of training, the hidden layer of the RBM is used as input\n",
    "#For the next layer of the DBN. \n",
    "for i,rbm in enumerate(rbm_list):\n",
    "    rbm_outputs = []\n",
    "    rbm_test_outputs = []\n",
    "    print('Input Shape: ', inpX.shape)\n",
    "    print('Layer: ',(i+1))\n",
    "\n",
    "    rbm.train(inpX, teX)\n",
    "    inpX = rbm.rbm_output(inpX)\n",
    "    test_inpx = rbm.rbm_output(test_inpx)\n",
    "    rbm_outputs.append(inpX)\n",
    "    rbm_test_outputs.append(test_inpx)\n",
    "\n",
    "    print('Output Shape: ', inpX.shape)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow import keras \n",
    "from tensorflow.keras import layers \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError, MeanAbsoluteError\n",
    "from tensorflow.keras.losses import MeanSquaredError, MeanAbsoluteError\n",
    "from tensorflow.keras.optimizers import Adam \n",
    "\n",
    "from keras.models import load_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generic Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelParameters:\n",
    "    def __init__(self):\n",
    "        self.Special_Layer_Type = layers.SimpleRNN\n",
    "        self.Special_Layer_Num = 1\n",
    "        self.Special_Layer_Units = 4\n",
    "        self.Special_Layer_Activation = \"tanh\"\n",
    "        self.Dense_Layer_Num = 1\n",
    "        self.Dense_Layer_Units = 4\n",
    "        self.Dense_Layer_Activation = None \n",
    "        self.Output_Layer_Units = 1 \n",
    "        self.Output_Layer_Activation = \"linear\"\n",
    "        self.Epochs = 10\n",
    "        self.Window_Length = 5\n",
    "        self.Input_Scaler = StandardScaler()\n",
    "        self.Output_Scaler = StandardScaler()\n",
    "        self.Training_Size = .70\n",
    "        self.Validation_Size = .20\n",
    "        self.ModelName = \"HatdogModel\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generic Network Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetworkWorkflow:\n",
    "    def __init__(self, ParameterClass, DataFileName, DataColumnName):\n",
    "        self.pc : ModelParameters = ParameterClass\n",
    "        self.raw_df = pd.read_csv(DataFileName)\n",
    "        self.target_column = DataColumnName\n",
    "\n",
    "    def preprocess_data(self):\n",
    "        # Copy Loaded DF \n",
    "        self.df = self.raw_df.copy()\n",
    "\n",
    "        # Hold Values into a temporary numpy array\n",
    "        t_arr = self.df[self.target_column].to_numpy()\n",
    "        X, y = [], []\n",
    "        \n",
    "        # Iterate through elements of the numpy array until end - window_length\n",
    "        for i in range(len(t_arr) - self.pc.Window_Length):\n",
    "            t_row = []\n",
    "            for j in t_arr[i : i + self.pc.Window_Length]:\n",
    "                t_row.append([j])\n",
    "            X.append(t_row)\n",
    "            y.append(t_arr[i + self.pc.Window_Length])\n",
    "\n",
    "        # Set curreny X and Y as Numpy Arrays (For Scaling)\n",
    "        X, y  = np.array(X), np.array(y)\n",
    "\n",
    "        # Create Scalers\n",
    "        in_scaler, out_scaler = self.pc.Input_Scaler, self.pc.Output_Scaler\n",
    "\n",
    "        # Create Copies\n",
    "        X_copy, y_copy = X.copy(), y.copy()\n",
    "\n",
    "        # Reshape X to Fit and Transform to Input Scaler\n",
    "        X = X.reshape(X.shape[0], X.shape[1])\n",
    "        X = in_scaler.fit_transform(X)\n",
    "        X = X.reshape(X_copy.shape[0], X_copy.shape[1], X_copy.shape[2])\n",
    "        print(X.shape)\n",
    "\n",
    "        # Reshape Y to Fit and Transform to Output Scaler\n",
    "        y = y.reshape(-1, 1)\n",
    "        y = out_scaler.fit_transform(y)\n",
    "        y = y.flatten()\n",
    "\n",
    "        # Split into Training, Testing and Validation Parts\n",
    "        train_part = int(self.pc.Training_Size * len(y))\n",
    "        valid_part = int(self.pc.Validation_Size * len(y))\n",
    "\n",
    "        # Assignments\n",
    "        self.X_train, self.y_train = X[:train_part], y[:train_part]\n",
    "        self.X_val, self.y_val = X[train_part:valid_part], y[train_part:valid_part]\n",
    "        self.X_test, self.y_test = X[valid_part:], y[valid_part:]\n",
    "        print(np.array(X))\n",
    "\n",
    "        # Preserve for Testing\n",
    "        self.y_test_copy = self.y_test.copy()\n",
    "\n",
    "    def build_model(self):\n",
    "        self.X_train = np.array(self.X_train)\n",
    "        print(self.X_train.shape)\n",
    "        model = Sequential()\n",
    "        \n",
    "        # Input Layer\n",
    "        model.add(layers.InputLayer(self.pc.Window_Length, 1, ))\n",
    "\n",
    "        # Special Layers\n",
    "        if self.pc.Special_Layer_Num > 1:\n",
    "            for _ in range(self.pc.Special_Layer_Num):\n",
    "                model.add(self.pc.Special_Layer_Type(self.pc.Special_Layer_Units, return_sequences=True, activation=self.pc.Special_Layer_Activation))\n",
    "        \n",
    "        # Final Special Layer\n",
    "        model.add(self.pc.Special_Layer_Type(self.pc.Special_Layer_Units, activation=self.pc.Special_Layer_Activation))\n",
    "\n",
    "        # Dense Layers\n",
    "        for _ in range(self.pc.Dense_Layer_Num):\n",
    "            model.add(layers.Dense(self.pc.Dense_Layer_Units, activation=self.pc.Dense_Layer_Activation))\n",
    "\n",
    "        # Output Layer\n",
    "        model.add(layers.Dense(self.pc.Output_Layer_Units, activation=self.pc.Output_Layer_Activation))\n",
    "        \n",
    "        # Filepath for Checkpoint\n",
    "        filepath = self.pc.ModelName + \"/\"\n",
    "        cp = ModelCheckpoint(filepath, save_best_only=True)\n",
    "\n",
    "        # Compile Model\n",
    "        model.compile(\n",
    "            loss = MeanSquaredError(),\n",
    "            optimizer = Adam(learning_rate=0.0001),\n",
    "            metrics = [RootMeanSquaredError()]\n",
    "        )\n",
    "\n",
    "        # Fit Model (Saves History)\n",
    "        history = model.fit(\n",
    "            self.X_train,\n",
    "            self.y_train,\n",
    "            validation_data=(self.X_val, self.y_val),\n",
    "            epochs = self.pc.Epochs,\n",
    "            callbacks = [cp],\n",
    "            verbose = 1\n",
    "        )\n",
    "        \n",
    "        # Load Model\n",
    "        model = load_model(\"LSTMTestModel/\")\n",
    "\n",
    "        self.trained_model = model \n",
    "\n",
    "    def show_historical_plots(self):\n",
    "        pass \n",
    "\n",
    "    def show_evaluation_results(self):\n",
    "        # Non Transformed\n",
    "        y_test = self.y_test_copy.copy()\n",
    "        input_arr = self.X_test.reshape(self.X_test.shape[0], self.X_test.shape[1])\n",
    "        test_predictions = model.predict(input_arr).flatten()\n",
    "        u = 1\n",
    "        l = 100\n",
    "        plt.figure(figsize=(15, 5))\n",
    "        plt.subplot(121)\n",
    "        plt.plot(test_predictions[u:l], label=\"Predictions\", color=\"green\")\n",
    "        plt.legend()\n",
    "        plt.subplot(122)\n",
    "        plt.plot(y_test[u:l], label=\"Actual Test\", color=\"orange\")\n",
    "        plt.legend()\n",
    "\n",
    "        # Inverse Transformed\n",
    "        y_test = self.y_test_copy.copy()\n",
    "        test_predictions = model.predict(input_arr).flatten()\n",
    "        y_test = y_test.reshape(-1, 1)\n",
    "        y_test = out_scaler.inverse_transform(y_test)\n",
    "        test_predictions = test_predictions.reshape(-1, 1)\n",
    "        test_predictions = out_scaler.inverse_transform(test_predictions)\n",
    "        plt.figure(figsize=(15, 5))\n",
    "        plt.subplot(123)\n",
    "        plt.plot(test_predictions[u:l], label=\"[O] Predictions\", color=\"blue\")\n",
    "        plt.legend()\n",
    "        plt.subplot(124)\n",
    "        plt.plot(y_test[u:l], label=\"[O] Actual Test\", color=\"red\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    def default_run(self):\n",
    "        self.preprocess_data()\n",
    "        self.build_model()\n",
    "        self.show_evaluation_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precipitation Predictor\n",
    "Applies Standard Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrecipitationPredictorParameters(ModelParameters):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.Special_Layer_Num = 3\n",
    "        self.Special_Layer_Units = 64\n",
    "        self.Dense_Layer_Num = 3\n",
    "        self.Dense_Layer_Units = 64\n",
    "        self.Output_Layer_Activation = None\n",
    "        self.Epochs = 10\n",
    "        self.Window_Length = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "PPP = PrecipitationPredictorParameters()\n",
    "New_Flow = NeuralNetworkWorkflow(PPP, \"qc aggregated data.csv\", \"precip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1303, 5, 1)\n",
      "[[[-0.40352016]\n",
      "  [-0.40785738]\n",
      "  [-0.41049622]\n",
      "  [-0.41074516]\n",
      "  [-0.38751205]]\n",
      "\n",
      " [[-0.40661442]\n",
      "  [-0.41094716]\n",
      "  [-0.41018488]\n",
      "  [-0.3865293 ]\n",
      "  [-0.41202801]]\n",
      "\n",
      " [[-0.40970867]\n",
      "  [-0.41063188]\n",
      "  [-0.38577584]\n",
      "  [-0.41105403]\n",
      "  [-0.40931087]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-0.26124759]\n",
      "  [-0.12321868]\n",
      "  [ 4.41016554]\n",
      "  [ 1.93121285]\n",
      "  [ 5.65199728]]\n",
      "\n",
      " [[-0.12156408]\n",
      "  [ 4.4707893 ]\n",
      "  [ 1.95045616]\n",
      "  [ 5.6551429 ]\n",
      "  [ 4.5462473 ]]\n",
      "\n",
      " [[ 4.47908769]\n",
      "  [ 1.97991698]\n",
      "  [ 5.70409398]\n",
      "  [ 4.54899693]\n",
      "  [ 1.04911074]]]\n",
      "(912, 5, 1)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer \"simple_rnn_7\" is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (1, 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Alaric\\Documents\\Code\\Thesis-Repository\\Final Model Files\\NumericHyperTuning.ipynb Cell 9\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Alaric/Documents/Code/Thesis-Repository/Final%20Model%20Files/NumericHyperTuning.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m New_Flow\u001b[39m.\u001b[39;49mdefault_run()\n",
      "\u001b[1;32mc:\\Users\\Alaric\\Documents\\Code\\Thesis-Repository\\Final Model Files\\NumericHyperTuning.ipynb Cell 9\u001b[0m line \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Alaric/Documents/Code/Thesis-Repository/Final%20Model%20Files/NumericHyperTuning.ipynb#X11sZmlsZQ%3D%3D?line=138'>139</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdefault_run\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Alaric/Documents/Code/Thesis-Repository/Final%20Model%20Files/NumericHyperTuning.ipynb#X11sZmlsZQ%3D%3D?line=139'>140</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpreprocess_data()\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/Alaric/Documents/Code/Thesis-Repository/Final%20Model%20Files/NumericHyperTuning.ipynb#X11sZmlsZQ%3D%3D?line=140'>141</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbuild_model()\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Alaric/Documents/Code/Thesis-Repository/Final%20Model%20Files/NumericHyperTuning.ipynb#X11sZmlsZQ%3D%3D?line=141'>142</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshow_evaluation_results()\n",
      "\u001b[1;32mc:\\Users\\Alaric\\Documents\\Code\\Thesis-Repository\\Final Model Files\\NumericHyperTuning.ipynb Cell 9\u001b[0m line \u001b[0;36m6\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Alaric/Documents/Code/Thesis-Repository/Final%20Model%20Files/NumericHyperTuning.ipynb#X11sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpc\u001b[39m.\u001b[39mSpecial_Layer_Num \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Alaric/Documents/Code/Thesis-Repository/Final%20Model%20Files/NumericHyperTuning.ipynb#X11sZmlsZQ%3D%3D?line=65'>66</a>\u001b[0m     \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpc\u001b[39m.\u001b[39mSpecial_Layer_Num):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Alaric/Documents/Code/Thesis-Repository/Final%20Model%20Files/NumericHyperTuning.ipynb#X11sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m         model\u001b[39m.\u001b[39;49madd(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpc\u001b[39m.\u001b[39;49mSpecial_Layer_Type(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpc\u001b[39m.\u001b[39;49mSpecial_Layer_Units, return_sequences\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, activation\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpc\u001b[39m.\u001b[39;49mSpecial_Layer_Activation))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Alaric/Documents/Code/Thesis-Repository/Final%20Model%20Files/NumericHyperTuning.ipynb#X11sZmlsZQ%3D%3D?line=68'>69</a>\u001b[0m \u001b[39m# Final Special Layer\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Alaric/Documents/Code/Thesis-Repository/Final%20Model%20Files/NumericHyperTuning.ipynb#X11sZmlsZQ%3D%3D?line=69'>70</a>\u001b[0m model\u001b[39m.\u001b[39madd(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpc\u001b[39m.\u001b[39mSpecial_Layer_Type(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpc\u001b[39m.\u001b[39mSpecial_Layer_Units, activation\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpc\u001b[39m.\u001b[39mSpecial_Layer_Activation))\n",
      "File \u001b[1;32mc:\\Users\\Alaric\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\trackable\\base.py:205\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    204\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 205\u001b[0m   result \u001b[39m=\u001b[39m method(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    206\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    207\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m previous_value  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Alaric\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\Alaric\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\input_spec.py:235\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    233\u001b[0m     ndim \u001b[39m=\u001b[39m shape\u001b[39m.\u001b[39mrank\n\u001b[0;32m    234\u001b[0m     \u001b[39mif\u001b[39;00m ndim \u001b[39m!=\u001b[39m spec\u001b[39m.\u001b[39mndim:\n\u001b[1;32m--> 235\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    236\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mInput \u001b[39m\u001b[39m{\u001b[39;00minput_index\u001b[39m}\u001b[39;00m\u001b[39m of layer \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mlayer_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    237\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mis incompatible with the layer: \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    238\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mexpected ndim=\u001b[39m\u001b[39m{\u001b[39;00mspec\u001b[39m.\u001b[39mndim\u001b[39m}\u001b[39;00m\u001b[39m, found ndim=\u001b[39m\u001b[39m{\u001b[39;00mndim\u001b[39m}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    239\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFull shape received: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtuple\u001b[39m(shape)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    240\u001b[0m         )\n\u001b[0;32m    241\u001b[0m \u001b[39mif\u001b[39;00m spec\u001b[39m.\u001b[39mmax_ndim \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    242\u001b[0m     ndim \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mshape\u001b[39m.\u001b[39mrank\n",
      "\u001b[1;31mValueError\u001b[0m: Input 0 of layer \"simple_rnn_7\" is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (1, 5)"
     ]
    }
   ],
   "source": [
    "New_Flow.default_run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy Summary Table\n",
    "\n",
    "|      Base Setup     \t|     \t|     \t|     \t|         \t|            \t|     \t|     \t|     \t|         \t|\n",
    "|:-------------------:\t|-----\t|-----\t|-----\t|---------\t|------------\t|-----\t|-----\t|-----\t|---------\t|\n",
    "| SciKit              \t|  1  \t|  2  \t|  3  \t| Average \t| Tensorflow \t|  1  \t|  2  \t|  3  \t| Average \t|\n",
    "| K Nearest Neighbors \t| 100 \t| 100 \t| 100 \t|   100   \t| LSTM       \t| 100 \t| 100 \t| 100 \t|   100   \t|\n",
    "| Linear & RBF SVM    \t| 100 \t| 100 \t| 100 \t|   100   \t| GRU        \t| 100 \t| 100 \t| 100 \t|   100   \t|\n",
    "| QDA                 \t| 100 \t| 100 \t| 100 \t|   100   \t| Simple RNN \t| 100 \t| 100 \t| 100 \t|   100   \t|\n",
    "| Gaussian Process    \t| 100 \t| 100 \t| 100 \t|   100   \t| Bi LSTM    \t| 100 \t| 100 \t| 100 \t|   100   \t|\n",
    "| Decision Tree       \t| 100 \t| 100 \t| 100 \t|   100   \t| Bi GRU     \t| 100 \t| 100 \t| 100 \t|   100   \t|\n",
    "| Random Forest       \t| 100 \t| 100 \t| 100 \t|   100   \t| Bi RNN     \t| 100 \t| 100 \t| 100 \t|   100   \t|\n",
    "| Neural Net          \t| 100 \t| 100 \t| 100 \t|   100   \t| Dense      \t| 100 \t| 100 \t| 100 \t|   100   \t|\n",
    "| AdaBoost            \t| 100 \t| 100 \t| 100 \t|   100   \t|            \t|     \t|     \t|     \t|         \t|\n",
    "| Naive Bayes         \t| 100 \t| 100 \t| 100 \t|   100   \t|            \t|     \t|     \t|     \t|         \t|\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-03 14:12:05.998808: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-03 14:12:06.952665: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-03 14:12:09.018627: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-03 14:12:12.157323: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import tensorflow as tf \n",
    "import pickle \n",
    "\n",
    "from pprint import pprint\n",
    "from tqdm import tqdm\n",
    "\n",
    "from tensorflow import keras \n",
    "from tensorflow.keras import layers \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError, MeanAbsoluteError\n",
    "from tensorflow.keras.losses import MeanSquaredError, MeanAbsoluteError\n",
    "from tensorflow.keras.optimizers import Adam \n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV \n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder, minmax_scale\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.neural_network import BernoulliRBM\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score, classification_report\n",
    "from sklearn.datasets import load_digits\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from scipy.ndimage import convolve\n",
    "\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "import collections \n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4721/3229338220.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  raw_dataset[\"conditions\"] = [word.replace(\", \", \"\\n\") if (\",\" in word) else word for word in raw_dataset[\"conditions\"]]\n",
      "/tmp/ipykernel_4721/3229338220.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  raw_dataset[\"conditions\"] =  LE.fit_transform(raw_dataset[\"conditions\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29372, 25) (7344, 25) (29372,) (7344,)\n"
     ]
    }
   ],
   "source": [
    "FULL_DATA = False\n",
    "LE = LabelEncoder()\n",
    "WINDOW_LENGTH = 5\n",
    "ADD_ELEMENTS = True\n",
    "\n",
    "\n",
    "concatenated_data = pd.read_csv(\"Concatenated Data.csv\")\n",
    "\n",
    "if FULL_DATA:\n",
    "    raw_dataset = concatenated_data[[\"tempmax\", \"tempmin\", \"temp\", \"feelslikemax\", \"feelslikemin\", \"feelslike\", \"dew\", \"humidity\", \"windspeed\", \"sealevelpressure\", \"conditions\"]]\n",
    "else:\n",
    "    raw_dataset = concatenated_data[[\"temp\", \"feelslike\", \"humidity\", \"windspeed\", \"sealevelpressure\", \"conditions\"]]\n",
    "\n",
    "raw_dataset[\"conditions\"] = [word.replace(\", \", \"\\n\") if (\",\" in word) else word for word in raw_dataset[\"conditions\"]]\n",
    "raw_dataset[\"conditions\"] =  LE.fit_transform(raw_dataset[\"conditions\"])\n",
    "\n",
    "t_arr = raw_dataset.copy().to_numpy()\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for i in range(len(t_arr) - WINDOW_LENGTH):\n",
    "    t_row = []\n",
    "    for j in t_arr[i : i + WINDOW_LENGTH]:\n",
    "        t_row.append(j[:-1])\n",
    "    t_row = np.array(t_row).flatten()\n",
    "    X.append(t_row)\n",
    "    y.append(t_arr[i + WINDOW_LENGTH][-1])\n",
    "\n",
    "X = np.array(X, \"float32\")\n",
    "X = minmax_scale(X, feature_range=(0, 1))\n",
    "y = np.array(y)\n",
    "\n",
    "counts = dict(collections.Counter(y))\n",
    "max_count = max(counts.values())\n",
    "\n",
    "# Data Augmentation\n",
    "\n",
    "if ADD_ELEMENTS:\n",
    "    for key, value in counts.items():\n",
    "        curX = []\n",
    "        curY = []\n",
    "        li, = np.where(y == key)\n",
    "        for i in range((max_count - value) * 10):\n",
    "            ci = random.choice(li)\n",
    "            curX.append(X[ci])\n",
    "            curY.append(y[ci])\n",
    "        tX = X.tolist()\n",
    "        tY = y.tolist()\n",
    "        tX.extend(curX)\n",
    "        tY.extend(curY)\n",
    "        X = np.array(tX)\n",
    "        y = np.array(tY)        \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size = 0.2)\n",
    "print(X_train.shape, X_test.shape, X_valid.shape, y_train.shape, y_valid.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN\tConstant\tLayer: 0\tAccuracy: 95.35675381263616\n",
      "KNN\tConstant\tLayer: 1\tAccuracy: 94.79847494553377\n",
      "KNN\tConstant\tLayer: 2\tAccuracy: 94.44444444444444\n",
      "KNN\tConstant\tLayer: 3\tAccuracy: 94.25381263616558\n",
      "KNN\tConstant\tLayer: 4\tAccuracy: 94.14488017429193\n",
      "KNN\tConstant\tLayer: 5\tAccuracy: 93.80446623093682\n",
      "RBF SVM\tConstant\tLayer: 0\tAccuracy: 90.16884531590415\n",
      "RBF SVM\tConstant\tLayer: 1\tAccuracy: 56.495098039215684\n",
      "RBF SVM\tConstant\tLayer: 2\tAccuracy: 55.9640522875817\n",
      "RBF SVM\tConstant\tLayer: 3\tAccuracy: 51.85185185185185\n",
      "RBF SVM\tConstant\tLayer: 4\tAccuracy: 54.69771241830066\n",
      "RBF SVM\tConstant\tLayer: 5\tAccuracy: 56.03213507625272\n",
      "LINEAR SVM\tConstant\tLayer: 0\tAccuracy: 82.77505446623094\n",
      "LINEAR SVM\tConstant\tLayer: 1\tAccuracy: 53.47222222222222\n",
      "LINEAR SVM\tConstant\tLayer: 2\tAccuracy: 50.65359477124183\n",
      "LINEAR SVM\tConstant\tLayer: 3\tAccuracy: 54.47984749455338\n",
      "LINEAR SVM\tConstant\tLayer: 4\tAccuracy: 54.738562091503276\n",
      "LINEAR SVM\tConstant\tLayer: 5\tAccuracy: 55.392156862745104\n",
      "DECISION TREE\tConstant\tLayer: 0\tAccuracy: 97.1541394335512\n",
      "DECISION TREE\tConstant\tLayer: 1\tAccuracy: 97.18137254901961\n",
      "DECISION TREE\tConstant\tLayer: 2\tAccuracy: 96.77287581699346\n",
      "DECISION TREE\tConstant\tLayer: 3\tAccuracy: 96.70479302832244\n",
      "DECISION TREE\tConstant\tLayer: 4\tAccuracy: 96.71840958605664\n",
      "DECISION TREE\tConstant\tLayer: 5\tAccuracy: 96.50054466230938\n",
      "RANDOM FOREST\tConstant\tLayer: 0\tAccuracy: 97.75326797385621\n",
      "RANDOM FOREST\tConstant\tLayer: 1\tAccuracy: 96.89542483660131\n",
      "RANDOM FOREST\tConstant\tLayer: 2\tAccuracy: 96.5958605664488\n",
      "RANDOM FOREST\tConstant\tLayer: 3\tAccuracy: 96.6367102396514\n",
      "RANDOM FOREST\tConstant\tLayer: 4\tAccuracy: 96.47331154684096\n",
      "RANDOM FOREST\tConstant\tLayer: 5\tAccuracy: 96.5958605664488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alaric\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP\tConstant\tLayer: 0\tAccuracy: 92.08877995642702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alaric\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP\tConstant\tLayer: 1\tAccuracy: 57.938453159041394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alaric\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP\tConstant\tLayer: 2\tAccuracy: 59.912854030501094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alaric\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP\tConstant\tLayer: 3\tAccuracy: 57.44825708061002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alaric\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP\tConstant\tLayer: 4\tAccuracy: 58.55119825708061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alaric\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP\tConstant\tLayer: 5\tAccuracy: 53.07734204793029\n",
      "ADA BOOST\tConstant\tLayer: 0\tAccuracy: 85.23965141612202\n",
      "ADA BOOST\tConstant\tLayer: 1\tAccuracy: 79.38453159041394\n",
      "ADA BOOST\tConstant\tLayer: 2\tAccuracy: 76.93355119825708\n",
      "ADA BOOST\tConstant\tLayer: 3\tAccuracy: 69.96187363834423\n",
      "ADA BOOST\tConstant\tLayer: 4\tAccuracy: 75.12254901960785\n",
      "ADA BOOST\tConstant\tLayer: 5\tAccuracy: 72.68518518518519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alaric\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOGISTIC\tConstant\tLayer: 0\tAccuracy: 76.10294117647058\n",
      "LOGISTIC\tConstant\tLayer: 1\tAccuracy: 56.141067538126364\n",
      "LOGISTIC\tConstant\tLayer: 2\tAccuracy: 50.885076252723316\n",
      "LOGISTIC\tConstant\tLayer: 3\tAccuracy: 54.724945533769066\n",
      "LOGISTIC\tConstant\tLayer: 4\tAccuracy: 55.392156862745104\n",
      "LOGISTIC\tConstant\tLayer: 5\tAccuracy: 57.27124183006536\n"
     ]
    }
   ],
   "source": [
    "RBM_MULTIPLIER = 0.5\n",
    "\n",
    "classifiers = [\n",
    "    (\"KNN\", KNeighborsClassifier()),\n",
    "    (\"RBF SVM\", SVC()),\n",
    "    (\"LINEAR SVM\", SVC(kernel = \"linear\")),\n",
    "    (\"DECISION TREE\", DecisionTreeClassifier()),\n",
    "    (\"RANDOM FOREST\", RandomForestClassifier()),\n",
    "    (\"MLP\", MLPClassifier()),\n",
    "    (\"ADA BOOST\", AdaBoostClassifier()),    \n",
    "    (\"LOGISTIC\", LogisticRegression())\n",
    "]\n",
    "\n",
    "Results = {\n",
    "\n",
    "}\n",
    "\n",
    "for (name, _clf) in classifiers:\n",
    "\n",
    "    for rbm_layer in range(0, 6):\n",
    "        comb = []\n",
    "\n",
    "        comb.append((f\"mms0\", MinMaxScaler()))\n",
    "        # Constant\n",
    "        for j in range(0, rbm_layer):\n",
    "            comb.append((f\"rbm{j}\", BernoulliRBM(n_components = int(X_train.shape[1] * RBM_MULTIPLIER), learning_rate = 0.01, n_iter = 10, verbose = 0)))\n",
    "\n",
    "            if j == rbm_layer - 1:\n",
    "                comb.append((f\"mms{j}\", MinMaxScaler()))\n",
    "\n",
    "\n",
    "        \n",
    "        comb.append((name, _clf))\n",
    "        predictor = Pipeline(comb)\n",
    "\n",
    "        predictor.fit(X_train, y_train)\n",
    "        y_pred = predictor.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred) * 100\n",
    "        if name not in Results:\n",
    "            Results[name] = {}\n",
    "        Results[name][rbm_layer] = accuracy\n",
    "        print(f\"{name}\\tConstant\\tLayer: {rbm_layer}\\tAccuracy: {accuracy}\")\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ADA BOOST': {0: 85.23965141612202,\n",
      "               1: 79.38453159041394,\n",
      "               2: 76.93355119825708,\n",
      "               3: 69.96187363834423,\n",
      "               4: 75.12254901960785,\n",
      "               5: 72.68518518518519},\n",
      " 'DECISION TREE': {0: 97.1541394335512,\n",
      "                   1: 97.18137254901961,\n",
      "                   2: 96.77287581699346,\n",
      "                   3: 96.70479302832244,\n",
      "                   4: 96.71840958605664,\n",
      "                   5: 96.50054466230938},\n",
      " 'KNN': {0: 95.35675381263616,\n",
      "         1: 94.79847494553377,\n",
      "         2: 94.44444444444444,\n",
      "         3: 94.25381263616558,\n",
      "         4: 94.14488017429193,\n",
      "         5: 93.80446623093682},\n",
      " 'LINEAR SVM': {0: 82.77505446623094,\n",
      "                1: 53.47222222222222,\n",
      "                2: 50.65359477124183,\n",
      "                3: 54.47984749455338,\n",
      "                4: 54.738562091503276,\n",
      "                5: 55.392156862745104},\n",
      " 'LOGISTIC': {0: 76.10294117647058,\n",
      "              1: 56.141067538126364,\n",
      "              2: 50.885076252723316,\n",
      "              3: 54.724945533769066,\n",
      "              4: 55.392156862745104,\n",
      "              5: 57.27124183006536},\n",
      " 'MLP': {0: 92.08877995642702,\n",
      "         1: 57.938453159041394,\n",
      "         2: 59.912854030501094,\n",
      "         3: 57.44825708061002,\n",
      "         4: 58.55119825708061,\n",
      "         5: 53.07734204793029},\n",
      " 'RANDOM FOREST': {0: 97.75326797385621,\n",
      "                   1: 96.89542483660131,\n",
      "                   2: 96.5958605664488,\n",
      "                   3: 96.6367102396514,\n",
      "                   4: 96.47331154684096,\n",
      "                   5: 96.5958605664488},\n",
      " 'RBF SVM': {0: 90.16884531590415,\n",
      "             1: 56.495098039215684,\n",
      "             2: 55.9640522875817,\n",
      "             3: 51.85185185185185,\n",
      "             4: 54.69771241830066,\n",
      "             5: 56.03213507625272}}\n"
     ]
    }
   ],
   "source": [
    "pprint(Results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def BuildGenericModel(input_dimension, output_dimension, layerType, Kernel_Count = 64, Layer_Count = 2, Dense_Flag = False, Bidirectional_Flag = False):\n",
    "    PredictorModel = Sequential()\n",
    "    PredictorModel.add(layers.InputLayer((input_dimension, 1)))\n",
    "\n",
    "    if Dense_Flag:\n",
    "        # No Return Sequences for Dense Layer\n",
    "        for i in range(1, Layer_Count):\n",
    "            PredictorModel.add(layerType(Kernel_Count))\n",
    "\n",
    "        # Final Layer\n",
    "        PredictorModel.add(layerType(Kernel_Count))\n",
    "        \n",
    "    elif Bidirectional_Flag:\n",
    "        # Return Sequences (Only Adds if More than 1 Layers)\n",
    "        for i in range(1, Layer_Count):\n",
    "            PredictorModel.add(layerType)\n",
    "\n",
    "        # Add a Final SimpleRNN Layer at End of Bidirectional Layers\n",
    "        PredictorModel.add(layers.SimpleRNN(Kernel_Count))\n",
    "\n",
    "    else:\n",
    "        # Return Sequences (Only Adds if More than 1 Layers)\n",
    "        for i in range(1, Layer_Count):\n",
    "            PredictorModel.add(layerType(Kernel_Count, return_sequences = True))\n",
    "        \n",
    "        # Final Layer\n",
    "        PredictorModel.add(layerType(Kernel_Count))\n",
    "\n",
    "    # Flatten Layer\n",
    "    PredictorModel.add(layers.Flatten()) \n",
    "\n",
    "    # Output Dimension\n",
    "    PredictorModel.add(layers.Dense(output_dimension, activation = \"softmax\"))\n",
    "\n",
    "    # Compile Model\n",
    "    PredictorModel.compile(loss = \"categorical_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])\n",
    "\n",
    "    return PredictorModel\n",
    "\n",
    "def buildModels(X_train_shape, Y_train_shape, Kernel = 64, Layer_Count = 2):\n",
    "    LSTMModel = BuildGenericModel(X_train_shape[1], Y_train_shape[1], layers.LSTM, Kernel, Layer_Count)\n",
    "    GRUModel = BuildGenericModel(X_train_shape[1], Y_train_shape[1], layers.GRU, Kernel, Layer_Count)\n",
    "    SimpleRNNModel = BuildGenericModel(X_train_shape[1], Y_train_shape[1], layers.SimpleRNN, Kernel, Layer_Count)\n",
    "    BiLSTMModel = BuildGenericModel(X_train_shape[1], Y_train_shape[1], layers.Bidirectional(layers.LSTM(Kernel, return_sequences = True)), Kernel, Layer_Count, Bidirectional_Flag = True)\n",
    "    BiGRUModel = BuildGenericModel(X_train_shape[1], Y_train_shape[1], layers.Bidirectional(layers.GRU(Kernel, return_sequences = True)), Kernel, Layer_Count, Bidirectional_Flag = True)\n",
    "    BiSimpleRNNModel = BuildGenericModel(X_train_shape[1], Y_train_shape[1], layers.Bidirectional(layers.SimpleRNN(Kernel, return_sequences = True)), Kernel, Layer_Count, Bidirectional_Flag = True)\n",
    "    DenseModel = BuildGenericModel(X_train_shape[1], Y_train_shape[1], layers.Dense, Kernel, Layer_Count, Dense_Flag = True)\n",
    "\n",
    "    return (LSTMModel, GRUModel, SimpleRNNModel, BiLSTMModel, BiGRUModel, BiSimpleRNNModel, DenseModel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "\n",
    "tf_X_train = minmax_scale(X_train, feature_range = (0, 1))\n",
    "tf_X_test = minmax_scale(X_test, feature_range = (0, 1))\n",
    "\n",
    "tf_y_train = to_categorical(y_train)\n",
    "tf_y_test = to_categorical(y_test)\n",
    "\n",
    "LSTM_Predictor, GRU_Predictor, RNN_Predictor, Bi_LSTM_Predictor, Bi_GRU_Predictor, Bi_RNN_Predictor, Dense_Predictor = buildModels(tf_X_train.shape, tf_y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "TRAIN_EPOCHS = 10\n",
    "BATCH_SIZE = 1024\n",
    "\n",
    "classifiers = [\n",
    "    (\"LSTM\", LSTM_Predictor), \n",
    "    (\"GRU\", GRU_Predictor), \n",
    "    (\"RNN\", RNN_Predictor), \n",
    "    (\"BI LSTM\", Bi_LSTM_Predictor), \n",
    "    (\"BI GRU\", Bi_GRU_Predictor), \n",
    "    (\"BI RNN\", Bi_RNN_Predictor), \n",
    "    (\"DENSE\", Dense_Predictor)\n",
    "]\n",
    "\n",
    "Results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 103ms/step - accuracy: 0.4037 - loss: 1.2605\n",
      "Epoch 2/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 101ms/step - accuracy: 0.4594 - loss: 1.1091\n",
      "Epoch 3/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 103ms/step - accuracy: 0.4572 - loss: 1.1103\n",
      "Epoch 4/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 99ms/step - accuracy: 0.4684 - loss: 1.0973\n",
      "Epoch 5/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 104ms/step - accuracy: 0.4639 - loss: 1.0888\n",
      "Epoch 6/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 101ms/step - accuracy: 0.4904 - loss: 1.0690\n",
      "Epoch 7/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 100ms/step - accuracy: 0.4765 - loss: 1.0655\n",
      "Epoch 8/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 99ms/step - accuracy: 0.4735 - loss: 1.0675\n",
      "Epoch 9/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 103ms/step - accuracy: 0.4786 - loss: 1.0564\n",
      "Epoch 10/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 100ms/step - accuracy: 0.4844 - loss: 1.0335\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
      "LSTM\tConstant\tLayer: 0\tAccuracy: 46.5958605664488\n",
      "Epoch 1/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 197ms/step - accuracy: 0.4097 - loss: 1.2219\n",
      "Epoch 2/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 195ms/step - accuracy: 0.4915 - loss: 1.0876\n",
      "Epoch 3/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 195ms/step - accuracy: 0.5134 - loss: 1.0680\n",
      "Epoch 4/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 194ms/step - accuracy: 0.5070 - loss: 1.0583\n",
      "Epoch 5/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 194ms/step - accuracy: 0.5165 - loss: 1.0470\n",
      "Epoch 6/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 193ms/step - accuracy: 0.5062 - loss: 1.0584\n",
      "Epoch 7/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 193ms/step - accuracy: 0.5244 - loss: 1.0419\n",
      "Epoch 8/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 196ms/step - accuracy: 0.5236 - loss: 1.0417\n",
      "Epoch 9/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 190ms/step - accuracy: 0.5273 - loss: 1.0401\n",
      "Epoch 10/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 191ms/step - accuracy: 0.5167 - loss: 1.0359\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
      "LSTM\tConstant\tLayer: 1\tAccuracy: 39.106753812636164\n",
      "Epoch 1/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 191ms/step - accuracy: 0.4015 - loss: 1.2566\n",
      "Epoch 2/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 192ms/step - accuracy: 0.4991 - loss: 1.0991\n",
      "Epoch 3/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 190ms/step - accuracy: 0.4955 - loss: 1.0722\n",
      "Epoch 4/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 192ms/step - accuracy: 0.5103 - loss: 1.0621\n",
      "Epoch 5/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 192ms/step - accuracy: 0.5196 - loss: 1.0583\n",
      "Epoch 6/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 190ms/step - accuracy: 0.5153 - loss: 1.0607\n",
      "Epoch 7/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 191ms/step - accuracy: 0.5067 - loss: 1.0545\n",
      "Epoch 8/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 192ms/step - accuracy: 0.5281 - loss: 1.0521\n",
      "Epoch 9/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 192ms/step - accuracy: 0.5225 - loss: 1.0476\n",
      "Epoch 10/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 189ms/step - accuracy: 0.5099 - loss: 1.0577\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
      "LSTM\tConstant\tLayer: 2\tAccuracy: 43.110021786492375\n",
      "Epoch 1/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 191ms/step - accuracy: 0.3989 - loss: 1.2551\n",
      "Epoch 2/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 193ms/step - accuracy: 0.4930 - loss: 1.0791\n",
      "Epoch 3/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 191ms/step - accuracy: 0.5334 - loss: 1.0571\n",
      "Epoch 4/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 190ms/step - accuracy: 0.5291 - loss: 1.0559\n",
      "Epoch 5/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 194ms/step - accuracy: 0.5268 - loss: 1.0564\n",
      "Epoch 6/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 190ms/step - accuracy: 0.5240 - loss: 1.0524\n",
      "Epoch 7/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 190ms/step - accuracy: 0.5381 - loss: 1.0507\n",
      "Epoch 8/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 192ms/step - accuracy: 0.5219 - loss: 1.0495\n",
      "Epoch 9/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 191ms/step - accuracy: 0.5301 - loss: 1.0473\n",
      "Epoch 10/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 190ms/step - accuracy: 0.5478 - loss: 1.0394\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
      "LSTM\tConstant\tLayer: 3\tAccuracy: 38.9161220043573\n",
      "Epoch 1/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 191ms/step - accuracy: 0.4428 - loss: 1.2445\n",
      "Epoch 2/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 195ms/step - accuracy: 0.5201 - loss: 1.0787\n",
      "Epoch 3/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 194ms/step - accuracy: 0.5233 - loss: 1.0550\n",
      "Epoch 4/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 193ms/step - accuracy: 0.5274 - loss: 1.0481\n",
      "Epoch 5/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 192ms/step - accuracy: 0.5294 - loss: 1.0445\n",
      "Epoch 6/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 192ms/step - accuracy: 0.5281 - loss: 1.0483\n",
      "Epoch 7/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 191ms/step - accuracy: 0.5221 - loss: 1.0453\n",
      "Epoch 8/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 190ms/step - accuracy: 0.5190 - loss: 1.0511\n",
      "Epoch 9/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 190ms/step - accuracy: 0.5271 - loss: 1.0509\n",
      "Epoch 10/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 192ms/step - accuracy: 0.5230 - loss: 1.0434\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
      "LSTM\tConstant\tLayer: 4\tAccuracy: 49.37363834422658\n",
      "Epoch 1/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 193ms/step - accuracy: 0.4105 - loss: 1.2134\n",
      "Epoch 2/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 192ms/step - accuracy: 0.5017 - loss: 1.0730\n",
      "Epoch 3/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 193ms/step - accuracy: 0.5091 - loss: 1.0631\n",
      "Epoch 4/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 191ms/step - accuracy: 0.5030 - loss: 1.0597\n",
      "Epoch 5/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 192ms/step - accuracy: 0.4990 - loss: 1.0529\n",
      "Epoch 6/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 190ms/step - accuracy: 0.5103 - loss: 1.0578\n",
      "Epoch 7/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 192ms/step - accuracy: 0.5094 - loss: 1.0546\n",
      "Epoch 8/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 193ms/step - accuracy: 0.5079 - loss: 1.0512\n",
      "Epoch 9/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 191ms/step - accuracy: 0.5051 - loss: 1.0520\n",
      "Epoch 10/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 190ms/step - accuracy: 0.5014 - loss: 1.0784\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
      "LSTM\tConstant\tLayer: 5\tAccuracy: 37.36383442265795\n",
      "Epoch 1/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 110ms/step - accuracy: 0.3777 - loss: 1.2576\n",
      "Epoch 2/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 111ms/step - accuracy: 0.4525 - loss: 1.1204\n",
      "Epoch 3/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 111ms/step - accuracy: 0.4521 - loss: 1.1109\n",
      "Epoch 4/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 110ms/step - accuracy: 0.4622 - loss: 1.1001\n",
      "Epoch 5/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 108ms/step - accuracy: 0.5483 - loss: 1.0737\n",
      "Epoch 6/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 114ms/step - accuracy: 0.6309 - loss: 0.9312\n",
      "Epoch 7/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 110ms/step - accuracy: 0.6598 - loss: 0.8621\n",
      "Epoch 8/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 112ms/step - accuracy: 0.6985 - loss: 0.8025\n",
      "Epoch 9/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 109ms/step - accuracy: 0.7299 - loss: 0.7597\n",
      "Epoch 10/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 111ms/step - accuracy: 0.7633 - loss: 0.6818\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "GRU\tConstant\tLayer: 0\tAccuracy: 81.93082788671025\n",
      "Epoch 1/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 219ms/step - accuracy: 0.4560 - loss: 1.1911\n",
      "Epoch 2/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 220ms/step - accuracy: 0.4560 - loss: 1.0937\n",
      "Epoch 3/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 222ms/step - accuracy: 0.4826 - loss: 1.0846\n",
      "Epoch 4/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 218ms/step - accuracy: 0.5225 - loss: 1.0616\n",
      "Epoch 5/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 219ms/step - accuracy: 0.5092 - loss: 1.0637\n",
      "Epoch 6/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 221ms/step - accuracy: 0.5122 - loss: 1.0570\n",
      "Epoch 7/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 220ms/step - accuracy: 0.4977 - loss: 1.0536\n",
      "Epoch 8/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 219ms/step - accuracy: 0.4895 - loss: 1.0618\n",
      "Epoch 9/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 220ms/step - accuracy: 0.5007 - loss: 1.0537\n",
      "Epoch 10/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 219ms/step - accuracy: 0.5106 - loss: 1.0606\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "GRU\tConstant\tLayer: 1\tAccuracy: 39.106753812636164\n",
      "Epoch 1/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 217ms/step - accuracy: 0.4631 - loss: 1.2506\n",
      "Epoch 2/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 222ms/step - accuracy: 0.5020 - loss: 1.1083\n",
      "Epoch 3/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 221ms/step - accuracy: 0.5318 - loss: 1.0615\n",
      "Epoch 4/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 215ms/step - accuracy: 0.5275 - loss: 1.0534\n",
      "Epoch 5/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 219ms/step - accuracy: 0.5301 - loss: 1.0498\n",
      "Epoch 6/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 221ms/step - accuracy: 0.5244 - loss: 1.0551\n",
      "Epoch 7/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 217ms/step - accuracy: 0.5283 - loss: 1.0597\n",
      "Epoch 8/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 217ms/step - accuracy: 0.5293 - loss: 1.0589\n",
      "Epoch 9/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 219ms/step - accuracy: 0.5338 - loss: 1.0498\n",
      "Epoch 10/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 218ms/step - accuracy: 0.5298 - loss: 1.0476\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "GRU\tConstant\tLayer: 2\tAccuracy: 42.93300653594771\n",
      "Epoch 1/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 218ms/step - accuracy: 0.3593 - loss: 1.2774\n",
      "Epoch 2/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 217ms/step - accuracy: 0.4607 - loss: 1.0909\n",
      "Epoch 3/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 222ms/step - accuracy: 0.5297 - loss: 1.0649\n",
      "Epoch 4/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 219ms/step - accuracy: 0.5286 - loss: 1.0551\n",
      "Epoch 5/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 218ms/step - accuracy: 0.5277 - loss: 1.0486\n",
      "Epoch 6/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 217ms/step - accuracy: 0.5286 - loss: 1.0433\n",
      "Epoch 7/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 225ms/step - accuracy: 0.5278 - loss: 1.0484\n",
      "Epoch 8/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 220ms/step - accuracy: 0.5259 - loss: 1.0482\n",
      "Epoch 9/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 221ms/step - accuracy: 0.5199 - loss: 1.0501\n",
      "Epoch 10/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 217ms/step - accuracy: 0.5264 - loss: 1.0449\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "GRU\tConstant\tLayer: 3\tAccuracy: 39.106753812636164\n",
      "Epoch 1/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 220ms/step - accuracy: 0.4077 - loss: 1.2677\n",
      "Epoch 2/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 219ms/step - accuracy: 0.4757 - loss: 1.1184\n",
      "Epoch 3/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 220ms/step - accuracy: 0.5050 - loss: 1.0801\n",
      "Epoch 4/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 217ms/step - accuracy: 0.5000 - loss: 1.0691\n",
      "Epoch 5/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 218ms/step - accuracy: 0.4927 - loss: 1.0634\n",
      "Epoch 6/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 220ms/step - accuracy: 0.4986 - loss: 1.0562\n",
      "Epoch 7/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 224ms/step - accuracy: 0.5131 - loss: 1.0593\n",
      "Epoch 8/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 217ms/step - accuracy: 0.4990 - loss: 1.0593\n",
      "Epoch 9/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 219ms/step - accuracy: 0.4945 - loss: 1.0609\n",
      "Epoch 10/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 222ms/step - accuracy: 0.4998 - loss: 1.0608\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "GRU\tConstant\tLayer: 4\tAccuracy: 46.54139433551198\n",
      "Epoch 1/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 223ms/step - accuracy: 0.3589 - loss: 1.2474\n",
      "Epoch 2/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 219ms/step - accuracy: 0.4673 - loss: 1.0923\n",
      "Epoch 3/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 219ms/step - accuracy: 0.5339 - loss: 1.0673\n",
      "Epoch 4/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 224ms/step - accuracy: 0.5229 - loss: 1.0509\n",
      "Epoch 5/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 220ms/step - accuracy: 0.5262 - loss: 1.0481\n",
      "Epoch 6/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 220ms/step - accuracy: 0.5237 - loss: 1.0476\n",
      "Epoch 7/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 218ms/step - accuracy: 0.5334 - loss: 1.0536\n",
      "Epoch 8/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 219ms/step - accuracy: 0.5301 - loss: 1.0404\n",
      "Epoch 9/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 216ms/step - accuracy: 0.5255 - loss: 1.0418\n",
      "Epoch 10/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 221ms/step - accuracy: 0.5308 - loss: 1.0430\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "GRU\tConstant\tLayer: 5\tAccuracy: 39.03867102396514\n",
      "Epoch 1/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 60ms/step - accuracy: 0.5704 - loss: 1.0613\n",
      "Epoch 2/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 0.7101 - loss: 0.8041\n",
      "Epoch 3/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - accuracy: 0.7683 - loss: 0.6916\n",
      "Epoch 4/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 0.8069 - loss: 0.5924\n",
      "Epoch 5/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.8437 - loss: 0.4877\n",
      "Epoch 6/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.8542 - loss: 0.4349\n",
      "Epoch 7/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.8663 - loss: 0.3858\n",
      "Epoch 8/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.8769 - loss: 0.3580\n",
      "Epoch 9/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.8822 - loss: 0.3322\n",
      "Epoch 10/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.8877 - loss: 0.3191\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "RNN\tConstant\tLayer: 0\tAccuracy: 84.76307189542483\n",
      "Epoch 1/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 65ms/step - accuracy: 0.4971 - loss: 1.1190\n",
      "Epoch 2/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - accuracy: 0.5196 - loss: 1.0584\n",
      "Epoch 3/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - accuracy: 0.5179 - loss: 1.0632\n",
      "Epoch 4/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 65ms/step - accuracy: 0.5162 - loss: 1.0498\n",
      "Epoch 5/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - accuracy: 0.5156 - loss: 1.0452\n",
      "Epoch 6/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - accuracy: 0.5089 - loss: 1.0520\n",
      "Epoch 7/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - accuracy: 0.5304 - loss: 1.0439\n",
      "Epoch 8/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - accuracy: 0.5177 - loss: 1.0480\n",
      "Epoch 9/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - accuracy: 0.5177 - loss: 1.0437\n",
      "Epoch 10/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - accuracy: 0.5161 - loss: 1.0491\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "RNN\tConstant\tLayer: 1\tAccuracy: 36.860021786492375\n",
      "Epoch 1/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 65ms/step - accuracy: 0.4316 - loss: 1.2173\n",
      "Epoch 2/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - accuracy: 0.5073 - loss: 1.0581\n",
      "Epoch 3/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - accuracy: 0.5106 - loss: 1.0546\n",
      "Epoch 4/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 64ms/step - accuracy: 0.5025 - loss: 1.0556\n",
      "Epoch 5/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - accuracy: 0.5098 - loss: 1.0470\n",
      "Epoch 6/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - accuracy: 0.5134 - loss: 1.0549\n",
      "Epoch 7/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - accuracy: 0.5159 - loss: 1.0511\n",
      "Epoch 8/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 67ms/step - accuracy: 0.5067 - loss: 1.0506\n",
      "Epoch 9/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - accuracy: 0.5135 - loss: 1.0412\n",
      "Epoch 10/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 66ms/step - accuracy: 0.5085 - loss: 1.0513\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "RNN\tConstant\tLayer: 2\tAccuracy: 47.167755991285404\n",
      "Epoch 1/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 65ms/step - accuracy: 0.4789 - loss: 1.1467\n",
      "Epoch 2/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - accuracy: 0.5045 - loss: 1.0627\n",
      "Epoch 3/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - accuracy: 0.5027 - loss: 1.0544\n",
      "Epoch 4/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 65ms/step - accuracy: 0.5078 - loss: 1.0548\n",
      "Epoch 5/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 64ms/step - accuracy: 0.5023 - loss: 1.0554\n",
      "Epoch 6/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - accuracy: 0.5076 - loss: 1.0499\n",
      "Epoch 7/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step - accuracy: 0.5045 - loss: 1.0511\n",
      "Epoch 8/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - accuracy: 0.5033 - loss: 1.0576\n",
      "Epoch 9/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - accuracy: 0.5112 - loss: 1.0538\n",
      "Epoch 10/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - accuracy: 0.4961 - loss: 1.0568\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "RNN\tConstant\tLayer: 3\tAccuracy: 32.84313725490196\n",
      "Epoch 1/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 64ms/step - accuracy: 0.4459 - loss: 1.1795\n",
      "Epoch 2/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - accuracy: 0.5232 - loss: 1.0522\n",
      "Epoch 3/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - accuracy: 0.5221 - loss: 1.0524\n",
      "Epoch 4/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 64ms/step - accuracy: 0.5336 - loss: 1.0513\n",
      "Epoch 5/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - accuracy: 0.5198 - loss: 1.0450\n",
      "Epoch 6/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - accuracy: 0.5228 - loss: 1.0446\n",
      "Epoch 7/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - accuracy: 0.5197 - loss: 1.0433\n",
      "Epoch 8/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - accuracy: 0.5233 - loss: 1.0422\n",
      "Epoch 9/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - accuracy: 0.5198 - loss: 1.0552\n",
      "Epoch 10/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 64ms/step - accuracy: 0.5152 - loss: 1.0483\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "RNN\tConstant\tLayer: 4\tAccuracy: 41.50326797385621\n",
      "Epoch 1/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 64ms/step - accuracy: 0.4559 - loss: 1.1494\n",
      "Epoch 2/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - accuracy: 0.5140 - loss: 1.0627\n",
      "Epoch 3/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - accuracy: 0.5265 - loss: 1.0577\n",
      "Epoch 4/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - accuracy: 0.5261 - loss: 1.0577\n",
      "Epoch 5/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - accuracy: 0.5199 - loss: 1.0578\n",
      "Epoch 6/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - accuracy: 0.5245 - loss: 1.0509\n",
      "Epoch 7/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - accuracy: 0.5110 - loss: 1.0483\n",
      "Epoch 8/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 68ms/step - accuracy: 0.5233 - loss: 1.0439\n",
      "Epoch 9/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - accuracy: 0.5136 - loss: 1.0549\n",
      "Epoch 10/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - accuracy: 0.5188 - loss: 1.0634\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "RNN\tConstant\tLayer: 5\tAccuracy: 38.834422657952075\n",
      "Epoch 1/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 106ms/step - accuracy: 0.4390 - loss: 1.1832\n",
      "Epoch 2/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 102ms/step - accuracy: 0.5143 - loss: 1.0755\n",
      "Epoch 3/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 103ms/step - accuracy: 0.5747 - loss: 1.0077\n",
      "Epoch 4/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 102ms/step - accuracy: 0.6511 - loss: 0.8903\n",
      "Epoch 5/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 102ms/step - accuracy: 0.6873 - loss: 0.8294\n",
      "Epoch 6/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 102ms/step - accuracy: 0.7353 - loss: 0.7595\n",
      "Epoch 7/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 100ms/step - accuracy: 0.7625 - loss: 0.6930\n",
      "Epoch 8/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 101ms/step - accuracy: 0.7889 - loss: 0.6256\n",
      "Epoch 9/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 101ms/step - accuracy: 0.8033 - loss: 0.5475\n",
      "Epoch 10/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 105ms/step - accuracy: 0.7846 - loss: 0.6193\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "BI LSTM\tConstant\tLayer: 0\tAccuracy: 79.2619825708061\n",
      "Epoch 1/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 317ms/step - accuracy: 0.4412 - loss: 1.1615\n",
      "Epoch 2/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 254ms/step - accuracy: 0.5162 - loss: 1.0600\n",
      "Epoch 3/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 241ms/step - accuracy: 0.5239 - loss: 1.0549\n",
      "Epoch 4/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 203ms/step - accuracy: 0.5152 - loss: 1.0515\n",
      "Epoch 5/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 199ms/step - accuracy: 0.5181 - loss: 1.0531\n",
      "Epoch 6/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 200ms/step - accuracy: 0.5215 - loss: 1.0440\n",
      "Epoch 7/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 198ms/step - accuracy: 0.5148 - loss: 1.0492\n",
      "Epoch 8/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 201ms/step - accuracy: 0.5158 - loss: 1.0480\n",
      "Epoch 9/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 200ms/step - accuracy: 0.5164 - loss: 1.0594\n",
      "Epoch 10/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 204ms/step - accuracy: 0.5237 - loss: 1.0450\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "BI LSTM\tConstant\tLayer: 1\tAccuracy: 39.14760348583878\n",
      "Epoch 1/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 203ms/step - accuracy: 0.4128 - loss: 1.2180\n",
      "Epoch 2/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 207ms/step - accuracy: 0.5193 - loss: 1.0636\n",
      "Epoch 3/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 202ms/step - accuracy: 0.5184 - loss: 1.0540\n",
      "Epoch 4/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 203ms/step - accuracy: 0.5086 - loss: 1.0626\n",
      "Epoch 5/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 199ms/step - accuracy: 0.5237 - loss: 1.0510\n",
      "Epoch 6/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 201ms/step - accuracy: 0.5200 - loss: 1.0479\n",
      "Epoch 7/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 199ms/step - accuracy: 0.5235 - loss: 1.0479\n",
      "Epoch 8/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 201ms/step - accuracy: 0.5311 - loss: 1.0440\n",
      "Epoch 9/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 201ms/step - accuracy: 0.5177 - loss: 1.0560\n",
      "Epoch 10/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 201ms/step - accuracy: 0.4829 - loss: 1.0962\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "BI LSTM\tConstant\tLayer: 2\tAccuracy: 45.46568627450981\n",
      "Epoch 1/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 201ms/step - accuracy: 0.4571 - loss: 1.1733\n",
      "Epoch 2/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 199ms/step - accuracy: 0.5065 - loss: 1.0755\n",
      "Epoch 3/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 199ms/step - accuracy: 0.5138 - loss: 1.0658\n",
      "Epoch 4/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 198ms/step - accuracy: 0.5001 - loss: 1.0546\n",
      "Epoch 5/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 198ms/step - accuracy: 0.5053 - loss: 1.0527\n",
      "Epoch 6/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 200ms/step - accuracy: 0.5242 - loss: 1.0462\n",
      "Epoch 7/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 200ms/step - accuracy: 0.5192 - loss: 1.0554\n",
      "Epoch 8/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 198ms/step - accuracy: 0.5162 - loss: 1.0446\n",
      "Epoch 9/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 202ms/step - accuracy: 0.5038 - loss: 1.0483\n",
      "Epoch 10/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 196ms/step - accuracy: 0.5064 - loss: 1.0423\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step\n",
      "BI LSTM\tConstant\tLayer: 3\tAccuracy: 39.13398692810458\n",
      "Epoch 1/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 204ms/step - accuracy: 0.3877 - loss: 1.2121\n",
      "Epoch 2/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 202ms/step - accuracy: 0.4986 - loss: 1.0807\n",
      "Epoch 3/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 200ms/step - accuracy: 0.5130 - loss: 1.0650\n",
      "Epoch 4/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 203ms/step - accuracy: 0.5109 - loss: 1.0543\n",
      "Epoch 5/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 202ms/step - accuracy: 0.5088 - loss: 1.0559\n",
      "Epoch 6/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 203ms/step - accuracy: 0.5181 - loss: 1.0499\n",
      "Epoch 7/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 203ms/step - accuracy: 0.5149 - loss: 1.0552\n",
      "Epoch 8/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 199ms/step - accuracy: 0.5127 - loss: 1.0481\n",
      "Epoch 9/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 200ms/step - accuracy: 0.5094 - loss: 1.0545\n",
      "Epoch 10/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 201ms/step - accuracy: 0.5100 - loss: 1.0523\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "BI LSTM\tConstant\tLayer: 4\tAccuracy: 49.11492374727669\n",
      "Epoch 1/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 201ms/step - accuracy: 0.4527 - loss: 1.1400\n",
      "Epoch 2/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 203ms/step - accuracy: 0.5138 - loss: 1.0604\n",
      "Epoch 3/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 200ms/step - accuracy: 0.5170 - loss: 1.0512\n",
      "Epoch 4/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 199ms/step - accuracy: 0.5122 - loss: 1.0541\n",
      "Epoch 5/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 204ms/step - accuracy: 0.5087 - loss: 1.0529\n",
      "Epoch 6/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 199ms/step - accuracy: 0.5002 - loss: 1.0472\n",
      "Epoch 7/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 197ms/step - accuracy: 0.5176 - loss: 1.0466\n",
      "Epoch 8/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 201ms/step - accuracy: 0.5051 - loss: 1.0503\n",
      "Epoch 9/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 198ms/step - accuracy: 0.5197 - loss: 1.0409\n",
      "Epoch 10/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 200ms/step - accuracy: 0.5159 - loss: 1.0398\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "BI LSTM\tConstant\tLayer: 5\tAccuracy: 38.57570806100218\n",
      "Epoch 1/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 116ms/step - accuracy: 0.5011 - loss: 1.1930\n",
      "Epoch 2/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 113ms/step - accuracy: 0.6042 - loss: 0.9507\n",
      "Epoch 3/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 114ms/step - accuracy: 0.6494 - loss: 0.8754\n",
      "Epoch 4/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 111ms/step - accuracy: 0.7187 - loss: 0.7766\n",
      "Epoch 5/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 114ms/step - accuracy: 0.7685 - loss: 0.6866\n",
      "Epoch 6/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 113ms/step - accuracy: 0.8099 - loss: 0.5818\n",
      "Epoch 7/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 115ms/step - accuracy: 0.8405 - loss: 0.4927\n",
      "Epoch 8/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 113ms/step - accuracy: 0.8583 - loss: 0.4265\n",
      "Epoch 9/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 113ms/step - accuracy: 0.8731 - loss: 0.3766\n",
      "Epoch 10/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 112ms/step - accuracy: 0.8730 - loss: 0.3717\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "BI GRU\tConstant\tLayer: 0\tAccuracy: 79.45261437908496\n",
      "Epoch 1/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 225ms/step - accuracy: 0.4819 - loss: 1.1133\n",
      "Epoch 2/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 230ms/step - accuracy: 0.5114 - loss: 1.0646\n",
      "Epoch 3/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 227ms/step - accuracy: 0.5123 - loss: 1.0555\n",
      "Epoch 4/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 223ms/step - accuracy: 0.5111 - loss: 1.0535\n",
      "Epoch 5/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 225ms/step - accuracy: 0.4999 - loss: 1.0523\n",
      "Epoch 6/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 222ms/step - accuracy: 0.5121 - loss: 1.0524\n",
      "Epoch 7/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 227ms/step - accuracy: 0.5158 - loss: 1.0560\n",
      "Epoch 8/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 225ms/step - accuracy: 0.5162 - loss: 1.0528\n",
      "Epoch 9/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 224ms/step - accuracy: 0.5095 - loss: 1.0453\n",
      "Epoch 10/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 227ms/step - accuracy: 0.5066 - loss: 1.0400\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
      "BI GRU\tConstant\tLayer: 1\tAccuracy: 39.61056644880174\n",
      "Epoch 1/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 226ms/step - accuracy: 0.4004 - loss: 1.1973\n",
      "Epoch 2/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 227ms/step - accuracy: 0.5119 - loss: 1.0753\n",
      "Epoch 3/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 224ms/step - accuracy: 0.5105 - loss: 1.0616\n",
      "Epoch 4/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 226ms/step - accuracy: 0.5034 - loss: 1.0571\n",
      "Epoch 5/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 225ms/step - accuracy: 0.5070 - loss: 1.0610\n",
      "Epoch 6/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 221ms/step - accuracy: 0.5005 - loss: 1.0553\n",
      "Epoch 7/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 223ms/step - accuracy: 0.5071 - loss: 1.0519\n",
      "Epoch 8/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 224ms/step - accuracy: 0.5095 - loss: 1.0474\n",
      "Epoch 9/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 221ms/step - accuracy: 0.5082 - loss: 1.0496\n",
      "Epoch 10/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 223ms/step - accuracy: 0.5152 - loss: 1.0455\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step\n",
      "BI GRU\tConstant\tLayer: 2\tAccuracy: 48.5838779956427\n",
      "Epoch 1/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 226ms/step - accuracy: 0.4561 - loss: 1.1864\n",
      "Epoch 2/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 225ms/step - accuracy: 0.5072 - loss: 1.0636\n",
      "Epoch 3/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 223ms/step - accuracy: 0.5119 - loss: 1.0635\n",
      "Epoch 4/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 223ms/step - accuracy: 0.5172 - loss: 1.0529\n",
      "Epoch 5/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 225ms/step - accuracy: 0.5050 - loss: 1.0520\n",
      "Epoch 6/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 223ms/step - accuracy: 0.5117 - loss: 1.0469\n",
      "Epoch 7/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 223ms/step - accuracy: 0.5136 - loss: 1.0469\n",
      "Epoch 8/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 224ms/step - accuracy: 0.5064 - loss: 1.0509\n",
      "Epoch 9/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 225ms/step - accuracy: 0.5018 - loss: 1.0544\n",
      "Epoch 10/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 222ms/step - accuracy: 0.5186 - loss: 1.0526\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
      "BI GRU\tConstant\tLayer: 3\tAccuracy: 38.88888888888889\n",
      "Epoch 1/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 223ms/step - accuracy: 0.4421 - loss: 1.1590\n",
      "Epoch 2/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 227ms/step - accuracy: 0.5158 - loss: 1.0751\n",
      "Epoch 3/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 226ms/step - accuracy: 0.5128 - loss: 1.0618\n",
      "Epoch 4/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 227ms/step - accuracy: 0.5150 - loss: 1.0543\n",
      "Epoch 5/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 228ms/step - accuracy: 0.5125 - loss: 1.0597\n",
      "Epoch 6/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 222ms/step - accuracy: 0.5192 - loss: 1.0493\n",
      "Epoch 7/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 224ms/step - accuracy: 0.5159 - loss: 1.0489\n",
      "Epoch 8/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 225ms/step - accuracy: 0.5208 - loss: 1.0512\n",
      "Epoch 9/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 225ms/step - accuracy: 0.5052 - loss: 1.0516\n",
      "Epoch 10/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 225ms/step - accuracy: 0.5203 - loss: 1.0460\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "BI GRU\tConstant\tLayer: 4\tAccuracy: 49.959150326797385\n",
      "Epoch 1/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 224ms/step - accuracy: 0.4385 - loss: 1.1508\n",
      "Epoch 2/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 229ms/step - accuracy: 0.4827 - loss: 1.0820\n",
      "Epoch 3/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 227ms/step - accuracy: 0.5133 - loss: 1.0613\n",
      "Epoch 4/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 223ms/step - accuracy: 0.5152 - loss: 1.0586\n",
      "Epoch 5/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 223ms/step - accuracy: 0.5061 - loss: 1.0732\n",
      "Epoch 6/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 222ms/step - accuracy: 0.5164 - loss: 1.0584\n",
      "Epoch 7/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 230ms/step - accuracy: 0.5024 - loss: 1.0547\n",
      "Epoch 8/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 224ms/step - accuracy: 0.5185 - loss: 1.0477\n",
      "Epoch 9/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 221ms/step - accuracy: 0.5086 - loss: 1.0559\n",
      "Epoch 10/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 226ms/step - accuracy: 0.5066 - loss: 1.0549\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
      "BI GRU\tConstant\tLayer: 5\tAccuracy: 43.12363834422658\n",
      "Epoch 1/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step - accuracy: 0.5552 - loss: 1.0801\n",
      "Epoch 2/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.7256 - loss: 0.7490\n",
      "Epoch 3/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.8036 - loss: 0.6109\n",
      "Epoch 4/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.8424 - loss: 0.4961\n",
      "Epoch 5/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.8546 - loss: 0.4251\n",
      "Epoch 6/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - accuracy: 0.8742 - loss: 0.3485\n",
      "Epoch 7/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - accuracy: 0.8753 - loss: 0.3356\n",
      "Epoch 8/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.8783 - loss: 0.3276\n",
      "Epoch 9/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.8921 - loss: 0.2885\n",
      "Epoch 10/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.8954 - loss: 0.2755\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "BI RNN\tConstant\tLayer: 0\tAccuracy: 83.87799564270153\n",
      "Epoch 1/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 101ms/step - accuracy: 0.4242 - loss: 1.2327\n",
      "Epoch 2/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 102ms/step - accuracy: 0.5213 - loss: 1.0563\n",
      "Epoch 3/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 108ms/step - accuracy: 0.5332 - loss: 1.0493\n",
      "Epoch 4/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 104ms/step - accuracy: 0.5345 - loss: 1.0467\n",
      "Epoch 5/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 100ms/step - accuracy: 0.5242 - loss: 1.0538\n",
      "Epoch 6/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 102ms/step - accuracy: 0.5314 - loss: 1.0422\n",
      "Epoch 7/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 102ms/step - accuracy: 0.5329 - loss: 1.0463\n",
      "Epoch 8/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 100ms/step - accuracy: 0.5398 - loss: 1.0378\n",
      "Epoch 9/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 101ms/step - accuracy: 0.5380 - loss: 1.0359\n",
      "Epoch 10/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 102ms/step - accuracy: 0.5372 - loss: 1.0392\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "BI RNN\tConstant\tLayer: 1\tAccuracy: 38.87527233115469\n",
      "Epoch 1/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 102ms/step - accuracy: 0.4725 - loss: 1.1292\n",
      "Epoch 2/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 101ms/step - accuracy: 0.5093 - loss: 1.0634\n",
      "Epoch 3/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 103ms/step - accuracy: 0.5016 - loss: 1.0464\n",
      "Epoch 4/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 101ms/step - accuracy: 0.5082 - loss: 1.0599\n",
      "Epoch 5/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 99ms/step - accuracy: 0.5132 - loss: 1.0521\n",
      "Epoch 6/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 104ms/step - accuracy: 0.5114 - loss: 1.0486\n",
      "Epoch 7/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 99ms/step - accuracy: 0.5077 - loss: 1.0527\n",
      "Epoch 8/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 101ms/step - accuracy: 0.5102 - loss: 1.0508\n",
      "Epoch 9/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 104ms/step - accuracy: 0.4991 - loss: 1.0491\n",
      "Epoch 10/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 101ms/step - accuracy: 0.5139 - loss: 1.0430\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "BI RNN\tConstant\tLayer: 2\tAccuracy: 26.742919389978216\n",
      "Epoch 1/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 103ms/step - accuracy: 0.4849 - loss: 1.1581\n",
      "Epoch 2/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 106ms/step - accuracy: 0.4951 - loss: 1.0771\n",
      "Epoch 3/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 102ms/step - accuracy: 0.5281 - loss: 1.0627\n",
      "Epoch 4/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 100ms/step - accuracy: 0.5120 - loss: 1.0639\n",
      "Epoch 5/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 103ms/step - accuracy: 0.5323 - loss: 1.0627\n",
      "Epoch 6/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 102ms/step - accuracy: 0.5312 - loss: 1.0642\n",
      "Epoch 7/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 100ms/step - accuracy: 0.5275 - loss: 1.0623\n",
      "Epoch 8/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 104ms/step - accuracy: 0.5259 - loss: 1.0647\n",
      "Epoch 9/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 99ms/step - accuracy: 0.5070 - loss: 1.0625\n",
      "Epoch 10/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 102ms/step - accuracy: 0.5201 - loss: 1.0672\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "BI RNN\tConstant\tLayer: 3\tAccuracy: 39.88289760348584\n",
      "Epoch 1/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 104ms/step - accuracy: 0.4217 - loss: 1.1817\n",
      "Epoch 2/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 102ms/step - accuracy: 0.5020 - loss: 1.0624\n",
      "Epoch 3/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 102ms/step - accuracy: 0.5110 - loss: 1.0598\n",
      "Epoch 4/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 104ms/step - accuracy: 0.5183 - loss: 1.0578\n",
      "Epoch 5/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 103ms/step - accuracy: 0.5243 - loss: 1.0562\n",
      "Epoch 6/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 105ms/step - accuracy: 0.5042 - loss: 1.0606\n",
      "Epoch 7/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 101ms/step - accuracy: 0.4984 - loss: 1.0569\n",
      "Epoch 8/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 102ms/step - accuracy: 0.5058 - loss: 1.0606\n",
      "Epoch 9/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 102ms/step - accuracy: 0.5128 - loss: 1.0596\n",
      "Epoch 10/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 101ms/step - accuracy: 0.5064 - loss: 1.0516\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "BI RNN\tConstant\tLayer: 4\tAccuracy: 43.409586056644876\n",
      "Epoch 1/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 106ms/step - accuracy: 0.4545 - loss: 1.1637\n",
      "Epoch 2/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 103ms/step - accuracy: 0.5142 - loss: 1.0583\n",
      "Epoch 3/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 102ms/step - accuracy: 0.5189 - loss: 1.0592\n",
      "Epoch 4/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 102ms/step - accuracy: 0.5074 - loss: 1.0613\n",
      "Epoch 5/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 106ms/step - accuracy: 0.5300 - loss: 1.0589\n",
      "Epoch 6/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 99ms/step - accuracy: 0.5208 - loss: 1.0550\n",
      "Epoch 7/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 102ms/step - accuracy: 0.5135 - loss: 1.0584\n",
      "Epoch 8/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 102ms/step - accuracy: 0.5149 - loss: 1.0589\n",
      "Epoch 9/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 102ms/step - accuracy: 0.5186 - loss: 1.0550\n",
      "Epoch 10/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 102ms/step - accuracy: 0.5146 - loss: 1.0576\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "BI RNN\tConstant\tLayer: 5\tAccuracy: 39.106753812636164\n",
      "Epoch 1/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.4755 - loss: 1.1676\n",
      "Epoch 2/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.6501 - loss: 0.9544\n",
      "Epoch 3/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6844 - loss: 0.8344\n",
      "Epoch 4/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.7077 - loss: 0.7699\n",
      "Epoch 5/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7294 - loss: 0.7299\n",
      "Epoch 6/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7410 - loss: 0.7153\n",
      "Epoch 7/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7615 - loss: 0.6983\n",
      "Epoch 8/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.7674 - loss: 0.6899\n",
      "Epoch 9/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7550 - loss: 0.6877\n",
      "Epoch 10/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7566 - loss: 0.6788\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 866us/step\n",
      "DENSE\tConstant\tLayer: 0\tAccuracy: 72.08605664488017\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense_8\" is incompatible with the layer: expected axis -1 of input shape to have value 1600, but received input with shape (None, 3200)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(None, 50), dtype=float32)\n  • training=True\n  • mask=None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 26\u001b[0m\n\u001b[1;32m     24\u001b[0m current_model \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mclone_model(_clf)\n\u001b[1;32m     25\u001b[0m current_model\u001b[38;5;241m.\u001b[39mcompile(loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m\"\u001b[39m, optimizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m\"\u001b[39m, metrics \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m---> 26\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mcurrent_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcopy_tf_X_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtf_y_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mTRAIN_EPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mmcp_save\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(current_model\u001b[38;5;241m.\u001b[39mpredict(tf_X_test), axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     28\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m accuracy_score(y_test, y_pred) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/keras/src/layers/input_spec.py:227\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m axis, value \u001b[38;5;129;01min\u001b[39;00m spec\u001b[38;5;241m.\u001b[39maxes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m shape[axis] \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m {\n\u001b[1;32m    224\u001b[0m             value,\n\u001b[1;32m    225\u001b[0m             \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    226\u001b[0m         }:\n\u001b[0;32m--> 227\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    228\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    229\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincompatible with the layer: expected axis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    230\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof input shape to have value \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    231\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut received input with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    232\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    233\u001b[0m             )\n\u001b[1;32m    234\u001b[0m \u001b[38;5;66;03m# Check shape.\u001b[39;00m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense_8\" is incompatible with the layer: expected axis -1 of input shape to have value 1600, but received input with shape (None, 3200)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(None, 50), dtype=float32)\n  • training=True\n  • mask=None"
     ]
    }
   ],
   "source": [
    "RBM_MULTIPLIER = 2 \n",
    "\n",
    "for (name, _clf) in classifiers:\n",
    "\n",
    "    for rbm_layer in range(0, 6):\n",
    "        comb = []\n",
    "\n",
    "        comb.append((f\"mms0\", MinMaxScaler()))\n",
    "\n",
    "        # Constant\n",
    "        for j in range(0, rbm_layer):\n",
    "            \n",
    "            comb.append((f\"rbm{j}\", BernoulliRBM(n_components = int(X_train.shape[1] * RBM_MULTIPLIER), learning_rate = 0.01, n_iter = 10, verbose = 0)))\n",
    "\n",
    "            if j == rbm_layer - 1:\n",
    "                comb.append((f\"mms1\", MinMaxScaler()))\n",
    "\n",
    "        predictor = Pipeline(comb)\n",
    "        \n",
    "        copy_tf_X_train = predictor.fit_transform(tf_X_train)\n",
    "        \n",
    "\n",
    "        mcp_save = ModelCheckpoint(f\"{name}_Constant_Layer_{rbm_layer}.keras\", save_best_only = True, monitor = \"accuracy\", mode = \"max\")\n",
    "        current_model = tf.keras.models.clone_model(_clf)\n",
    "        current_model.compile(loss = \"categorical_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])\n",
    "        history = current_model.fit(copy_tf_X_train, tf_y_train, batch_size = BATCH_SIZE, epochs = TRAIN_EPOCHS, callbacks = [mcp_save])\n",
    "        y_pred = np.argmax(current_model.predict(tf_X_test), axis = 1)\n",
    "        accuracy = accuracy_score(y_test, y_pred) * 100\n",
    "        \n",
    "        if name not in Results:\n",
    "            Results[name] = {}\n",
    "        \n",
    "        Results[name][rbm_layer] = {}\n",
    "        Results[name][rbm_layer][\"accuracy\"] = accuracy\n",
    "        Results[name][rbm_layer][\"history\"] = history.history\n",
    "        \n",
    "        print(f\"{name}\\tConstant\\tLayer: {rbm_layer}\\tAccuracy: {accuracy}\")\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "with open(\"TensorflowAccuracySaves.pkl\", \"wb\") as f:\n",
    "    pickle.dump(Results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'BI GRU': {0: {'accuracy': 79.45261437908496,\n",
      "                'history': {'accuracy': [0.5532479882240295,\n",
      "                                         0.6133732795715332,\n",
      "                                         0.6611058115959167,\n",
      "                                         0.7331812381744385,\n",
      "                                         0.7777815461158752,\n",
      "                                         0.8153683543205261,\n",
      "                                         0.847201406955719,\n",
      "                                         0.8630668520927429,\n",
      "                                         0.8743020296096802,\n",
      "                                         0.8494144082069397],\n",
      "                            'loss': [1.0838005542755127,\n",
      "                                     0.9378266334533691,\n",
      "                                     0.8530462384223938,\n",
      "                                     0.7580858469009399,\n",
      "                                     0.6650296449661255,\n",
      "                                     0.5629475712776184,\n",
      "                                     0.46999791264533997,\n",
      "                                     0.4096503257751465,\n",
      "                                     0.3712565004825592,\n",
      "                                     0.43639594316482544]}},\n",
      "            1: {'accuracy': 39.61056644880174,\n",
      "                'history': {'accuracy': [0.5007830858230591,\n",
      "                                         0.511371374130249,\n",
      "                                         0.5150142908096313,\n",
      "                                         0.5114394426345825,\n",
      "                                         0.5063666105270386,\n",
      "                                         0.5108947157859802,\n",
      "                                         0.5096009969711304,\n",
      "                                         0.5115075707435608,\n",
      "                                         0.5066390037536621,\n",
      "                                         0.5106223821640015],\n",
      "                            'loss': [1.0914307832717896,\n",
      "                                     1.059004306793213,\n",
      "                                     1.0537843704223633,\n",
      "                                     1.052590250968933,\n",
      "                                     1.0514698028564453,\n",
      "                                     1.0506833791732788,\n",
      "                                     1.0485378503799438,\n",
      "                                     1.04938542842865,\n",
      "                                     1.0490659475326538,\n",
      "                                     1.0432567596435547]}},\n",
      "            2: {'accuracy': 48.5838779956427,\n",
      "                'history': {'accuracy': [0.47031185030937195,\n",
      "                                         0.5112351775169373,\n",
      "                                         0.5123927593231201,\n",
      "                                         0.5130396485328674,\n",
      "                                         0.5090903043746948,\n",
      "                                         0.5009873509407043,\n",
      "                                         0.5068773031234741,\n",
      "                                         0.5120522975921631,\n",
      "                                         0.5121203660964966,\n",
      "                                         0.5149462223052979],\n",
      "                            'loss': [1.1357005834579468,\n",
      "                                     1.0700191259384155,\n",
      "                                     1.0573686361312866,\n",
      "                                     1.0513032674789429,\n",
      "                                     1.063230037689209,\n",
      "                                     1.0553454160690308,\n",
      "                                     1.053966760635376,\n",
      "                                     1.050554871559143,\n",
      "                                     1.050920844078064,\n",
      "                                     1.0506559610366821]}},\n",
      "            3: {'accuracy': 38.88888888888889,\n",
      "                'history': {'accuracy': [0.46929049491882324,\n",
      "                                         0.5097712278366089,\n",
      "                                         0.5093286037445068,\n",
      "                                         0.5132439136505127,\n",
      "                                         0.5018385052680969,\n",
      "                                         0.5089200735092163,\n",
      "                                         0.5058218836784363,\n",
      "                                         0.5057197213172913,\n",
      "                                         0.5040174126625061,\n",
      "                                         0.5114054083824158],\n",
      "                            'loss': [1.1238360404968262,\n",
      "                                     1.061812162399292,\n",
      "                                     1.0574114322662354,\n",
      "                                     1.055912733078003,\n",
      "                                     1.0527739524841309,\n",
      "                                     1.0505050420761108,\n",
      "                                     1.0504971742630005,\n",
      "                                     1.0518563985824585,\n",
      "                                     1.048525094985962,\n",
      "                                     1.0518056154251099]}},\n",
      "            4: {'accuracy': 49.959150326797385,\n",
      "                'history': {'accuracy': [0.4686436057090759,\n",
      "                                         0.5157292485237122,\n",
      "                                         0.5129715204238892,\n",
      "                                         0.5163761377334595,\n",
      "                                         0.5122565627098083,\n",
      "                                         0.5153887867927551,\n",
      "                                         0.5094988346099854,\n",
      "                                         0.5148780941963196,\n",
      "                                         0.51079261302948,\n",
      "                                         0.5246152877807617],\n",
      "                            'loss': [1.119722604751587,\n",
      "                                     1.0692217350006104,\n",
      "                                     1.059104561805725,\n",
      "                                     1.055030107498169,\n",
      "                                     1.0579177141189575,\n",
      "                                     1.0506623983383179,\n",
      "                                     1.0492249727249146,\n",
      "                                     1.0489847660064697,\n",
      "                                     1.0514410734176636,\n",
      "                                     1.0419408082962036]}},\n",
      "            5: {'accuracy': 43.12363834422658,\n",
      "                'history': {'accuracy': [0.45706796646118164,\n",
      "                                         0.49703800678253174,\n",
      "                                         0.5114394426345825,\n",
      "                                         0.5158994793891907,\n",
      "                                         0.4975486993789673,\n",
      "                                         0.5107244849205017,\n",
      "                                         0.5032343864440918,\n",
      "                                         0.5095669627189636,\n",
      "                                         0.5112351775169373,\n",
      "                                         0.5003744959831238],\n",
      "                            'loss': [1.1164027452468872,\n",
      "                                     1.0735574960708618,\n",
      "                                     1.0601931810379028,\n",
      "                                     1.0573996305465698,\n",
      "                                     1.0718241930007935,\n",
      "                                     1.0584423542022705,\n",
      "                                     1.0560777187347412,\n",
      "                                     1.0565457344055176,\n",
      "                                     1.0483589172363281,\n",
      "                                     1.0537009239196777]}}},\n",
      " 'BI LSTM': {0: {'accuracy': 79.2619825708061,\n",
      "                 'history': {'accuracy': [0.46054065227508545,\n",
      "                                          0.5241726636886597,\n",
      "                                          0.594205379486084,\n",
      "                                          0.6477938294410706,\n",
      "                                          0.6937559843063354,\n",
      "                                          0.7448590397834778,\n",
      "                                          0.7677720189094543,\n",
      "                                          0.7874506115913391,\n",
      "                                          0.802975594997406,\n",
      "                                          0.8015456795692444],\n",
      "                             'loss': [1.129815697669983,\n",
      "                                      1.0573577880859375,\n",
      "                                      0.9848219752311707,\n",
      "                                      0.8784767389297485,\n",
      "                                      0.8131195306777954,\n",
      "                                      0.7424432635307312,\n",
      "                                      0.6748402714729309,\n",
      "                                      0.6193081736564636,\n",
      "                                      0.5447137951850891,\n",
      "                                      0.5727142691612244]}},\n",
      "             1: {'accuracy': 39.14760348583878,\n",
      "                 'history': {'accuracy': [0.4859730303287506,\n",
      "                                          0.5219937562942505,\n",
      "                                          0.5210404396057129,\n",
      "                                          0.5157292485237122,\n",
      "                                          0.5162399411201477,\n",
      "                                          0.5191338658332825,\n",
      "                                          0.5128353238105774,\n",
      "                                          0.5161378383636475,\n",
      "                                          0.5209383368492126,\n",
      "                                          0.5182486772537231],\n",
      "                             'loss': [1.1093149185180664,\n",
      "                                      1.061463475227356,\n",
      "                                      1.056154727935791,\n",
      "                                      1.0533583164215088,\n",
      "                                      1.0507324934005737,\n",
      "                                      1.0488005876541138,\n",
      "                                      1.0475053787231445,\n",
      "                                      1.0477960109710693,\n",
      "                                      1.0541797876358032,\n",
      "                                      1.048784613609314]}},\n",
      "             2: {'accuracy': 45.46568627450981,\n",
      "                 'history': {'accuracy': [0.47766581177711487,\n",
      "                                          0.522061824798584,\n",
      "                                          0.5214830636978149,\n",
      "                                          0.519746720790863,\n",
      "                                          0.5206659436225891,\n",
      "                                          0.5184189081192017,\n",
      "                                          0.521959662437439,\n",
      "                                          0.5227767825126648,\n",
      "                                          0.4944164454936981,\n",
      "                                          0.49421218037605286],\n",
      "                             'loss': [1.1430115699768066,\n",
      "                                      1.0572625398635864,\n",
      "                                      1.052042007446289,\n",
      "                                      1.0524694919586182,\n",
      "                                      1.048648476600647,\n",
      "                                      1.0488579273223877,\n",
      "                                      1.0450564622879028,\n",
      "                                      1.050606608390808,\n",
      "                                      1.0725305080413818,\n",
      "                                      1.0928115844726562]}},\n",
      "             3: {'accuracy': 39.13398692810458,\n",
      "                 'history': {'accuracy': [0.4700394868850708,\n",
      "                                          0.5164783000946045,\n",
      "                                          0.5114054083824158,\n",
      "                                          0.5025534629821777,\n",
      "                                          0.5047323703765869,\n",
      "                                          0.5172953605651855,\n",
      "                                          0.5165804028511047,\n",
      "                                          0.5120863318443298,\n",
      "                                          0.5039493441581726,\n",
      "                                          0.5074900984764099],\n",
      "                             'loss': [1.1245927810668945,\n",
      "                                      1.0658957958221436,\n",
      "                                      1.0589722394943237,\n",
      "                                      1.0543280839920044,\n",
      "                                      1.0513050556182861,\n",
      "                                      1.0517603158950806,\n",
      "                                      1.0532783269882202,\n",
      "                                      1.0484180450439453,\n",
      "                                      1.0459210872650146,\n",
      "                                      1.0457501411437988]}},\n",
      "             4: {'accuracy': 49.11492374727669,\n",
      "                 'history': {'accuracy': [0.4479776620864868,\n",
      "                                          0.5048345327377319,\n",
      "                                          0.5158994793891907,\n",
      "                                          0.5076944231987,\n",
      "                                          0.5080007910728455,\n",
      "                                          0.5099414587020874,\n",
      "                                          0.5130396485328674,\n",
      "                                          0.5117458701133728,\n",
      "                                          0.5122565627098083,\n",
      "                                          0.5153547525405884],\n",
      "                             'loss': [1.147111415863037,\n",
      "                                      1.0732148885726929,\n",
      "                                      1.0603612661361694,\n",
      "                                      1.0559250116348267,\n",
      "                                      1.052936315536499,\n",
      "                                      1.051329493522644,\n",
      "                                      1.0505576133728027,\n",
      "                                      1.0512287616729736,\n",
      "                                      1.0542573928833008,\n",
      "                                      1.0508449077606201]}},\n",
      "             5: {'accuracy': 38.57570806100218,\n",
      "                 'history': {'accuracy': [0.47749558091163635,\n",
      "                                          0.5135162472724915,\n",
      "                                          0.5209383368492126,\n",
      "                                          0.5108947157859802,\n",
      "                                          0.5119161009788513,\n",
      "                                          0.5072517991065979,\n",
      "                                          0.51079261302948,\n",
      "                                          0.5110649466514587,\n",
      "                                          0.5146057605743408,\n",
      "                                          0.5131077170372009],\n",
      "                             'loss': [1.1047184467315674,\n",
      "                                      1.0586726665496826,\n",
      "                                      1.0565364360809326,\n",
      "                                      1.0554890632629395,\n",
      "                                      1.0515280961990356,\n",
      "                                      1.0480306148529053,\n",
      "                                      1.0498511791229248,\n",
      "                                      1.0468498468399048,\n",
      "                                      1.0451706647872925,\n",
      "                                      1.0454431772232056]}}},\n",
      " 'BI RNN': {0: {'accuracy': 83.87799564270153,\n",
      "                'history': {'accuracy': [0.6138159036636353,\n",
      "                                         0.7423055768013,\n",
      "                                         0.8140406012535095,\n",
      "                                         0.847303569316864,\n",
      "                                         0.8577556610107422,\n",
      "                                         0.8742339611053467,\n",
      "                                         0.8731104731559753,\n",
      "                                         0.8839370608329773,\n",
      "                                         0.891325056552887,\n",
      "                                         0.896602213382721],\n",
      "                            'loss': [0.9627890586853027,\n",
      "                                     0.7162654399871826,\n",
      "                                     0.5846415758132935,\n",
      "                                     0.47111886739730835,\n",
      "                                     0.41005846858024597,\n",
      "                                     0.33945414423942566,\n",
      "                                     0.34997665882110596,\n",
      "                                     0.313838392496109,\n",
      "                                     0.2870800793170929,\n",
      "                                     0.2723412811756134]}},\n",
      "            1: {'accuracy': 38.87527233115469,\n",
      "                'history': {'accuracy': [0.48103636503219604,\n",
      "                                         0.524717390537262,\n",
      "                                         0.5347950458526611,\n",
      "                                         0.5335693955421448,\n",
      "                                         0.522742748260498,\n",
      "                                         0.5314244627952576,\n",
      "                                         0.5358844995498657,\n",
      "                                         0.5384039282798767,\n",
      "                                         0.5331267714500427,\n",
      "                                         0.5354079008102417],\n",
      "                            'loss': [1.131833553314209,\n",
      "                                     1.0552877187728882,\n",
      "                                     1.0507265329360962,\n",
      "                                     1.0482615232467651,\n",
      "                                     1.0496090650558472,\n",
      "                                     1.0463329553604126,\n",
      "                                     1.0435516834259033,\n",
      "                                     1.0414420366287231,\n",
      "                                     1.044607400894165,\n",
      "                                     1.0407497882843018]}},\n",
      "            2: {'accuracy': 26.742919389978216,\n",
      "                'history': {'accuracy': [0.5,\n",
      "                                         0.5108266472816467,\n",
      "                                         0.5024853348731995,\n",
      "                                         0.508034884929657,\n",
      "                                         0.5147419571876526,\n",
      "                                         0.5045281052589417,\n",
      "                                         0.5107244849205017,\n",
      "                                         0.5104861855506897,\n",
      "                                         0.5029619932174683,\n",
      "                                         0.5124267935752869],\n",
      "                            'loss': [1.0901572704315186,\n",
      "                                     1.058764100074768,\n",
      "                                     1.0534628629684448,\n",
      "                                     1.0533689260482788,\n",
      "                                     1.054464340209961,\n",
      "                                     1.0497181415557861,\n",
      "                                     1.0502663850784302,\n",
      "                                     1.0473268032073975,\n",
      "                                     1.0478273630142212,\n",
      "                                     1.0480326414108276]}},\n",
      "            3: {'accuracy': 39.88289760348584,\n",
      "                'history': {'accuracy': [0.4963911175727844,\n",
      "                                         0.511371374130249,\n",
      "                                         0.524717390537262,\n",
      "                                         0.5068092346191406,\n",
      "                                         0.5237641334533691,\n",
      "                                         0.5256707072257996,\n",
      "                                         0.5259431004524231,\n",
      "                                         0.5275092124938965,\n",
      "                                         0.5163421034812927,\n",
      "                                         0.5235258340835571],\n",
      "                            'loss': [1.1052606105804443,\n",
      "                                     1.0695836544036865,\n",
      "                                     1.064892053604126,\n",
      "                                     1.0647673606872559,\n",
      "                                     1.0632266998291016,\n",
      "                                     1.0621886253356934,\n",
      "                                     1.062355875968933,\n",
      "                                     1.0602189302444458,\n",
      "                                     1.0599000453948975,\n",
      "                                     1.0656721591949463]}},\n",
      "            4: {'accuracy': 43.409586056644876,\n",
      "                'history': {'accuracy': [0.4705161452293396,\n",
      "                                         0.5045281052589417,\n",
      "                                         0.510452151298523,\n",
      "                                         0.5129374861717224,\n",
      "                                         0.5212106704711914,\n",
      "                                         0.508375346660614,\n",
      "                                         0.5007830858230591,\n",
      "                                         0.5095328688621521,\n",
      "                                         0.5148780941963196,\n",
      "                                         0.5084774494171143],\n",
      "                            'loss': [1.1095058917999268,\n",
      "                                     1.0647835731506348,\n",
      "                                     1.0594260692596436,\n",
      "                                     1.0573471784591675,\n",
      "                                     1.0549522638320923,\n",
      "                                     1.0551260709762573,\n",
      "                                     1.0618597269058228,\n",
      "                                     1.058451771736145,\n",
      "                                     1.0565316677093506,\n",
      "                                     1.056475043296814]}},\n",
      "            5: {'accuracy': 39.106753812636164,\n",
      "                'history': {'accuracy': [0.4843047857284546,\n",
      "                                         0.5181124806404114,\n",
      "                                         0.5137546062469482,\n",
      "                                         0.511609673500061,\n",
      "                                         0.5243428945541382,\n",
      "                                         0.5159335136413574,\n",
      "                                         0.5177720189094543,\n",
      "                                         0.5180103778839111,\n",
      "                                         0.5213128328323364,\n",
      "                                         0.5192360281944275],\n",
      "                            'loss': [1.1078685522079468,\n",
      "                                     1.0604091882705688,\n",
      "                                     1.060915231704712,\n",
      "                                     1.058967113494873,\n",
      "                                     1.0566552877426147,\n",
      "                                     1.058700680732727,\n",
      "                                     1.0585455894470215,\n",
      "                                     1.0562355518341064,\n",
      "                                     1.0537700653076172,\n",
      "                                     1.0597532987594604]}}},\n",
      " 'DENSE': {0: {'accuracy': 72.08605664488017,\n",
      "               'history': {'accuracy': [0.5450088381767273,\n",
      "                                        0.655113697052002,\n",
      "                                        0.6888533234596252,\n",
      "                                        0.7074084281921387,\n",
      "                                        0.7369603514671326,\n",
      "                                        0.7442802786827087,\n",
      "                                        0.7629374861717224,\n",
      "                                        0.7633460164070129,\n",
      "                                        0.755617618560791,\n",
      "                                        0.7587498426437378],\n",
      "                           'loss': [1.099197268486023,\n",
      "                                    0.9238905906677246,\n",
      "                                    0.8205193877220154,\n",
      "                                    0.7583594918251038,\n",
      "                                    0.7240001559257507,\n",
      "                                    0.7120170593261719,\n",
      "                                    0.6981621980667114,\n",
      "                                    0.692436933517456,\n",
      "                                    0.6888765096664429,\n",
      "                                    0.6836680769920349]}}},\n",
      " 'GRU': {0: {'accuracy': 81.93082788671025,\n",
      "             'history': {'accuracy': [0.42428162693977356,\n",
      "                                      0.45424214005470276,\n",
      "                                      0.45424214005470276,\n",
      "                                      0.47317174077033997,\n",
      "                                      0.5796336531639099,\n",
      "                                      0.6360819935798645,\n",
      "                                      0.6681873798370361,\n",
      "                                      0.7062168121337891,\n",
      "                                      0.7390031218528748,\n",
      "                                      0.7824799418449402],\n",
      "                         'loss': [1.1847132444381714,\n",
      "                                  1.1135659217834473,\n",
      "                                  1.1079996824264526,\n",
      "                                  1.0996825695037842,\n",
      "                                  1.0501458644866943,\n",
      "                                  0.9157247543334961,\n",
      "                                  0.8500472903251648,\n",
      "                                  0.7927377223968506,\n",
      "                                  0.7366323471069336,\n",
      "                                  0.6423576474189758]}},\n",
      "         1: {'accuracy': 39.106753812636164,\n",
      "             'history': {'accuracy': [0.4551273286342621,\n",
      "                                      0.459961861371994,\n",
      "                                      0.5040855407714844,\n",
      "                                      0.5127672553062439,\n",
      "                                      0.5078305602073669,\n",
      "                                      0.5019746422767639,\n",
      "                                      0.505753755569458,\n",
      "                                      0.48971810936927795,\n",
      "                                      0.5067411065101624,\n",
      "                                      0.5066730380058289],\n",
      "                         'loss': [1.136730670928955,\n",
      "                                  1.0896409749984741,\n",
      "                                  1.0768029689788818,\n",
      "                                  1.061517596244812,\n",
      "                                  1.0584732294082642,\n",
      "                                  1.0571867227554321,\n",
      "                                  1.0570749044418335,\n",
      "                                  1.0565611124038696,\n",
      "                                  1.0565623044967651,\n",
      "                                  1.057863712310791]}},\n",
      "         2: {'accuracy': 42.93300653594771,\n",
      "             'history': {'accuracy': [0.4677584171295166,\n",
      "                                      0.5156952142715454,\n",
      "                                      0.5316628217697144,\n",
      "                                      0.5293817520141602,\n",
      "                                      0.5292795896530151,\n",
      "                                      0.5281901359558105,\n",
      "                                      0.530335009098053,\n",
      "                                      0.5277815461158752,\n",
      "                                      0.5276113152503967,\n",
      "                                      0.5301307439804077],\n",
      "                         'loss': [1.1834511756896973,\n",
      "                                  1.098071575164795,\n",
      "                                  1.0587632656097412,\n",
      "                                  1.0539720058441162,\n",
      "                                  1.0536701679229736,\n",
      "                                  1.053708553314209,\n",
      "                                  1.0539103746414185,\n",
      "                                  1.0529433488845825,\n",
      "                                  1.0528349876403809,\n",
      "                                  1.0518549680709839]}},\n",
      "         3: {'accuracy': 39.106753812636164,\n",
      "             'history': {'accuracy': [0.42591583728790283,\n",
      "                                      0.46557945013046265,\n",
      "                                      0.5275092124938965,\n",
      "                                      0.5305052399635315,\n",
      "                                      0.5290412902832031,\n",
      "                                      0.5300626158714294,\n",
      "                                      0.5309818983078003,\n",
      "                                      0.5321394801139832,\n",
      "                                      0.5308116674423218,\n",
      "                                      0.5258409380912781],\n",
      "                         'loss': [1.1858406066894531,\n",
      "                                  1.0884908437728882,\n",
      "                                  1.0603039264678955,\n",
      "                                  1.0484453439712524,\n",
      "                                  1.0462841987609863,\n",
      "                                  1.045418381690979,\n",
      "                                  1.0457159280776978,\n",
      "                                  1.0460152626037598,\n",
      "                                  1.0444114208221436,\n",
      "                                  1.0439804792404175]}},\n",
      "         4: {'accuracy': 46.54139433551198,\n",
      "             'history': {'accuracy': [0.4536293148994446,\n",
      "                                      0.493156760931015,\n",
      "                                      0.5082391500473022,\n",
      "                                      0.5037450790405273,\n",
      "                                      0.49615278840065,\n",
      "                                      0.4940759837627411,\n",
      "                                      0.5060261487960815,\n",
      "                                      0.49737846851348877,\n",
      "                                      0.4970720410346985,\n",
      "                                      0.49482500553131104],\n",
      "                         'loss': [1.1935780048370361,\n",
      "                                  1.1087299585342407,\n",
      "                                  1.075937032699585,\n",
      "                                  1.0635652542114258,\n",
      "                                  1.0621851682662964,\n",
      "                                  1.0612704753875732,\n",
      "                                  1.061012864112854,\n",
      "                                  1.0601240396499634,\n",
      "                                  1.0605357885360718,\n",
      "                                  1.058620572090149]}},\n",
      "         5: {'accuracy': 39.03867102396514,\n",
      "             'history': {'accuracy': [0.4266988933086395,\n",
      "                                      0.4818875193595886,\n",
      "                                      0.533671498298645,\n",
      "                                      0.5241045951843262,\n",
      "                                      0.5266580581665039,\n",
      "                                      0.5246152877807617,\n",
      "                                      0.533433198928833,\n",
      "                                      0.5251259803771973,\n",
      "                                      0.5270665884017944,\n",
      "                                      0.5261133313179016],\n",
      "                         'loss': [1.1691967248916626,\n",
      "                                  1.0863157510757446,\n",
      "                                  1.0591657161712646,\n",
      "                                  1.0493760108947754,\n",
      "                                  1.0457314252853394,\n",
      "                                  1.0459574460983276,\n",
      "                                  1.0478392839431763,\n",
      "                                  1.0442843437194824,\n",
      "                                  1.0439943075180054,\n",
      "                                  1.0444389581680298]}}},\n",
      " 'LSTM': {0: {'accuracy': 46.5958605664488,\n",
      "              'history': {'accuracy': [0.43255481123924255,\n",
      "                                       0.45825955271720886,\n",
      "                                       0.4583617150783539,\n",
      "                                       0.4713672995567322,\n",
      "                                       0.46568161249160767,\n",
      "                                       0.48042353987693787,\n",
      "                                       0.4726269841194153,\n",
      "                                       0.47432929277420044,\n",
      "                                       0.4795042872428894,\n",
      "                                       0.48284080624580383],\n",
      "                          'loss': [1.1831039190292358,\n",
      "                                   1.1114225387573242,\n",
      "                                   1.1061428785324097,\n",
      "                                   1.0989151000976562,\n",
      "                                   1.0787433385849,\n",
      "                                   1.0725822448730469,\n",
      "                                   1.0666115283966064,\n",
      "                                   1.0582877397537231,\n",
      "                                   1.0518629550933838,\n",
      "                                   1.04164457321167]}},\n",
      "          1: {'accuracy': 39.106753812636164,\n",
      "              'history': {'accuracy': [0.44304099678993225,\n",
      "                                       0.5048685669898987,\n",
      "                                       0.511711835861206,\n",
      "                                       0.5149462223052979,\n",
      "                                       0.5125289559364319,\n",
      "                                       0.515967607498169,\n",
      "                                       0.5221298933029175,\n",
      "                                       0.525160014629364,\n",
      "                                       0.5229470133781433,\n",
      "                                       0.5124267935752869],\n",
      "                          'loss': [1.1475725173950195,\n",
      "                                   1.0789834260940552,\n",
      "                                   1.0586137771606445,\n",
      "                                   1.056671380996704,\n",
      "                                   1.0509589910507202,\n",
      "                                   1.0490798950195312,\n",
      "                                   1.0462902784347534,\n",
      "                                   1.0420947074890137,\n",
      "                                   1.0397981405258179,\n",
      "                                   1.0481047630310059]}},\n",
      "          2: {'accuracy': 43.110021786492375,\n",
      "              'history': {'accuracy': [0.44784149527549744,\n",
      "                                       0.5064346790313721,\n",
      "                                       0.5024853348731995,\n",
      "                                       0.5091243386268616,\n",
      "                                       0.51389080286026,\n",
      "                                       0.5126651525497437,\n",
      "                                       0.5076944231987,\n",
      "                                       0.5182486772537231,\n",
      "                                       0.5244110226631165,\n",
      "                                       0.5198488235473633],\n",
      "                          'loss': [1.1827812194824219,\n",
      "                                   1.088590383529663,\n",
      "                                   1.0685300827026367,\n",
      "                                   1.0620112419128418,\n",
      "                                   1.0626575946807861,\n",
      "                                   1.059934139251709,\n",
      "                                   1.0559790134429932,\n",
      "                                   1.0534931421279907,\n",
      "                                   1.0505788326263428,\n",
      "                                   1.0549660921096802]}},\n",
      "          3: {'accuracy': 38.9161220043573,\n",
      "              'history': {'accuracy': [0.446922242641449,\n",
      "                                       0.5105882883071899,\n",
      "                                       0.525057852268219,\n",
      "                                       0.5222320556640625,\n",
      "                                       0.5321394801139832,\n",
      "                                       0.5229810476303101,\n",
      "                                       0.5339779257774353,\n",
      "                                       0.5289391279220581,\n",
      "                                       0.5319351553916931,\n",
      "                                       0.5403105020523071],\n",
      "                          'loss': [1.166185975074768,\n",
      "                                   1.0688693523406982,\n",
      "                                   1.0557172298431396,\n",
      "                                   1.0539741516113281,\n",
      "                                   1.0526783466339111,\n",
      "                                   1.0532150268554688,\n",
      "                                   1.0504469871520996,\n",
      "                                   1.0497738122940063,\n",
      "                                   1.0492759943008423,\n",
      "                                   1.047631025314331]}},\n",
      "          4: {'accuracy': 49.37363834422658,\n",
      "              'history': {'accuracy': [0.4724908173084259,\n",
      "                                       0.5187253355979919,\n",
      "                                       0.5231512784957886,\n",
      "                                       0.525057852268219,\n",
      "                                       0.5257387757301331,\n",
      "                                       0.527679443359375,\n",
      "                                       0.5260452032089233,\n",
      "                                       0.5243428945541382,\n",
      "                                       0.5301647782325745,\n",
      "                                       0.5295519828796387],\n",
      "                          'loss': [1.1673604249954224,\n",
      "                                   1.0732178688049316,\n",
      "                                   1.0559685230255127,\n",
      "                                   1.0510653257369995,\n",
      "                                   1.0482527017593384,\n",
      "                                   1.046728253364563,\n",
      "                                   1.0469155311584473,\n",
      "                                   1.0531502962112427,\n",
      "                                   1.0462350845336914,\n",
      "                                   1.0396043062210083]}},\n",
      "          5: {'accuracy': 37.36383442265795,\n",
      "              'history': {'accuracy': [0.4494757056236267,\n",
      "                                       0.5019065737724304,\n",
      "                                       0.5036769509315491,\n",
      "                                       0.5057878494262695,\n",
      "                                       0.5066730380058289,\n",
      "                                       0.5097712278366089,\n",
      "                                       0.5097371935844421,\n",
      "                                       0.5040515065193176,\n",
      "                                       0.5019406080245972,\n",
      "                                       0.4910799264907837],\n",
      "                          'loss': [1.140444278717041,\n",
      "                                   1.0688495635986328,\n",
      "                                   1.063275694847107,\n",
      "                                   1.05787992477417,\n",
      "                                   1.0595753192901611,\n",
      "                                   1.0576237440109253,\n",
      "                                   1.0551977157592773,\n",
      "                                   1.0522596836090088,\n",
      "                                   1.0487362146377563,\n",
      "                                   1.0848376750946045]}}},\n",
      " 'RNN': {0: {'accuracy': 84.76307189542483,\n",
      "             'history': {'accuracy': [0.6230763792991638,\n",
      "                                      0.7266784906387329,\n",
      "                                      0.7789391279220581,\n",
      "                                      0.8150960206985474,\n",
      "                                      0.8427754044532776,\n",
      "                                      0.8570066690444946,\n",
      "                                      0.867186427116394,\n",
      "                                      0.8753915429115295,\n",
      "                                      0.8818602561950684,\n",
      "                                      0.8870352506637573],\n",
      "                         'loss': [0.9674045443534851,\n",
      "                                  0.7770270705223083,\n",
      "                                  0.6653823256492615,\n",
      "                                  0.5693496465682983,\n",
      "                                  0.47695615887641907,\n",
      "                                  0.4256415069103241,\n",
      "                                  0.385000616312027,\n",
      "                                  0.35263505578041077,\n",
      "                                  0.3287089169025421,\n",
      "                                  0.31570106744766235]}},\n",
      "         1: {'accuracy': 36.860021786492375,\n",
      "             'history': {'accuracy': [0.5109968781471252,\n",
      "                                      0.5149802565574646,\n",
      "                                      0.5208702087402344,\n",
      "                                      0.516546368598938,\n",
      "                                      0.5201212167739868,\n",
      "                                      0.5124608278274536,\n",
      "                                      0.5241386294364929,\n",
      "                                      0.5140950679779053,\n",
      "                                      0.5214830636978149,\n",
      "                                      0.5203595161437988],\n",
      "                         'loss': [1.0818753242492676,\n",
      "                                  1.0628459453582764,\n",
      "                                  1.0553793907165527,\n",
      "                                  1.0518213510513306,\n",
      "                                  1.0514470338821411,\n",
      "                                  1.049453616142273,\n",
      "                                  1.0526787042617798,\n",
      "                                  1.0509941577911377,\n",
      "                                  1.047498106956482,\n",
      "                                  1.0461851358413696]}},\n",
      "         2: {'accuracy': 47.167755991285404,\n",
      "             'history': {'accuracy': [0.48787960410118103,\n",
      "                                      0.5103499889373779,\n",
      "                                      0.5093286037445068,\n",
      "                                      0.5075582265853882,\n",
      "                                      0.5053452253341675,\n",
      "                                      0.5154909491539001,\n",
      "                                      0.510928750038147,\n",
      "                                      0.5066049098968506,\n",
      "                                      0.5148100256919861,\n",
      "                                      0.5071496367454529],\n",
      "                         'loss': [1.1149982213974,\n",
      "                                  1.0588070154190063,\n",
      "                                  1.0530526638031006,\n",
      "                                  1.0524064302444458,\n",
      "                                  1.0513333082199097,\n",
      "                                  1.056530475616455,\n",
      "                                  1.0533956289291382,\n",
      "                                  1.0485328435897827,\n",
      "                                  1.0469626188278198,\n",
      "                                  1.0500261783599854]}},\n",
      "         3: {'accuracy': 32.84313725490196,\n",
      "             'history': {'accuracy': [0.494144082069397,\n",
      "                                      0.5009873509407043,\n",
      "                                      0.49942120909690857,\n",
      "                                      0.508851945400238,\n",
      "                                      0.500340461730957,\n",
      "                                      0.5044940710067749,\n",
      "                                      0.5013618469238281,\n",
      "                                      0.5020427703857422,\n",
      "                                      0.5071496367454529,\n",
      "                                      0.4998297691345215],\n",
      "                         'loss': [1.0932859182357788,\n",
      "                                  1.0618153810501099,\n",
      "                                  1.0567386150360107,\n",
      "                                  1.0567865371704102,\n",
      "                                  1.0562207698822021,\n",
      "                                  1.055873155593872,\n",
      "                                  1.0566128492355347,\n",
      "                                  1.0558558702468872,\n",
      "                                  1.0542396306991577,\n",
      "                                  1.055757999420166]}},\n",
      "         4: {'accuracy': 41.50326797385621,\n",
      "             'history': {'accuracy': [0.502178966999054,\n",
      "                                      0.5216532945632935,\n",
      "                                      0.5247514843940735,\n",
      "                                      0.524581253528595,\n",
      "                                      0.5232534408569336,\n",
      "                                      0.5195083618164062,\n",
      "                                      0.5182827115058899,\n",
      "                                      0.5190998315811157,\n",
      "                                      0.522504448890686,\n",
      "                                      0.519406259059906],\n",
      "                         'loss': [1.0978944301605225,\n",
      "                                  1.0519534349441528,\n",
      "                                  1.0533872842788696,\n",
      "                                  1.05220365524292,\n",
      "                                  1.048828125,\n",
      "                                  1.047671914100647,\n",
      "                                  1.0483800172805786,\n",
      "                                  1.0448380708694458,\n",
      "                                  1.0482600927352905,\n",
      "                                  1.0437771081924438]}},\n",
      "         5: {'accuracy': 38.834422657952075,\n",
      "             'history': {'accuracy': [0.49373552203178406,\n",
      "                                      0.5137205719947815,\n",
      "                                      0.5257047414779663,\n",
      "                                      0.5239343643188477,\n",
      "                                      0.5198488235473633,\n",
      "                                      0.528019905090332,\n",
      "                                      0.5187593698501587,\n",
      "                                      0.5232874751091003,\n",
      "                                      0.5166144371032715,\n",
      "                                      0.5223682522773743],\n",
      "                         'loss': [1.0997611284255981,\n",
      "                                  1.0618200302124023,\n",
      "                                  1.0550732612609863,\n",
      "                                  1.0542747974395752,\n",
      "                                  1.0523327589035034,\n",
      "                                  1.0499308109283447,\n",
      "                                  1.0513321161270142,\n",
      "                                  1.0469685792922974,\n",
      "                                  1.052321195602417,\n",
      "                                  1.0554383993148804]}}}}\n"
     ]
    }
   ],
   "source": [
    "pprint(Results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history[\"accuracy\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.45601851851851855"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = LSTMClassif.predict(X_test)\n",
    "y_pred = np.argmax(y_pred, axis = 1)\n",
    "accuracy_score(y_pred, y_test)\n",
    "# .45 - Correct RBM Size, 10 Iter\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m918/918\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - accuracy: 0.4580 - loss: 1.1095\n",
      "Epoch 2/100\n",
      "\u001b[1m918/918\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.5038 - loss: 1.0420\n",
      "Epoch 3/100\n",
      "\u001b[1m918/918\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.6517 - loss: 0.8817\n",
      "Epoch 4/100\n",
      "\u001b[1m688/918\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.8010 - loss: 0.5502"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mLSTMClassif\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# LSTMPipe.fit(X_train, y_train)\u001b[39;00m\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/scikeras/wrappers.py:1501\u001b[0m, in \u001b[0;36mKerasClassifier.fit\u001b[0;34m(self, X, y, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m     sample_weight \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m sample_weight\n\u001b[1;32m   1500\u001b[0m     sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(class_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_weight, y\u001b[38;5;241m=\u001b[39my)\n\u001b[0;32m-> 1501\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/scikeras/wrappers.py:770\u001b[0m, in \u001b[0;36mBaseWrapper.fit\u001b[0;34m(self, X, y, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m    765\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m    766\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit__epochs\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepochs)\n\u001b[1;32m    767\u001b[0m )\n\u001b[1;32m    768\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minitial_epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minitial_epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m--> 770\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    771\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    772\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    773\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    774\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwarm_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwarm_start\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    775\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    776\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    778\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/scikeras/wrappers.py:938\u001b[0m, in \u001b[0;36mBaseWrapper._fit\u001b[0;34m(self, X, y, sample_weight, warm_start, epochs, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    934\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_encoder_\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[1;32m    936\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_model_compatibility(y)\n\u001b[0;32m--> 938\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_keras_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    939\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    940\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    941\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    942\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwarm_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwarm_start\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/scikeras/wrappers.py:535\u001b[0m, in \u001b[0;36mBaseWrapper._fit_keras_model\u001b[0;34m(self, X, y, sample_weight, warm_start, epochs, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    533\u001b[0m         hist \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_\u001b[38;5;241m.\u001b[39mfit(x\u001b[38;5;241m=\u001b[39mX, y\u001b[38;5;241m=\u001b[39my, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_args)\n\u001b[1;32m    534\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 535\u001b[0m     hist \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m warm_start \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhistory_\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m initial_epoch \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhistory_ \u001b[38;5;241m=\u001b[39m defaultdict(\u001b[38;5;28mlist\u001b[39m)\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:314\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[1;32m    313\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 314\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    315\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[1;32m    316\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1500\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1498\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1500\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1501\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1503\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1504\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1505\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1506\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1508\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1509\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1510\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1514\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1515\u001b[0m   )\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "LSTMClassif.fit(X_train, y_train)\n",
    "# LSTMPipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 37ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "50.422113289760354"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y_pred = LSTMPipe.predict(X_test)\n",
    "y_pred = LSTMClassif.predict(X_test)\n",
    "accuracy_score(y_test, y_pred) * 100\n",
    "# LSTM Only = 89%\n",
    "# LSTM (10 epochs) + 1 RBM = 50.42"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

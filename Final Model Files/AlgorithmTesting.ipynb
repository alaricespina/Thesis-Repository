{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy Summary Table\n",
    "\n",
    "|      Base Setup     \t|     \t|     \t|     \t|         \t|            \t|     \t|     \t|     \t|         \t|\n",
    "|:-------------------:\t|-----\t|-----\t|-----\t|---------\t|------------\t|-----\t|-----\t|-----\t|---------\t|\n",
    "| SciKit              \t|  1  \t|  2  \t|  3  \t| Average \t| Tensorflow \t|  1  \t|  2  \t|  3  \t| Average \t|\n",
    "| K Nearest Neighbors \t| 100 \t| 100 \t| 100 \t|   100   \t| LSTM       \t| 100 \t| 100 \t| 100 \t|   100   \t|\n",
    "| Linear & RBF SVM    \t| 100 \t| 100 \t| 100 \t|   100   \t| GRU        \t| 100 \t| 100 \t| 100 \t|   100   \t|\n",
    "| QDA                 \t| 100 \t| 100 \t| 100 \t|   100   \t| Simple RNN \t| 100 \t| 100 \t| 100 \t|   100   \t|\n",
    "| Gaussian Process    \t| 100 \t| 100 \t| 100 \t|   100   \t| Bi LSTM    \t| 100 \t| 100 \t| 100 \t|   100   \t|\n",
    "| Decision Tree       \t| 100 \t| 100 \t| 100 \t|   100   \t| Bi GRU     \t| 100 \t| 100 \t| 100 \t|   100   \t|\n",
    "| Random Forest       \t| 100 \t| 100 \t| 100 \t|   100   \t| Bi RNN     \t| 100 \t| 100 \t| 100 \t|   100   \t|\n",
    "| Neural Net          \t| 100 \t| 100 \t| 100 \t|   100   \t| Dense      \t| 100 \t| 100 \t| 100 \t|   100   \t|\n",
    "| AdaBoost            \t| 100 \t| 100 \t| 100 \t|   100   \t|            \t|     \t|     \t|     \t|         \t|\n",
    "| Naive Bayes         \t| 100 \t| 100 \t| 100 \t|   100   \t|            \t|     \t|     \t|     \t|         \t|\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-01 13:21:51.388143: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-01 13:21:52.445203: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-01 13:21:55.150426: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-01 13:21:58.314462: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import tensorflow as tf \n",
    "import pickle \n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from tensorflow import keras \n",
    "from tensorflow.keras import layers \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError, MeanAbsoluteError\n",
    "from tensorflow.keras.losses import MeanSquaredError, MeanAbsoluteError\n",
    "from tensorflow.keras.optimizers import Adam \n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV \n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder, minmax_scale\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.neural_network import BernoulliRBM\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score, classification_report\n",
    "from sklearn.datasets import load_digits\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from scipy.ndimage import convolve\n",
    "\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "import collections \n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Noisy Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_filename = \"MXNWSS.csv\"\n",
    "df = pd.read_csv(csv_filename)\n",
    "\n",
    "window_length = 5 \n",
    "t_arr = df[\"value\"].to_numpy().reshape(-1, 1)\n",
    "SS = StandardScaler()\n",
    "\n",
    "t_arr = SS.fit_transform(t_arr).flatten()\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "# print(\"Rearranging Data\")\n",
    "for i in range(len(t_arr)-window_length):\n",
    "    t_row = []\n",
    "    for j in t_arr[i:i+window_length]:\n",
    "        t_row.append([j])\n",
    "    X.append(t_row)\n",
    "    y.append(t_arr[i + window_length])\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# print(X.shape, y.shape)\n",
    "\n",
    "X_train = X[:600]\n",
    "X_valid = X[:800]\n",
    "X_test = X[:1000]\n",
    "\n",
    "y_train = y[:600]\n",
    "y_valid = y[:800]\n",
    "y_test = y[:1000]\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "# X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size = 0.1)\n",
    "\n",
    "# print(X_train.shape, y_train.shape, X_test.shape, y_test.shape, X_valid.shape, y_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    layers.InputLayer((window_length, 1)),\n",
    "    layers.SimpleRNN(64, return_sequences=True),\n",
    "    layers.SimpleRNN(64),\n",
    "    layers.Dense(4),\n",
    "    layers.Dense(1)\n",
    "])\n",
    "\n",
    "# print(model.summary())\n",
    "\n",
    "cp = ModelCheckpoint(\"LSTMTestModel/\", save_best_only=True)\n",
    "model.compile(\n",
    "    loss = MeanSquaredError(),\n",
    "    optimizer = Adam(learning_rate=0.0001),\n",
    "    metrics = [RootMeanSquaredError()]\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    epochs = 10,\n",
    "    callbacks = [cp],\n",
    "    verbose = 2\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history[\"loss\"], label=\"Loss\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"Val Loss\")\n",
    "plt.plot(history.history[\"root_mean_squared_error\"], label=\"RMSE\")\n",
    "plt.plot(history.history[\"val_root_mean_squared_error\"], label=\"Val RMSE\")\n",
    "plt.title(\"Training History\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "view_length = 100\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(SS.inverse_transform(model.predict(X_test))[:view_length], label=\"Model Output\")\n",
    "plt.plot(y_test[:view_length], label=\"Actual\")\n",
    "plt.title(\"Viewing Predictions\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RBM Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1293, 64) (144, 64) (360, 64) (1293,) (144,) (360,)\n",
      "Accuracy 0.6583333333333333\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X, y = load_digits(return_X_y = True)\n",
    "\n",
    "# X = np.asarray(X, \"float32\")\n",
    "# X = minmax_scale(X, feature_range=(0, 1))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size = 0.1, random_state = 0)\n",
    "\n",
    "print(X_train.shape, X_valid.shape, X_test.shape, y_train.shape, y_valid.shape, y_test.shape)\n",
    "\n",
    "# (\"random forest\", RandomForestClassifier()),\n",
    "# (\"ada boost\", AdaBoostClassifier()),   \n",
    "# (\"gaussian process\", GaussianProcessClassifier()),\n",
    "# (\"decision tree\", DecisionTreeClassifier()),\n",
    "# (\"mlp\", MLPClassifier()),\n",
    "# (\"svm\", SVC())\n",
    "\n",
    "# print(\"Before RBM: \", X_train[0])\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"mms1\", MinMaxScaler()),\n",
    "    (\"rbm1\", BernoulliRBM(n_components=640, learning_rate = 0.1, n_iter = 100, verbose = False, random_state = 0)),\n",
    "    (\"mms2\", MinMaxScaler()),\n",
    "    (\"rbm2\", BernoulliRBM(n_components=640, learning_rate = 0.1, n_iter = 100, verbose = False, random_state = 0)),\n",
    "    (\"mms3\", MinMaxScaler()),\n",
    "    (\"rbm3\", BernoulliRBM(n_components=640, learning_rate = 0.1, n_iter = 100, verbose = False, random_state = 0)),\n",
    "    (\"mms4\", MinMaxScaler()),\n",
    "    (\"rbm4\", BernoulliRBM(n_components=640, learning_rate = 0.1, n_iter = 100, verbose = False, random_state = 0)),\n",
    "    (\"mms5\", MinMaxScaler()),\n",
    "    (\"rbm5\", BernoulliRBM(n_components=640, learning_rate = 0.1, n_iter = 100, verbose = False, random_state = 0)),\n",
    "    (\"final_classifier\", RandomForestClassifier(random_state = 0))\n",
    "])\n",
    "# print(\"After RBM: \",X_train[0])\n",
    "pipe.fit(X_train, y_train)\n",
    "y_pred = pipe.predict(X_test)\n",
    "\n",
    "print(\"Accuracy\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "r_cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix = r_cm)\n",
    "\n",
    "disp.plot()\n",
    "plt.show()\n",
    "\n",
    "# .91, .90, .91 -128, 10\n",
    "# .89, .88, .90 -256, 10\n",
    "# .93, .91, .90 -64, 10\n",
    "# .89, .89, .92 -32, 10\n",
    "# .85, .85, .85 -64, 64, (10)\n",
    "# .86, .86, .86 -64, 64, (10)\n",
    "# .88, .91, .87 -64, 64, (10, 20)\n",
    "# .91, .91,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SciKit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1309/2226633099.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  raw_dataset[\"conditions\"] = [word.replace(\", \", \"\\n\") if (\",\" in word) else word for word in raw_dataset[\"conditions\"]]\n",
      "/tmp/ipykernel_1309/2226633099.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  raw_dataset[\"conditions\"] =  LE.fit_transform(raw_dataset[\"conditions\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29372, 25) (7344, 25) (29372,) (7344,)\n"
     ]
    }
   ],
   "source": [
    "FULL_DATA = False \n",
    "LE = LabelEncoder()\n",
    "WINDOW_LENGTH = 5\n",
    "ADD_ELEMENTS = True\n",
    "\n",
    "\n",
    "concatenated_data = pd.read_csv(\"Concatenated Data.csv\")\n",
    "\n",
    "if FULL_DATA:\n",
    "    raw_dataset = concatenated_data[[\"tempmax\", \"tempmin\", \"temp\", \"feelslikemax\", \"feelslikemin\", \"feelslike\", \"dew\", \"humidity\", \"windspeed\", \"sealevelpressure\", \"conditions\"]]\n",
    "else:\n",
    "    raw_dataset = concatenated_data[[\"temp\", \"feelslike\", \"humidity\", \"windspeed\", \"sealevelpressure\", \"conditions\"]]\n",
    "\n",
    "raw_dataset[\"conditions\"] = [word.replace(\", \", \"\\n\") if (\",\" in word) else word for word in raw_dataset[\"conditions\"]]\n",
    "raw_dataset[\"conditions\"] =  LE.fit_transform(raw_dataset[\"conditions\"])\n",
    "\n",
    "t_arr = raw_dataset.copy().to_numpy()\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for i in range(len(t_arr) - WINDOW_LENGTH):\n",
    "    t_row = []\n",
    "    for j in t_arr[i : i + WINDOW_LENGTH]:\n",
    "        t_row.append(j[:-1])\n",
    "    t_row = np.array(t_row).flatten()\n",
    "    X.append(t_row)\n",
    "    y.append(t_arr[i + WINDOW_LENGTH][-1])\n",
    "\n",
    "X = np.array(X, \"float32\")\n",
    "X = minmax_scale(X, feature_range=(0, 1))\n",
    "y = np.array(y)\n",
    "\n",
    "counts = dict(collections.Counter(y))\n",
    "max_count = max(counts.values())\n",
    "\n",
    "if ADD_ELEMENTS:\n",
    "    for key, value in counts.items():\n",
    "        curX = []\n",
    "        curY = []\n",
    "        li, = np.where(y == key)\n",
    "        for i in range((max_count - value) * 10):\n",
    "            ci = random.choice(li)\n",
    "            curX.append(X[ci])\n",
    "            curY.append(y[ci])\n",
    "        tX = X.tolist()\n",
    "        tY = y.tolist()\n",
    "        tX.extend(curX)\n",
    "        tY.extend(curY)\n",
    "        X = np.array(tX)\n",
    "        y = np.array(tY)        \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN\tConstant\tLayer: 0\tAccuracy: 95.7107843137255\n",
      "KNN\tIncreasing\tLayer: 0\tAccuracy: 95.7107843137255\n",
      "KNN\tDecreasing\tLayer: 0\tAccuracy: 95.7107843137255\n",
      "KNN\tConstant\tLayer: 1\tAccuracy: 95.7107843137255\n",
      "KNN\tIncreasing\tLayer: 1\tAccuracy: 95.7107843137255\n",
      "KNN\tDecreasing\tLayer: 1\tAccuracy: 95.7107843137255\n",
      "KNN\tConstant\tLayer: 2\tAccuracy: 94.8937908496732\n",
      "KNN\tIncreasing\tLayer: 2\tAccuracy: 94.880174291939\n",
      "KNN\tDecreasing\tLayer: 2\tAccuracy: 94.66230936819173\n",
      "KNN\tConstant\tLayer: 3\tAccuracy: 94.71677559912854\n",
      "KNN\tIncreasing\tLayer: 3\tAccuracy: 94.83932461873638\n",
      "KNN\tDecreasing\tLayer: 3\tAccuracy: 94.49891067538127\n",
      "KNN\tConstant\tLayer: 4\tAccuracy: 94.36274509803921\n",
      "KNN\tIncreasing\tLayer: 4\tAccuracy: 94.28104575163398\n",
      "KNN\tDecreasing\tLayer: 4\tAccuracy: 94.18572984749454\n",
      "RBF SVM\tConstant\tLayer: 0\tAccuracy: 90.19607843137256\n",
      "RBF SVM\tIncreasing\tLayer: 0\tAccuracy: 90.19607843137256\n",
      "RBF SVM\tDecreasing\tLayer: 0\tAccuracy: 90.19607843137256\n",
      "RBF SVM\tConstant\tLayer: 1\tAccuracy: 90.19607843137256\n",
      "RBF SVM\tIncreasing\tLayer: 1\tAccuracy: 90.19607843137256\n",
      "RBF SVM\tDecreasing\tLayer: 1\tAccuracy: 90.19607843137256\n",
      "RBF SVM\tConstant\tLayer: 2\tAccuracy: 58.755446623093675\n",
      "RBF SVM\tIncreasing\tLayer: 2\tAccuracy: 53.567538126361654\n",
      "RBF SVM\tDecreasing\tLayer: 2\tAccuracy: 53.05010893246187\n",
      "RBF SVM\tConstant\tLayer: 3\tAccuracy: 53.1318082788671\n",
      "RBF SVM\tIncreasing\tLayer: 3\tAccuracy: 54.34368191721133\n",
      "RBF SVM\tDecreasing\tLayer: 3\tAccuracy: 52.57352941176471\n",
      "RBF SVM\tConstant\tLayer: 4\tAccuracy: 56.25\n",
      "RBF SVM\tIncreasing\tLayer: 4\tAccuracy: 55.43300653594771\n",
      "RBF SVM\tDecreasing\tLayer: 4\tAccuracy: 56.33169934640523\n",
      "LINEAR SVM\tConstant\tLayer: 0\tAccuracy: 82.35294117647058\n",
      "LINEAR SVM\tIncreasing\tLayer: 0\tAccuracy: 82.35294117647058\n",
      "LINEAR SVM\tDecreasing\tLayer: 0\tAccuracy: 82.35294117647058\n",
      "LINEAR SVM\tConstant\tLayer: 1\tAccuracy: 82.35294117647058\n",
      "LINEAR SVM\tIncreasing\tLayer: 1\tAccuracy: 82.35294117647058\n",
      "LINEAR SVM\tDecreasing\tLayer: 1\tAccuracy: 82.35294117647058\n",
      "LINEAR SVM\tConstant\tLayer: 2\tAccuracy: 55.378540305010894\n",
      "LINEAR SVM\tIncreasing\tLayer: 2\tAccuracy: 53.6900871459695\n",
      "LINEAR SVM\tDecreasing\tLayer: 2\tAccuracy: 52.900326797385624\n",
      "LINEAR SVM\tConstant\tLayer: 3\tAccuracy: 53.24074074074075\n",
      "LINEAR SVM\tIncreasing\tLayer: 3\tAccuracy: 50.54466230936819\n",
      "LINEAR SVM\tDecreasing\tLayer: 3\tAccuracy: 52.2739651416122\n",
      "LINEAR SVM\tConstant\tLayer: 4\tAccuracy: 53.85348583877996\n",
      "LINEAR SVM\tIncreasing\tLayer: 4\tAccuracy: 54.643246187363836\n",
      "LINEAR SVM\tDecreasing\tLayer: 4\tAccuracy: 53.58115468409586\n",
      "DECISION TREE\tConstant\tLayer: 0\tAccuracy: 97.35838779956427\n",
      "DECISION TREE\tIncreasing\tLayer: 0\tAccuracy: 97.4673202614379\n",
      "DECISION TREE\tDecreasing\tLayer: 0\tAccuracy: 97.4400871459695\n",
      "DECISION TREE\tConstant\tLayer: 1\tAccuracy: 97.39923747276688\n",
      "DECISION TREE\tIncreasing\tLayer: 1\tAccuracy: 97.4400871459695\n",
      "DECISION TREE\tDecreasing\tLayer: 1\tAccuracy: 97.31753812636165\n",
      "DECISION TREE\tConstant\tLayer: 2\tAccuracy: 97.4400871459695\n",
      "DECISION TREE\tIncreasing\tLayer: 2\tAccuracy: 97.42647058823529\n",
      "DECISION TREE\tDecreasing\tLayer: 2\tAccuracy: 97.49455337690632\n",
      "DECISION TREE\tConstant\tLayer: 3\tAccuracy: 96.97712418300654\n",
      "DECISION TREE\tIncreasing\tLayer: 3\tAccuracy: 96.99074074074075\n",
      "DECISION TREE\tDecreasing\tLayer: 3\tAccuracy: 97.30392156862744\n",
      "DECISION TREE\tConstant\tLayer: 4\tAccuracy: 97.1541394335512\n",
      "DECISION TREE\tIncreasing\tLayer: 4\tAccuracy: 97.1541394335512\n",
      "DECISION TREE\tDecreasing\tLayer: 4\tAccuracy: 97.20860566448802\n",
      "RANDOM FOREST\tConstant\tLayer: 0\tAccuracy: 98.0119825708061\n",
      "RANDOM FOREST\tIncreasing\tLayer: 0\tAccuracy: 98.06644880174292\n",
      "RANDOM FOREST\tDecreasing\tLayer: 0\tAccuracy: 97.97113289760348\n",
      "RANDOM FOREST\tConstant\tLayer: 1\tAccuracy: 98.08006535947712\n",
      "RANDOM FOREST\tIncreasing\tLayer: 1\tAccuracy: 97.94389978213508\n",
      "RANDOM FOREST\tDecreasing\tLayer: 1\tAccuracy: 97.91666666666666\n",
      "RANDOM FOREST\tConstant\tLayer: 2\tAccuracy: 97.37200435729847\n",
      "RANDOM FOREST\tIncreasing\tLayer: 2\tAccuracy: 97.03159041394336\n",
      "RANDOM FOREST\tDecreasing\tLayer: 2\tAccuracy: 96.82734204793029\n",
      "RANDOM FOREST\tConstant\tLayer: 3\tAccuracy: 97.07244008714598\n",
      "RANDOM FOREST\tIncreasing\tLayer: 3\tAccuracy: 97.07244008714598\n",
      "RANDOM FOREST\tDecreasing\tLayer: 3\tAccuracy: 96.75925925925925\n",
      "RANDOM FOREST\tConstant\tLayer: 4\tAccuracy: 97.05882352941177\n",
      "RANDOM FOREST\tIncreasing\tLayer: 4\tAccuracy: 97.26307189542483\n",
      "RANDOM FOREST\tDecreasing\tLayer: 4\tAccuracy: 97.1132897603486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP\tConstant\tLayer: 0\tAccuracy: 93.34150326797386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP\tIncreasing\tLayer: 0\tAccuracy: 92.97385620915033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP\tDecreasing\tLayer: 0\tAccuracy: 92.18409586056644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP\tConstant\tLayer: 1\tAccuracy: 92.66067538126362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP\tIncreasing\tLayer: 1\tAccuracy: 92.26579520697167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP\tDecreasing\tLayer: 1\tAccuracy: 91.24455337690632\n",
      "MLP\tConstant\tLayer: 2\tAccuracy: 53.78540305010894\n",
      "MLP\tIncreasing\tLayer: 2\tAccuracy: 53.649237472766885\n",
      "MLP\tDecreasing\tLayer: 2\tAccuracy: 51.53867102396514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP\tConstant\tLayer: 3\tAccuracy: 56.91721132897604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP\tIncreasing\tLayer: 3\tAccuracy: 58.10185185185185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP\tDecreasing\tLayer: 3\tAccuracy: 60.811546840958606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP\tConstant\tLayer: 4\tAccuracy: 54.79302832244009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP\tIncreasing\tLayer: 4\tAccuracy: 62.79956427015251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP\tDecreasing\tLayer: 4\tAccuracy: 56.94444444444444\n",
      "ADA BOOST\tConstant\tLayer: 0\tAccuracy: 80.66448801742919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADA BOOST\tIncreasing\tLayer: 0\tAccuracy: 80.66448801742919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADA BOOST\tDecreasing\tLayer: 0\tAccuracy: 80.66448801742919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADA BOOST\tConstant\tLayer: 1\tAccuracy: 80.66448801742919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADA BOOST\tIncreasing\tLayer: 1\tAccuracy: 80.66448801742919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADA BOOST\tDecreasing\tLayer: 1\tAccuracy: 80.66448801742919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADA BOOST\tConstant\tLayer: 2\tAccuracy: 73.0255991285403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADA BOOST\tIncreasing\tLayer: 2\tAccuracy: 74.31917211328975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADA BOOST\tDecreasing\tLayer: 2\tAccuracy: 73.39324618736384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADA BOOST\tConstant\tLayer: 3\tAccuracy: 77.01525054466231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADA BOOST\tIncreasing\tLayer: 3\tAccuracy: 69.93464052287581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADA BOOST\tDecreasing\tLayer: 3\tAccuracy: 69.24019607843137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADA BOOST\tConstant\tLayer: 4\tAccuracy: 75.2995642701525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADA BOOST\tIncreasing\tLayer: 4\tAccuracy: 76.19825708061002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADA BOOST\tDecreasing\tLayer: 4\tAccuracy: 78.56753812636165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOGISTIC\tConstant\tLayer: 0\tAccuracy: 76.52505446623094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOGISTIC\tIncreasing\tLayer: 0\tAccuracy: 76.52505446623094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOGISTIC\tDecreasing\tLayer: 0\tAccuracy: 76.52505446623094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOGISTIC\tConstant\tLayer: 1\tAccuracy: 76.52505446623094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOGISTIC\tIncreasing\tLayer: 1\tAccuracy: 76.52505446623094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOGISTIC\tDecreasing\tLayer: 1\tAccuracy: 76.52505446623094\n",
      "LOGISTIC\tConstant\tLayer: 2\tAccuracy: 53.96241830065359\n",
      "LOGISTIC\tIncreasing\tLayer: 2\tAccuracy: 54.180283224400874\n",
      "LOGISTIC\tDecreasing\tLayer: 2\tAccuracy: 52.65522875816993\n",
      "LOGISTIC\tConstant\tLayer: 3\tAccuracy: 53.649237472766885\n",
      "LOGISTIC\tIncreasing\tLayer: 3\tAccuracy: 53.635620915032675\n",
      "LOGISTIC\tDecreasing\tLayer: 3\tAccuracy: 54.20751633986928\n",
      "LOGISTIC\tConstant\tLayer: 4\tAccuracy: 51.06209150326797\n",
      "LOGISTIC\tIncreasing\tLayer: 4\tAccuracy: 49.78213507625273\n",
      "LOGISTIC\tDecreasing\tLayer: 4\tAccuracy: 55.54193899782135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n"
     ]
    }
   ],
   "source": [
    "classifiers = [\n",
    "    (\"KNN\", KNeighborsClassifier()),\n",
    "    (\"RBF SVM\", SVC()),\n",
    "    (\"LINEAR SVM\", SVC(kernel = \"linear\")),\n",
    "    (\"DECISION TREE\", DecisionTreeClassifier()),\n",
    "    (\"RANDOM FOREST\", RandomForestClassifier()),\n",
    "    (\"MLP\", MLPClassifier()),\n",
    "    (\"ADA BOOST\", AdaBoostClassifier()),    \n",
    "    (\"LOGISTIC\", LogisticRegression())\n",
    "]\n",
    "\n",
    "Results = {}\n",
    "for name, _ in classifiers:\n",
    "    Results[name] = {\n",
    "        \"CONSTANT\" : {\n",
    "\n",
    "        },\n",
    "        \"INCREASING\" : {\n",
    "\n",
    "        },\n",
    "        \"DECREASING\" : {\n",
    "\n",
    "        }\n",
    "    }\n",
    "\n",
    "for (name, _clf) in classifiers:\n",
    "\n",
    "    for rbm_layer in range(0, 5):\n",
    "        comb = []\n",
    "\n",
    "        # Constant\n",
    "        for j in range(1, rbm_layer):\n",
    "            comb.append((f\"mms{j}\", MinMaxScaler()))\n",
    "            comb.append((f\"rbm{j}\", BernoulliRBM(n_components = X_train.shape[1], learning_rate = 0.01, n_iter = 10, verbose = 0)))\n",
    "\n",
    "        comb.append((name, _clf))\n",
    "        predictor = Pipeline(comb)\n",
    "\n",
    "        predictor.fit(X_train, y_train)\n",
    "        y_pred = predictor.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred) * 100\n",
    "        Results[name][\"CONSTANT\"][rbm_layer] = accuracy\n",
    "        print(f\"{name}\\tConstant\\tLayer: {rbm_layer}\\tAccuracy: {accuracy}\")\n",
    "        \n",
    "        # Increasing\n",
    "        comb = []\n",
    "        for j in range(1, rbm_layer):\n",
    "            comb.append((f\"mms{j}\", MinMaxScaler()))\n",
    "            comb.append((f\"rbm{j}\", BernoulliRBM(n_components = X_train.shape[1] * j, learning_rate = 0.01, n_iter = 10, verbose = 0)))\n",
    "\n",
    "        comb.append((name, _clf))\n",
    "        predictor = Pipeline(comb)\n",
    "\n",
    "        predictor.fit(X_train, y_train)\n",
    "        y_pred = predictor.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred) * 100\n",
    "        Results[name][\"INCREASING\"][rbm_layer] = accuracy\n",
    "        print(f\"{name}\\tIncreasing\\tLayer: {rbm_layer}\\tAccuracy: {accuracy}\")\n",
    "\n",
    "        # Decreasing\n",
    "        comb = []\n",
    "        for j in range(1, rbm_layer):\n",
    "            comb.append((f\"mms{j}\", MinMaxScaler()))\n",
    "            comb.append((f\"rbm{j}\", BernoulliRBM(n_components = X_train.shape[1] * rbm_layer - j, learning_rate = 0.01, n_iter = 10, verbose = 0)))\n",
    "\n",
    "        comb.append((name, _clf))\n",
    "        predictor = Pipeline(comb)\n",
    "\n",
    "        predictor.fit(X_train, y_train)\n",
    "        y_pred = predictor.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred) * 100\n",
    "        Results[name][\"DECREASING\"][rbm_layer] = accuracy\n",
    "        print(f\"{name}\\tDecreasing\\tLayer: {rbm_layer}\\tAccuracy: {accuracy}\")\n",
    "\n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "# predictor.fit(X_train, y_train)\n",
    "# y_pred = predictor.predict(X_test)\n",
    "\n",
    "# pipe.fit(X_train, y_train)\n",
    "\n",
    "# y_pred = pipe.predict(X_test)\n",
    "# r_cm = confusion_matrix(y_test, y_pred)\n",
    "# disp = ConfusionMatrixDisplay(confusion_matrix = r_cm, display_labels = LE.classes_)\n",
    "\n",
    "with open(\"SciKitAccuracySaves.pkl\", \"wb\") as f:\n",
    "    pickle.dump(Results, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BuildGenericModel(input_dimension, output_dimension, layerType, Kernel_Count = 64, Layer_Count = 2, Dense_Flag = False, Bidirectional_Flag = False):\n",
    "    PredictorModel = Sequential()\n",
    "    PredictorModel.add(layers.InputLayer((input_dimension, 1)))\n",
    "\n",
    "    if Dense_Flag:\n",
    "        # No Return Sequences for Dense Layer\n",
    "        for i in range(1, Layer_Count):\n",
    "            PredictorModel.add(layerType(Kernel_Count))\n",
    "\n",
    "        # Final Layer\n",
    "        PredictorModel.add(layerType(Kernel_Count))\n",
    "        \n",
    "    elif Bidirectional_Flag:\n",
    "        # Return Sequences (Only Adds if More than 1 Layers)\n",
    "        for i in range(1, Layer_Count):\n",
    "            PredictorModel.add(layerType)\n",
    "\n",
    "        # Add a Final SimpleRNN Layer at End of Bidirectional Layers\n",
    "        PredictorModel.add(layers.SimpleRNN(Kernel_Count))\n",
    "\n",
    "    else:\n",
    "        # Return Sequences (Only Adds if More than 1 Layers)\n",
    "        for i in range(1, Layer_Count):\n",
    "            PredictorModel.add(layerType(Kernel_Count, return_sequences = True))\n",
    "        \n",
    "        # Final Layer\n",
    "        PredictorModel.add(layerType(Kernel_Count))\n",
    "\n",
    "    # Flatten Layer\n",
    "    PredictorModel.add(layers.Flatten()) \n",
    "\n",
    "    # Output Dimension\n",
    "    PredictorModel.add(layers.Dense(output_dimension, activation = \"softmax\"))\n",
    "\n",
    "    # Compile Model\n",
    "    PredictorModel.compile(loss = \"categorical_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])\n",
    "\n",
    "    return PredictorModel\n",
    "\n",
    "def buildModels(X_train_shape, Y_train_shape, Kernel = 64, Layer_Count = 2):\n",
    "    LSTMModel = BuildGenericModel(X_train_shape[1], Y_train_shape[1], layers.LSTM, Kernel, Layer_Count)\n",
    "    GRUModel = BuildGenericModel(X_train_shape[1], Y_train_shape[1], layers.GRU, Kernel, Layer_Count)\n",
    "    SimpleRNNModel = BuildGenericModel(X_train_shape[1], Y_train_shape[1], layers.SimpleRNN, Kernel, Layer_Count)\n",
    "    BiLSTMModel = BuildGenericModel(X_train_shape[1], Y_train_shape[1], layers.Bidirectional(layers.LSTM(Kernel, return_sequences = True)), Kernel, Layer_Count, Bidirectional_Flag = True)\n",
    "    BiGRUModel = BuildGenericModel(X_train_shape[1], Y_train_shape[1], layers.Bidirectional(layers.GRU(Kernel, return_sequences = True)), Kernel, Layer_Count, Bidirectional_Flag = True)\n",
    "    BiSimpleRNNModel = BuildGenericModel(X_train_shape[1], Y_train_shape[1], layers.Bidirectional(layers.SimpleRNN(Kernel, return_sequences = True)), Kernel, Layer_Count, Bidirectional_Flag = True)\n",
    "    DenseModel = BuildGenericModel(X_train_shape[1], Y_train_shape[1], layers.Dense, Kernel, Layer_Count, Dense_Flag = True)\n",
    "\n",
    "    return (LSTMModel, GRUModel, SimpleRNNModel, BiLSTMModel, BiGRUModel, BiSimpleRNNModel, DenseModel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tf_X_train = minmax_scale(X_train, feature_range = (0, 1))\n",
    "tf_X_test = minmax_scale(X_test, feature_range = (0, 1))\n",
    "\n",
    "tf_y_train = to_categorical(y_train)\n",
    "tf_y_test = to_categorical(y_test)\n",
    "\n",
    "LSTM_Predictor, GRU_Predictor, RNN_Predictor, Bi_LSTM_Predictor, Bi_GRU_Predictor, Bi_RNN_Predictor, Dense_Predictor = buildModels(tf_X_train.shape, tf_y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_EPOCHS = 20\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "classifiers = [\n",
    "    (\"LSTM\", LSTM_Predictor), \n",
    "    (\"GRU\", GRU_Predictor), \n",
    "    (\"RNN\", RNN_Predictor), \n",
    "    (\"BI LSTM\", Bi_LSTM_Predictor), \n",
    "    (\"BI GRU\", Bi_GRU_Predictor), \n",
    "    (\"BI RNN\", Bi_RNN_Predictor), \n",
    "    (\"DENSE\", Dense_Predictor)\n",
    "]\n",
    "\n",
    "Results = {}\n",
    "for name, _ in classifiers:\n",
    "    Results[name] = {\n",
    "        \"CONSTANT\" : {\n",
    "\n",
    "        },\n",
    "        \"INCREASING\" : {\n",
    "\n",
    "        },\n",
    "        \"DECREASING\" : {\n",
    "\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 9ms/step - accuracy: 0.4888 - loss: 1.0707\n",
      "Epoch 2/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.8509 - loss: 0.4137\n",
      "Epoch 3/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.8819 - loss: 0.3093\n",
      "Epoch 4/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.8961 - loss: 0.2747\n",
      "Epoch 5/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - accuracy: 0.9117 - loss: 0.2396\n",
      "Epoch 6/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.9198 - loss: 0.2206\n",
      "Epoch 7/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.9306 - loss: 0.1924\n",
      "Epoch 8/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.9427 - loss: 0.1568\n",
      "Epoch 9/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.9462 - loss: 0.1459\n",
      "Epoch 10/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.9510 - loss: 0.1349\n",
      "Epoch 11/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.9501 - loss: 0.1304\n",
      "Epoch 12/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.9550 - loss: 0.1173\n",
      "Epoch 13/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.9524 - loss: 0.1256\n",
      "Epoch 14/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.9580 - loss: 0.1083\n",
      "Epoch 15/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - accuracy: 0.9619 - loss: 0.0980\n",
      "Epoch 16/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.9576 - loss: 0.1162\n",
      "Epoch 17/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.9599 - loss: 0.1041\n",
      "Epoch 18/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.9617 - loss: 0.0965\n",
      "Epoch 19/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.9643 - loss: 0.0903\n",
      "Epoch 20/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.9644 - loss: 0.0900\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "LSTM\tConstant\tLayer: 0\tAccuracy: 70.31590413943356\n",
      "Epoch 1/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - accuracy: 0.4675 - loss: 1.0976\n",
      "Epoch 2/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.7482 - loss: 0.6744\n",
      "Epoch 3/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.8629 - loss: 0.3708\n",
      "Epoch 4/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.8791 - loss: 0.3187\n",
      "Epoch 5/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.8909 - loss: 0.2927\n",
      "Epoch 6/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.8894 - loss: 0.3022\n",
      "Epoch 7/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.9058 - loss: 0.2652\n",
      "Epoch 8/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.9154 - loss: 0.2380\n",
      "Epoch 9/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.9215 - loss: 0.2196\n",
      "Epoch 10/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.9239 - loss: 0.2065\n",
      "Epoch 11/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.9343 - loss: 0.1865\n",
      "Epoch 12/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.9341 - loss: 0.1880\n",
      "Epoch 13/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.9368 - loss: 0.1725\n",
      "Epoch 14/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.9458 - loss: 0.1469\n",
      "Epoch 15/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.9385 - loss: 0.1698\n",
      "Epoch 16/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.9540 - loss: 0.1285\n",
      "Epoch 17/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.9547 - loss: 0.1246\n",
      "Epoch 18/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.9539 - loss: 0.1255\n",
      "Epoch 19/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.9564 - loss: 0.1148\n",
      "Epoch 20/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.9575 - loss: 0.1140\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
      "LSTM\tINCREASING\tLayer: 0\tAccuracy: 77.72331154684096\n",
      "Epoch 1/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 9ms/step - accuracy: 0.4589 - loss: 1.1049\n",
      "Epoch 2/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.5760 - loss: 0.9423\n",
      "Epoch 3/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.8625 - loss: 0.3629\n",
      "Epoch 4/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 9ms/step - accuracy: 0.8846 - loss: 0.2998\n",
      "Epoch 5/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 9ms/step - accuracy: 0.8953 - loss: 0.2918\n",
      "Epoch 6/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 9ms/step - accuracy: 0.9117 - loss: 0.2453\n",
      "Epoch 7/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 9ms/step - accuracy: 0.9225 - loss: 0.2181\n",
      "Epoch 8/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 9ms/step - accuracy: 0.9318 - loss: 0.1923\n",
      "Epoch 9/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 9ms/step - accuracy: 0.9401 - loss: 0.1630\n",
      "Epoch 10/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 9ms/step - accuracy: 0.9438 - loss: 0.1493\n",
      "Epoch 11/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 9ms/step - accuracy: 0.9487 - loss: 0.1358\n",
      "Epoch 12/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 9ms/step - accuracy: 0.9489 - loss: 0.1339\n",
      "Epoch 13/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 9ms/step - accuracy: 0.9479 - loss: 0.1483\n",
      "Epoch 14/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 9ms/step - accuracy: 0.9533 - loss: 0.1206\n",
      "Epoch 15/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 9ms/step - accuracy: 0.9600 - loss: 0.1056\n",
      "Epoch 16/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 9ms/step - accuracy: 0.9574 - loss: 0.1154\n",
      "Epoch 17/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 9ms/step - accuracy: 0.9505 - loss: 0.1346\n",
      "Epoch 18/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 9ms/step - accuracy: 0.9603 - loss: 0.1001\n",
      "Epoch 19/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 9ms/step - accuracy: 0.9635 - loss: 0.0910\n",
      "Epoch 20/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 9ms/step - accuracy: 0.9631 - loss: 0.0920\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
      "LSTM\tDECREASING\tLayer: 0\tAccuracy: 84.81753812636165\n",
      "Epoch 1/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 9ms/step - accuracy: 0.4528 - loss: 1.1139\n",
      "Epoch 2/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.5134 - loss: 1.0345\n",
      "Epoch 3/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.6097 - loss: 0.9144\n",
      "Epoch 4/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.8144 - loss: 0.5395\n",
      "Epoch 5/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.8436 - loss: 0.4357\n",
      "Epoch 6/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.8852 - loss: 0.3200\n",
      "Epoch 7/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.8933 - loss: 0.2917\n",
      "Epoch 8/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - accuracy: 0.8978 - loss: 0.2857\n",
      "Epoch 9/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.9179 - loss: 0.2283\n",
      "Epoch 10/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.9261 - loss: 0.2053\n",
      "Epoch 11/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.9327 - loss: 0.1810\n",
      "Epoch 12/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.9425 - loss: 0.1582\n",
      "Epoch 13/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.9445 - loss: 0.1525\n",
      "Epoch 14/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.9473 - loss: 0.1398\n",
      "Epoch 15/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.9510 - loss: 0.1308\n",
      "Epoch 16/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.9550 - loss: 0.1169\n",
      "Epoch 17/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.9535 - loss: 0.1226\n",
      "Epoch 18/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.9525 - loss: 0.1205\n",
      "Epoch 19/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.9579 - loss: 0.1088\n",
      "Epoch 20/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.9573 - loss: 0.1095\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
      "LSTM\tConstant\tLayer: 1\tAccuracy: 73.22984749455338\n",
      "Epoch 1/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 9ms/step - accuracy: 0.4772 - loss: 1.0991\n",
      "Epoch 2/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.8378 - loss: 0.4754\n",
      "Epoch 3/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.8752 - loss: 0.3290\n",
      "Epoch 4/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.8736 - loss: 0.3315\n",
      "Epoch 5/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.8912 - loss: 0.2792\n",
      "Epoch 6/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.8963 - loss: 0.2629\n",
      "Epoch 7/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.9114 - loss: 0.2418\n",
      "Epoch 8/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.9073 - loss: 0.2546\n",
      "Epoch 9/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.9298 - loss: 0.2011\n",
      "Epoch 10/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.9361 - loss: 0.1769\n",
      "Epoch 11/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.9400 - loss: 0.1635\n",
      "Epoch 12/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.9431 - loss: 0.1589\n",
      "Epoch 13/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.9482 - loss: 0.1409\n",
      "Epoch 14/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.9512 - loss: 0.1323\n",
      "Epoch 15/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.9496 - loss: 0.1375\n",
      "Epoch 16/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.9602 - loss: 0.1063\n",
      "Epoch 17/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.9615 - loss: 0.1024\n",
      "Epoch 18/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.9611 - loss: 0.1004\n",
      "Epoch 19/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.9565 - loss: 0.1127\n",
      "Epoch 20/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.9573 - loss: 0.1112\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "LSTM\tINCREASING\tLayer: 1\tAccuracy: 78.9488017429194\n",
      "Epoch 1/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 9ms/step - accuracy: 0.4597 - loss: 1.1085\n",
      "Epoch 2/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.6339 - loss: 0.8789\n",
      "Epoch 3/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.8727 - loss: 0.3504\n",
      "Epoch 4/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.8840 - loss: 0.3151\n",
      "Epoch 5/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.8934 - loss: 0.2863\n",
      "Epoch 6/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.9142 - loss: 0.2351\n",
      "Epoch 7/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.9260 - loss: 0.2010\n",
      "Epoch 8/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - accuracy: 0.9341 - loss: 0.1810\n",
      "Epoch 9/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.9447 - loss: 0.1563\n",
      "Epoch 10/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.9517 - loss: 0.1325\n",
      "Epoch 11/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.9521 - loss: 0.1309\n",
      "Epoch 12/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.9545 - loss: 0.1178\n",
      "Epoch 13/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.9555 - loss: 0.1146\n",
      "Epoch 14/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.9608 - loss: 0.1018\n",
      "Epoch 15/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.9551 - loss: 0.1144\n",
      "Epoch 16/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.9595 - loss: 0.1047\n",
      "Epoch 17/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.9642 - loss: 0.0913\n",
      "Epoch 18/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.9603 - loss: 0.1028\n",
      "Epoch 19/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.9608 - loss: 0.1002\n",
      "Epoch 20/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.9639 - loss: 0.0892\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "LSTM\tDECREASING\tLayer: 1\tAccuracy: 73.5702614379085\n",
      "Epoch 1/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 9ms/step - accuracy: 0.4505 - loss: 1.1157\n",
      "Epoch 2/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.5199 - loss: 1.0608\n",
      "Epoch 3/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.5231 - loss: 1.0524\n",
      "Epoch 4/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.5139 - loss: 1.0543\n",
      "Epoch 5/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.5283 - loss: 1.0390\n",
      "Epoch 6/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.5352 - loss: 1.0266\n",
      "Epoch 7/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.5231 - loss: 1.0382\n",
      "Epoch 8/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.5443 - loss: 1.0191\n",
      "Epoch 9/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.5846 - loss: 0.9743\n",
      "Epoch 10/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.5857 - loss: 0.9724\n",
      "Epoch 11/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.5951 - loss: 0.9582\n",
      "Epoch 12/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.5984 - loss: 0.9499\n",
      "Epoch 13/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.6116 - loss: 0.9240\n",
      "Epoch 14/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.6240 - loss: 0.9154\n",
      "Epoch 15/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.6372 - loss: 0.8980\n",
      "Epoch 16/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.6460 - loss: 0.8821\n",
      "Epoch 17/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.6474 - loss: 0.8695\n",
      "Epoch 18/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.6443 - loss: 0.8588\n",
      "Epoch 19/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.6493 - loss: 0.8646\n",
      "Epoch 20/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.6480 - loss: 0.8518\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "LSTM\tConstant\tLayer: 2\tAccuracy: 9.272875816993464\n",
      "Epoch 1/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 18ms/step - accuracy: 0.4397 - loss: 1.1230\n",
      "Epoch 2/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 18ms/step - accuracy: 0.4975 - loss: 1.0805\n",
      "Epoch 3/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 18ms/step - accuracy: 0.5023 - loss: 1.0678\n",
      "Epoch 4/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 18ms/step - accuracy: 0.5006 - loss: 1.0640\n",
      "Epoch 5/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 18ms/step - accuracy: 0.4922 - loss: 1.0678\n",
      "Epoch 6/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 18ms/step - accuracy: 0.4949 - loss: 1.0639\n",
      "Epoch 7/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 18ms/step - accuracy: 0.4969 - loss: 1.0624\n",
      "Epoch 8/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 18ms/step - accuracy: 0.4945 - loss: 1.0622\n",
      "Epoch 9/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 18ms/step - accuracy: 0.5003 - loss: 1.0515\n",
      "Epoch 10/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 18ms/step - accuracy: 0.4937 - loss: 1.0635\n",
      "Epoch 11/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 18ms/step - accuracy: 0.4982 - loss: 1.0639\n",
      "Epoch 12/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 18ms/step - accuracy: 0.4987 - loss: 1.0550\n",
      "Epoch 13/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 18ms/step - accuracy: 0.4936 - loss: 1.0634\n",
      "Epoch 14/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 18ms/step - accuracy: 0.4949 - loss: 1.0598\n",
      "Epoch 15/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 18ms/step - accuracy: 0.5130 - loss: 1.0489\n",
      "Epoch 16/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 18ms/step - accuracy: 0.5207 - loss: 1.0445\n",
      "Epoch 17/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 18ms/step - accuracy: 0.5285 - loss: 1.0455\n",
      "Epoch 18/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 19ms/step - accuracy: 0.5428 - loss: 1.0183\n",
      "Epoch 19/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 20ms/step - accuracy: 0.5630 - loss: 1.0135\n",
      "Epoch 20/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 19ms/step - accuracy: 0.5488 - loss: 1.0247\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
      "LSTM\tINCREASING\tLayer: 2\tAccuracy: 11.083877995642702\n",
      "Epoch 1/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 18ms/step - accuracy: 0.4491 - loss: 1.1219\n",
      "Epoch 2/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 19ms/step - accuracy: 0.5043 - loss: 1.0689\n",
      "Epoch 3/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 18ms/step - accuracy: 0.5010 - loss: 1.0555\n",
      "Epoch 4/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 18ms/step - accuracy: 0.5025 - loss: 1.0511\n",
      "Epoch 5/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 18ms/step - accuracy: 0.5000 - loss: 1.0457\n",
      "Epoch 6/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 18ms/step - accuracy: 0.5167 - loss: 1.0365\n",
      "Epoch 7/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 18ms/step - accuracy: 0.5298 - loss: 1.0344\n",
      "Epoch 8/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 18ms/step - accuracy: 0.5027 - loss: 1.0617\n",
      "Epoch 9/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 18ms/step - accuracy: 0.5066 - loss: 1.0692\n",
      "Epoch 10/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 17ms/step - accuracy: 0.5098 - loss: 1.0599\n",
      "Epoch 11/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 17ms/step - accuracy: 0.5046 - loss: 1.0610\n",
      "Epoch 12/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 17ms/step - accuracy: 0.5181 - loss: 1.0507\n",
      "Epoch 13/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 18ms/step - accuracy: 0.4923 - loss: 1.0770\n",
      "Epoch 14/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 18ms/step - accuracy: 0.5106 - loss: 1.0506\n",
      "Epoch 15/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 17ms/step - accuracy: 0.5034 - loss: 1.0691\n",
      "Epoch 16/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 17ms/step - accuracy: 0.5025 - loss: 1.0538\n",
      "Epoch 17/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 17ms/step - accuracy: 0.5008 - loss: 1.0497\n",
      "Epoch 18/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 17ms/step - accuracy: 0.5009 - loss: 1.0419\n",
      "Epoch 19/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 17ms/step - accuracy: 0.5047 - loss: 1.0464\n",
      "Epoch 20/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 17ms/step - accuracy: 0.5053 - loss: 1.0488\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
      "LSTM\tDECREASING\tLayer: 2\tAccuracy: 50.108932461873636\n",
      "Epoch 1/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 9ms/step - accuracy: 0.4916 - loss: 1.0914\n",
      "Epoch 2/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.5199 - loss: 1.0643\n",
      "Epoch 3/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.5192 - loss: 1.0533\n",
      "Epoch 4/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.5211 - loss: 1.0620\n",
      "Epoch 5/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.5211 - loss: 1.0599\n",
      "Epoch 6/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 9ms/step - accuracy: 0.5212 - loss: 1.0568\n",
      "Epoch 7/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.5215 - loss: 1.0488\n",
      "Epoch 8/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - accuracy: 0.5176 - loss: 1.0564\n",
      "Epoch 9/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 9ms/step - accuracy: 0.5391 - loss: 1.0309\n",
      "Epoch 10/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.5319 - loss: 1.0330\n",
      "Epoch 11/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.5238 - loss: 1.0476\n",
      "Epoch 12/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.5254 - loss: 1.0490\n",
      "Epoch 13/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 9ms/step - accuracy: 0.5301 - loss: 1.0318\n",
      "Epoch 14/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 9ms/step - accuracy: 0.5246 - loss: 1.0498\n",
      "Epoch 15/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.5388 - loss: 1.0099\n",
      "Epoch 16/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.5590 - loss: 0.9996\n",
      "Epoch 17/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 9ms/step - accuracy: 0.5558 - loss: 0.9893\n",
      "Epoch 18/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.5705 - loss: 0.9712\n",
      "Epoch 19/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.5630 - loss: 0.9783\n",
      "Epoch 20/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 9ms/step - accuracy: 0.5632 - loss: 0.9769\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "LSTM\tConstant\tLayer: 3\tAccuracy: 41.80283224400871\n",
      "Epoch 1/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 27ms/step - accuracy: 0.4764 - loss: 1.1051\n",
      "Epoch 2/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 28ms/step - accuracy: 0.5110 - loss: 1.0637\n",
      "Epoch 3/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 28ms/step - accuracy: 0.5147 - loss: 1.0595\n",
      "Epoch 4/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 28ms/step - accuracy: 0.5180 - loss: 1.0580\n",
      "Epoch 5/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 28ms/step - accuracy: 0.5441 - loss: 1.0204\n",
      "Epoch 6/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 28ms/step - accuracy: 0.5524 - loss: 0.9976\n",
      "Epoch 7/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 28ms/step - accuracy: 0.5511 - loss: 1.0160\n",
      "Epoch 8/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 28ms/step - accuracy: 0.5360 - loss: 1.0419\n",
      "Epoch 9/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 29ms/step - accuracy: 0.5074 - loss: 1.0634\n",
      "Epoch 10/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 28ms/step - accuracy: 0.5139 - loss: 1.0586\n",
      "Epoch 11/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 28ms/step - accuracy: 0.5128 - loss: 1.0616\n",
      "Epoch 12/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 28ms/step - accuracy: 0.5340 - loss: 1.0432\n",
      "Epoch 13/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 28ms/step - accuracy: 0.5506 - loss: 1.0053\n",
      "Epoch 14/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 28ms/step - accuracy: 0.5533 - loss: 1.0059\n",
      "Epoch 15/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 28ms/step - accuracy: 0.5498 - loss: 0.9985\n",
      "Epoch 16/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 28ms/step - accuracy: 0.5524 - loss: 0.9938\n",
      "Epoch 17/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 28ms/step - accuracy: 0.5568 - loss: 0.9975\n",
      "Epoch 18/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 28ms/step - accuracy: 0.5626 - loss: 0.9917\n",
      "Epoch 19/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 27ms/step - accuracy: 0.4916 - loss: 1.0883\n",
      "Epoch 20/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 27ms/step - accuracy: 0.5091 - loss: 1.0729\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "LSTM\tINCREASING\tLayer: 3\tAccuracy: 54.41176470588235\n",
      "Epoch 1/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 27ms/step - accuracy: 0.4761 - loss: 1.1013\n",
      "Epoch 2/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 27ms/step - accuracy: 0.5142 - loss: 1.0652\n",
      "Epoch 3/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 27ms/step - accuracy: 0.5128 - loss: 1.0660\n",
      "Epoch 4/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 27ms/step - accuracy: 0.5104 - loss: 1.0521\n",
      "Epoch 5/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 27ms/step - accuracy: 0.5197 - loss: 1.0567\n",
      "Epoch 6/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 27ms/step - accuracy: 0.5172 - loss: 1.0456\n",
      "Epoch 7/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 27ms/step - accuracy: 0.5243 - loss: 1.0511\n",
      "Epoch 8/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 27ms/step - accuracy: 0.5207 - loss: 1.0487\n",
      "Epoch 9/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 27ms/step - accuracy: 0.5219 - loss: 1.0330\n",
      "Epoch 10/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 27ms/step - accuracy: 0.5684 - loss: 0.9948\n",
      "Epoch 11/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 27ms/step - accuracy: 0.5572 - loss: 1.0137\n",
      "Epoch 12/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 27ms/step - accuracy: 0.5329 - loss: 1.0332\n",
      "Epoch 13/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 27ms/step - accuracy: 0.5431 - loss: 1.0257\n",
      "Epoch 14/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 27ms/step - accuracy: 0.5596 - loss: 0.9991\n",
      "Epoch 15/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 27ms/step - accuracy: 0.5602 - loss: 0.9742\n",
      "Epoch 16/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 27ms/step - accuracy: 0.5189 - loss: 1.0512\n",
      "Epoch 17/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 27ms/step - accuracy: 0.5118 - loss: 1.0502\n",
      "Epoch 18/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 27ms/step - accuracy: 0.5290 - loss: 1.0200\n",
      "Epoch 19/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 27ms/step - accuracy: 0.5544 - loss: 1.0186\n",
      "Epoch 20/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 27ms/step - accuracy: 0.5801 - loss: 0.9770\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
      "LSTM\tDECREASING\tLayer: 3\tAccuracy: 35.60729847494553\n",
      "Epoch 1/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 9ms/step - accuracy: 0.4709 - loss: 1.0996\n",
      "Epoch 2/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.5232 - loss: 1.0688\n",
      "Epoch 3/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.5226 - loss: 1.0624\n",
      "Epoch 4/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.5231 - loss: 1.0589\n",
      "Epoch 5/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - accuracy: 0.5217 - loss: 1.0574\n",
      "Epoch 6/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.5309 - loss: 1.0537\n",
      "Epoch 7/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.5397 - loss: 1.0274\n",
      "Epoch 8/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.5357 - loss: 1.0295\n",
      "Epoch 9/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 9ms/step - accuracy: 0.5440 - loss: 1.0152\n",
      "Epoch 10/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.5511 - loss: 1.0075\n",
      "Epoch 11/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.5545 - loss: 1.0037\n",
      "Epoch 12/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.5421 - loss: 1.0171\n",
      "Epoch 13/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.5362 - loss: 1.0363\n",
      "Epoch 14/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.5724 - loss: 0.9760\n",
      "Epoch 15/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.5669 - loss: 0.9830\n",
      "Epoch 16/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.5673 - loss: 0.9819\n",
      "Epoch 17/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.5888 - loss: 0.9383\n",
      "Epoch 18/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.5742 - loss: 0.9795\n",
      "Epoch 19/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.5795 - loss: 0.9619\n",
      "Epoch 20/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.5947 - loss: 0.9355\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
      "LSTM\tConstant\tLayer: 4\tAccuracy: 38.56209150326798\n",
      "Epoch 1/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 37ms/step - accuracy: 0.4463 - loss: 1.1210\n",
      "Epoch 2/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 37ms/step - accuracy: 0.5183 - loss: 1.0757\n",
      "Epoch 3/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 37ms/step - accuracy: 0.5292 - loss: 1.0695\n",
      "Epoch 4/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 37ms/step - accuracy: 0.5246 - loss: 1.0666\n",
      "Epoch 5/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 37ms/step - accuracy: 0.5246 - loss: 1.0663\n",
      "Epoch 6/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 37ms/step - accuracy: 0.5347 - loss: 1.0609\n",
      "Epoch 7/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 37ms/step - accuracy: 0.5282 - loss: 1.0519\n",
      "Epoch 8/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 37ms/step - accuracy: 0.5326 - loss: 1.0373\n",
      "Epoch 9/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 37ms/step - accuracy: 0.5383 - loss: 1.0346\n",
      "Epoch 10/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 37ms/step - accuracy: 0.5440 - loss: 1.0265\n",
      "Epoch 11/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 37ms/step - accuracy: 0.5345 - loss: 1.0477\n",
      "Epoch 12/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 37ms/step - accuracy: 0.5318 - loss: 1.0382\n",
      "Epoch 13/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 37ms/step - accuracy: 0.5375 - loss: 1.0351\n",
      "Epoch 14/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 37ms/step - accuracy: 0.5285 - loss: 1.0365\n",
      "Epoch 15/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 37ms/step - accuracy: 0.5264 - loss: 1.0303\n",
      "Epoch 16/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 37ms/step - accuracy: 0.5605 - loss: 1.0068\n",
      "Epoch 17/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 38ms/step - accuracy: 0.5603 - loss: 1.0055\n",
      "Epoch 18/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 37ms/step - accuracy: 0.5648 - loss: 1.0040\n",
      "Epoch 19/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 37ms/step - accuracy: 0.5682 - loss: 0.9913\n",
      "Epoch 20/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 37ms/step - accuracy: 0.5687 - loss: 0.9793\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
      "LSTM\tINCREASING\tLayer: 4\tAccuracy: 44.104030501089326\n",
      "Epoch 1/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 36ms/step - accuracy: 0.4681 - loss: 1.0935\n",
      "Epoch 2/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 36ms/step - accuracy: 0.4873 - loss: 1.0538\n",
      "Epoch 3/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 36ms/step - accuracy: 0.4862 - loss: 1.0546\n",
      "Epoch 4/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 36ms/step - accuracy: 0.5016 - loss: 1.0539\n",
      "Epoch 5/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 36ms/step - accuracy: 0.4629 - loss: 1.1040\n",
      "Epoch 6/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 36ms/step - accuracy: 0.5051 - loss: 1.0654\n",
      "Epoch 7/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 36ms/step - accuracy: 0.5038 - loss: 1.0686\n",
      "Epoch 8/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 36ms/step - accuracy: 0.5088 - loss: 1.0533\n",
      "Epoch 9/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 36ms/step - accuracy: 0.5007 - loss: 1.0527\n",
      "Epoch 10/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 36ms/step - accuracy: 0.5125 - loss: 1.0511\n",
      "Epoch 11/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 36ms/step - accuracy: 0.4968 - loss: 1.0500\n",
      "Epoch 12/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 35ms/step - accuracy: 0.5100 - loss: 1.0633\n",
      "Epoch 13/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 35ms/step - accuracy: 0.5044 - loss: 1.0764\n",
      "Epoch 14/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 35ms/step - accuracy: 0.5130 - loss: 1.0472\n",
      "Epoch 15/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 35ms/step - accuracy: 0.5318 - loss: 1.0279\n",
      "Epoch 16/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 35ms/step - accuracy: 0.5502 - loss: 1.0213\n",
      "Epoch 17/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 35ms/step - accuracy: 0.5205 - loss: 1.0410\n",
      "Epoch 18/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 34ms/step - accuracy: 0.5220 - loss: 1.0339\n",
      "Epoch 19/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 34ms/step - accuracy: 0.6053 - loss: 0.9560\n",
      "Epoch 20/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 34ms/step - accuracy: 0.5699 - loss: 0.9810\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "LSTM\tDECREASING\tLayer: 4\tAccuracy: 40.781590413943356\n",
      "Epoch 1/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 9ms/step - accuracy: 0.4886 - loss: 1.0959\n",
      "Epoch 2/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.5312 - loss: 1.0618\n",
      "Epoch 3/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 9ms/step - accuracy: 0.5216 - loss: 1.0576\n",
      "Epoch 4/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 9ms/step - accuracy: 0.5165 - loss: 1.0597\n",
      "Epoch 5/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.5172 - loss: 1.0511\n",
      "Epoch 6/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 9ms/step - accuracy: 0.5130 - loss: 1.0595\n",
      "Epoch 7/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.5226 - loss: 1.0501\n",
      "Epoch 8/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.5149 - loss: 1.0493\n",
      "Epoch 9/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.5180 - loss: 1.0483\n",
      "Epoch 10/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 9ms/step - accuracy: 0.5104 - loss: 1.0510\n",
      "Epoch 11/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.5542 - loss: 1.0255\n",
      "Epoch 12/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.5591 - loss: 0.9994\n",
      "Epoch 13/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.5822 - loss: 0.9643\n",
      "Epoch 14/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.5698 - loss: 0.9672\n",
      "Epoch 15/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - accuracy: 0.5856 - loss: 0.9470\n",
      "Epoch 16/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.5856 - loss: 0.9459\n",
      "Epoch 17/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.5508 - loss: 1.0379\n",
      "Epoch 18/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.5628 - loss: 0.9888\n",
      "Epoch 19/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 9ms/step - accuracy: 0.5634 - loss: 0.9883\n",
      "Epoch 20/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.5605 - loss: 0.9893\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "LSTM\tConstant\tLayer: 5\tAccuracy: 37.99019607843137\n",
      "Epoch 1/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 46ms/step - accuracy: 0.4747 - loss: 1.0996\n",
      "Epoch 2/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 46ms/step - accuracy: 0.5227 - loss: 1.0679\n",
      "Epoch 3/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 46ms/step - accuracy: 0.5296 - loss: 1.0527\n",
      "Epoch 4/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 46ms/step - accuracy: 0.5397 - loss: 1.0424\n",
      "Epoch 5/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 46ms/step - accuracy: 0.5338 - loss: 1.0424\n",
      "Epoch 6/20\n",
      "\u001b[1m1836/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 46ms/step - accuracy: 0.5253 - loss: 1.0387\n",
      "Epoch 7/20\n",
      "\u001b[1m1233/1836\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m28s\u001b[0m 47ms/step - accuracy: 0.5372 - loss: 1.0348"
     ]
    }
   ],
   "source": [
    "for (name, _clf) in classifiers:\n",
    "\n",
    "    for rbm_layer in range(0, 6):\n",
    "        comb = []\n",
    "\n",
    "        # Constant\n",
    "        for j in range(0, rbm_layer):\n",
    "            comb.append((f\"mms{j}\", MinMaxScaler()))\n",
    "            comb.append((f\"rbm{j}\", BernoulliRBM(n_components = X_train.shape[1], learning_rate = 0.01, n_iter = 10, verbose = 0)))\n",
    "\n",
    "        predictor = Pipeline(comb)\n",
    "        if rbm_layer > 1:\n",
    "            copy_tf_X_train = predictor.fit_transform(tf_X_train)\n",
    "        else:\n",
    "            copy_tf_X_train = tf_X_train.copy()\n",
    "\n",
    "        mcp_save = ModelCheckpoint(f\"{name}_Constant_Layer_{rbm_layer}.keras\", save_best_only = True, monitor = \"accuracy\", mode = \"max\")\n",
    "        current_model = tf.keras.models.clone_model(_clf)\n",
    "        current_model.compile(loss = \"categorical_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])\n",
    "        history = current_model.fit(copy_tf_X_train, tf_y_train, batch_size = BATCH_SIZE, epochs = TRAIN_EPOCHS, callbacks = [mcp_save])\n",
    "        y_pred = np.argmax(current_model.predict(tf_X_test), axis = 1)\n",
    "        accuracy = accuracy_score(y_test, y_pred) * 100\n",
    "        Results[name][\"CONSTANT\"][rbm_layer] = {}\n",
    "        Results[name][\"CONSTANT\"][rbm_layer][\"accuracy\"] = accuracy\n",
    "        Results[name][\"CONSTANT\"][rbm_layer][\"history\"] = history.history\n",
    "        print(f\"{name}\\tConstant\\tLayer: {rbm_layer}\\tAccuracy: {accuracy}\")\n",
    "        \n",
    "        # Increasing\n",
    "        comb = []\n",
    "        for j in range(0, rbm_layer):\n",
    "            comb.append((f\"mms{j}\", MinMaxScaler()))\n",
    "            comb.append((f\"rbm{j}\", BernoulliRBM(n_components = X_train.shape[1] * (j + 1), learning_rate = 0.01, n_iter = 10, verbose = 0)))\n",
    "\n",
    "        predictor = Pipeline(comb)\n",
    "\n",
    "        if rbm_layer > 1:\n",
    "            copy_tf_X_train = predictor.fit_transform(tf_X_train)\n",
    "        else:\n",
    "            copy_tf_X_train = tf_X_train.copy()\n",
    "\n",
    "        mcp_save = ModelCheckpoint(f\"{name}_Increasing_Layer_{rbm_layer}.keras\", save_best_only = True, monitor = \"accuracy\", mode = \"max\")\n",
    "        current_model = tf.keras.models.clone_model(_clf)\n",
    "        current_model.compile(loss = \"categorical_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])\n",
    "        history = current_model.fit(copy_tf_X_train, tf_y_train, batch_size = BATCH_SIZE, epochs = TRAIN_EPOCHS, callbacks = [mcp_save])\n",
    "        y_pred = np.argmax(current_model.predict(tf_X_test), axis = 1)\n",
    "        accuracy = accuracy_score(y_test, y_pred) * 100\n",
    "        Results[name][\"INCREASING\"][rbm_layer] = {} \n",
    "        Results[name][\"INCREASING\"][rbm_layer][\"accuracy\"] = accuracy\n",
    "        Results[name][\"INCREASING\"][rbm_layer][\"history\"] = history.history\n",
    "        print(f\"{name}\\tINCREASING\\tLayer: {rbm_layer}\\tAccuracy: {accuracy}\")\n",
    "\n",
    "        # Decreasing\n",
    "        comb = []\n",
    "        for j in range(0, rbm_layer):\n",
    "            comb.append((f\"mms{j}\", MinMaxScaler()))\n",
    "            comb.append((f\"rbm{j}\", BernoulliRBM(n_components = X_train.shape[1] * rbm_layer - j, learning_rate = 0.01, n_iter = 10, verbose = 0)))\n",
    "\n",
    "        predictor = Pipeline(comb)\n",
    "\n",
    "        if rbm_layer > 1:\n",
    "            copy_tf_X_train = predictor.fit_transform(tf_X_train)\n",
    "        else:\n",
    "            copy_tf_X_train = tf_X_train.copy()\n",
    "\n",
    "        mcp_save = ModelCheckpoint(f\"{name}_Decreasing_Layer_{rbm_layer}.keras\", save_best_only = True, monitor = \"accuracy\", mode = \"max\")\n",
    "        current_model = tf.keras.models.clone_model(_clf)\n",
    "        current_model.compile(loss = \"categorical_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])\n",
    "        history = current_model.fit(copy_tf_X_train, tf_y_train, batch_size = BATCH_SIZE, epochs = TRAIN_EPOCHS, callbacks = [mcp_save])\n",
    "        y_pred = np.argmax(current_model.predict(tf_X_test), axis = 1)\n",
    "        accuracy = accuracy_score(y_test, y_pred) * 100\n",
    "        Results[name][\"DECREASING\"][rbm_layer] = {} \n",
    "        Results[name][\"DECREASING\"][rbm_layer][\"accuracy\"] = accuracy\n",
    "        Results[name][\"DECREASING\"][rbm_layer][\"history\"] = history.history\n",
    "        print(f\"{name}\\tDECREASING\\tLayer: {rbm_layer}\\tAccuracy: {accuracy}\")\n",
    "\n",
    "with open(\"TensorflowAccuracySaves.pkl\", \"wb\") as f:\n",
    "    pickle.dump(Results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history[\"accuracy\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.45601851851851855"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = LSTMClassif.predict(X_test)\n",
    "y_pred = np.argmax(y_pred, axis = 1)\n",
    "accuracy_score(y_pred, y_test)\n",
    "# .45 - Correct RBM Size, 10 Iter\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m918/918\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - accuracy: 0.4580 - loss: 1.1095\n",
      "Epoch 2/100\n",
      "\u001b[1m918/918\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.5038 - loss: 1.0420\n",
      "Epoch 3/100\n",
      "\u001b[1m918/918\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.6517 - loss: 0.8817\n",
      "Epoch 4/100\n",
      "\u001b[1m688/918\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.8010 - loss: 0.5502"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mLSTMClassif\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# LSTMPipe.fit(X_train, y_train)\u001b[39;00m\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/scikeras/wrappers.py:1501\u001b[0m, in \u001b[0;36mKerasClassifier.fit\u001b[0;34m(self, X, y, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m     sample_weight \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m sample_weight\n\u001b[1;32m   1500\u001b[0m     sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(class_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_weight, y\u001b[38;5;241m=\u001b[39my)\n\u001b[0;32m-> 1501\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/scikeras/wrappers.py:770\u001b[0m, in \u001b[0;36mBaseWrapper.fit\u001b[0;34m(self, X, y, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m    765\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m    766\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit__epochs\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepochs)\n\u001b[1;32m    767\u001b[0m )\n\u001b[1;32m    768\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minitial_epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minitial_epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m--> 770\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    771\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    772\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    773\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    774\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwarm_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwarm_start\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    775\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    776\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    778\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/scikeras/wrappers.py:938\u001b[0m, in \u001b[0;36mBaseWrapper._fit\u001b[0;34m(self, X, y, sample_weight, warm_start, epochs, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    934\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_encoder_\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[1;32m    936\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_model_compatibility(y)\n\u001b[0;32m--> 938\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_keras_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    939\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    940\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    941\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    942\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwarm_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwarm_start\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/scikeras/wrappers.py:535\u001b[0m, in \u001b[0;36mBaseWrapper._fit_keras_model\u001b[0;34m(self, X, y, sample_weight, warm_start, epochs, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    533\u001b[0m         hist \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_\u001b[38;5;241m.\u001b[39mfit(x\u001b[38;5;241m=\u001b[39mX, y\u001b[38;5;241m=\u001b[39my, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_args)\n\u001b[1;32m    534\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 535\u001b[0m     hist \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m warm_start \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhistory_\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m initial_epoch \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhistory_ \u001b[38;5;241m=\u001b[39m defaultdict(\u001b[38;5;28mlist\u001b[39m)\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:314\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[1;32m    313\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 314\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    315\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[1;32m    316\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1500\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1498\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1500\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1501\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1503\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1504\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1505\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1506\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1508\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1509\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1510\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1514\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1515\u001b[0m   )\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "LSTMClassif.fit(X_train, y_train)\n",
    "# LSTMPipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 37ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "50.422113289760354"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y_pred = LSTMPipe.predict(X_test)\n",
    "y_pred = LSTMClassif.predict(X_test)\n",
    "accuracy_score(y_test, y_pred) * 100\n",
    "# LSTM Only = 89%\n",
    "# LSTM (10 epochs) + 1 RBM = 50.42"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy Summary Table\n",
    "\n",
    "|      Base Setup     \t|     \t|     \t|     \t|         \t|            \t|     \t|     \t|     \t|         \t|\n",
    "|:-------------------:\t|-----\t|-----\t|-----\t|---------\t|------------\t|-----\t|-----\t|-----\t|---------\t|\n",
    "| SciKit              \t|  1  \t|  2  \t|  3  \t| Average \t| Tensorflow \t|  1  \t|  2  \t|  3  \t| Average \t|\n",
    "| K Nearest Neighbors \t| 100 \t| 100 \t| 100 \t|   100   \t| LSTM       \t| 100 \t| 100 \t| 100 \t|   100   \t|\n",
    "| Linear & RBF SVM    \t| 100 \t| 100 \t| 100 \t|   100   \t| GRU        \t| 100 \t| 100 \t| 100 \t|   100   \t|\n",
    "| QDA                 \t| 100 \t| 100 \t| 100 \t|   100   \t| Simple RNN \t| 100 \t| 100 \t| 100 \t|   100   \t|\n",
    "| Gaussian Process    \t| 100 \t| 100 \t| 100 \t|   100   \t| Bi LSTM    \t| 100 \t| 100 \t| 100 \t|   100   \t|\n",
    "| Decision Tree       \t| 100 \t| 100 \t| 100 \t|   100   \t| Bi GRU     \t| 100 \t| 100 \t| 100 \t|   100   \t|\n",
    "| Random Forest       \t| 100 \t| 100 \t| 100 \t|   100   \t| Bi RNN     \t| 100 \t| 100 \t| 100 \t|   100   \t|\n",
    "| Neural Net          \t| 100 \t| 100 \t| 100 \t|   100   \t| Dense      \t| 100 \t| 100 \t| 100 \t|   100   \t|\n",
    "| AdaBoost            \t| 100 \t| 100 \t| 100 \t|   100   \t|            \t|     \t|     \t|     \t|         \t|\n",
    "| Naive Bayes         \t| 100 \t| 100 \t| 100 \t|   100   \t|            \t|     \t|     \t|     \t|         \t|\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import tensorflow as tf \n",
    "import pickle \n",
    "\n",
    "from pprint import pprint\n",
    "from tqdm import tqdm\n",
    "\n",
    "from tensorflow import keras \n",
    "from tensorflow.keras import layers \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError, MeanAbsoluteError\n",
    "from tensorflow.keras.losses import MeanSquaredError, MeanAbsoluteError\n",
    "from tensorflow.keras.optimizers import Adam \n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV \n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder, minmax_scale\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.neural_network import BernoulliRBM\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score, classification_report\n",
    "from sklearn.datasets import load_digits\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from scipy.ndimage import convolve\n",
    "\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "import collections \n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alaric\\AppData\\Local\\Temp\\ipykernel_16432\\3229338220.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  raw_dataset[\"conditions\"] = [word.replace(\", \", \"\\n\") if (\",\" in word) else word for word in raw_dataset[\"conditions\"]]\n",
      "C:\\Users\\Alaric\\AppData\\Local\\Temp\\ipykernel_16432\\3229338220.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  raw_dataset[\"conditions\"] =  LE.fit_transform(raw_dataset[\"conditions\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29372, 25) (7344, 25) (29372,) (7344,)\n"
     ]
    }
   ],
   "source": [
    "FULL_DATA = False\n",
    "LE = LabelEncoder()\n",
    "WINDOW_LENGTH = 5\n",
    "ADD_ELEMENTS = True\n",
    "\n",
    "\n",
    "concatenated_data = pd.read_csv(\"Concatenated Data.csv\")\n",
    "\n",
    "if FULL_DATA:\n",
    "    raw_dataset = concatenated_data[[\"tempmax\", \"tempmin\", \"temp\", \"feelslikemax\", \"feelslikemin\", \"feelslike\", \"dew\", \"humidity\", \"windspeed\", \"sealevelpressure\", \"conditions\"]]\n",
    "else:\n",
    "    raw_dataset = concatenated_data[[\"temp\", \"feelslike\", \"humidity\", \"windspeed\", \"sealevelpressure\", \"conditions\"]]\n",
    "\n",
    "raw_dataset[\"conditions\"] = [word.replace(\", \", \"\\n\") if (\",\" in word) else word for word in raw_dataset[\"conditions\"]]\n",
    "raw_dataset[\"conditions\"] =  LE.fit_transform(raw_dataset[\"conditions\"])\n",
    "\n",
    "t_arr = raw_dataset.copy().to_numpy()\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for i in range(len(t_arr) - WINDOW_LENGTH):\n",
    "    t_row = []\n",
    "    for j in t_arr[i : i + WINDOW_LENGTH]:\n",
    "        t_row.append(j[:-1])\n",
    "    t_row = np.array(t_row).flatten()\n",
    "    X.append(t_row)\n",
    "    y.append(t_arr[i + WINDOW_LENGTH][-1])\n",
    "\n",
    "X = np.array(X, \"float32\")\n",
    "X = minmax_scale(X, feature_range=(0, 1))\n",
    "y = np.array(y)\n",
    "\n",
    "counts = dict(collections.Counter(y))\n",
    "max_count = max(counts.values())\n",
    "\n",
    "# Data Augmentation\n",
    "\n",
    "if ADD_ELEMENTS:\n",
    "    for key, value in counts.items():\n",
    "        curX = []\n",
    "        curY = []\n",
    "        li, = np.where(y == key)\n",
    "        for i in range((max_count - value) * 10):\n",
    "            ci = random.choice(li)\n",
    "            curX.append(X[ci])\n",
    "            curY.append(y[ci])\n",
    "        tX = X.tolist()\n",
    "        tY = y.tolist()\n",
    "        tX.extend(curX)\n",
    "        tY.extend(curY)\n",
    "        X = np.array(tX)\n",
    "        y = np.array(tY)        \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN\tConstant\tLayer: 0\tAccuracy: 95.35675381263616\n",
      "KNN\tConstant\tLayer: 1\tAccuracy: 94.79847494553377\n",
      "KNN\tConstant\tLayer: 2\tAccuracy: 94.44444444444444\n",
      "KNN\tConstant\tLayer: 3\tAccuracy: 94.25381263616558\n",
      "KNN\tConstant\tLayer: 4\tAccuracy: 94.14488017429193\n",
      "KNN\tConstant\tLayer: 5\tAccuracy: 93.80446623093682\n",
      "RBF SVM\tConstant\tLayer: 0\tAccuracy: 90.16884531590415\n",
      "RBF SVM\tConstant\tLayer: 1\tAccuracy: 56.495098039215684\n",
      "RBF SVM\tConstant\tLayer: 2\tAccuracy: 55.9640522875817\n",
      "RBF SVM\tConstant\tLayer: 3\tAccuracy: 51.85185185185185\n",
      "RBF SVM\tConstant\tLayer: 4\tAccuracy: 54.69771241830066\n",
      "RBF SVM\tConstant\tLayer: 5\tAccuracy: 56.03213507625272\n",
      "LINEAR SVM\tConstant\tLayer: 0\tAccuracy: 82.77505446623094\n",
      "LINEAR SVM\tConstant\tLayer: 1\tAccuracy: 53.47222222222222\n",
      "LINEAR SVM\tConstant\tLayer: 2\tAccuracy: 50.65359477124183\n",
      "LINEAR SVM\tConstant\tLayer: 3\tAccuracy: 54.47984749455338\n",
      "LINEAR SVM\tConstant\tLayer: 4\tAccuracy: 54.738562091503276\n",
      "LINEAR SVM\tConstant\tLayer: 5\tAccuracy: 55.392156862745104\n",
      "DECISION TREE\tConstant\tLayer: 0\tAccuracy: 97.1541394335512\n",
      "DECISION TREE\tConstant\tLayer: 1\tAccuracy: 97.18137254901961\n",
      "DECISION TREE\tConstant\tLayer: 2\tAccuracy: 96.77287581699346\n",
      "DECISION TREE\tConstant\tLayer: 3\tAccuracy: 96.70479302832244\n",
      "DECISION TREE\tConstant\tLayer: 4\tAccuracy: 96.71840958605664\n",
      "DECISION TREE\tConstant\tLayer: 5\tAccuracy: 96.50054466230938\n",
      "RANDOM FOREST\tConstant\tLayer: 0\tAccuracy: 97.75326797385621\n",
      "RANDOM FOREST\tConstant\tLayer: 1\tAccuracy: 96.89542483660131\n",
      "RANDOM FOREST\tConstant\tLayer: 2\tAccuracy: 96.5958605664488\n",
      "RANDOM FOREST\tConstant\tLayer: 3\tAccuracy: 96.6367102396514\n",
      "RANDOM FOREST\tConstant\tLayer: 4\tAccuracy: 96.47331154684096\n",
      "RANDOM FOREST\tConstant\tLayer: 5\tAccuracy: 96.5958605664488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alaric\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP\tConstant\tLayer: 0\tAccuracy: 92.08877995642702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alaric\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP\tConstant\tLayer: 1\tAccuracy: 57.938453159041394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alaric\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP\tConstant\tLayer: 2\tAccuracy: 59.912854030501094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alaric\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP\tConstant\tLayer: 3\tAccuracy: 57.44825708061002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alaric\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP\tConstant\tLayer: 4\tAccuracy: 58.55119825708061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alaric\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP\tConstant\tLayer: 5\tAccuracy: 53.07734204793029\n",
      "ADA BOOST\tConstant\tLayer: 0\tAccuracy: 85.23965141612202\n",
      "ADA BOOST\tConstant\tLayer: 1\tAccuracy: 79.38453159041394\n",
      "ADA BOOST\tConstant\tLayer: 2\tAccuracy: 76.93355119825708\n",
      "ADA BOOST\tConstant\tLayer: 3\tAccuracy: 69.96187363834423\n",
      "ADA BOOST\tConstant\tLayer: 4\tAccuracy: 75.12254901960785\n",
      "ADA BOOST\tConstant\tLayer: 5\tAccuracy: 72.68518518518519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alaric\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOGISTIC\tConstant\tLayer: 0\tAccuracy: 76.10294117647058\n",
      "LOGISTIC\tConstant\tLayer: 1\tAccuracy: 56.141067538126364\n",
      "LOGISTIC\tConstant\tLayer: 2\tAccuracy: 50.885076252723316\n",
      "LOGISTIC\tConstant\tLayer: 3\tAccuracy: 54.724945533769066\n",
      "LOGISTIC\tConstant\tLayer: 4\tAccuracy: 55.392156862745104\n",
      "LOGISTIC\tConstant\tLayer: 5\tAccuracy: 57.27124183006536\n"
     ]
    }
   ],
   "source": [
    "RBM_MULTIPLIER = 0.5\n",
    "\n",
    "classifiers = [\n",
    "    (\"KNN\", KNeighborsClassifier()),\n",
    "    (\"RBF SVM\", SVC()),\n",
    "    (\"LINEAR SVM\", SVC(kernel = \"linear\")),\n",
    "    (\"DECISION TREE\", DecisionTreeClassifier()),\n",
    "    (\"RANDOM FOREST\", RandomForestClassifier()),\n",
    "    (\"MLP\", MLPClassifier()),\n",
    "    (\"ADA BOOST\", AdaBoostClassifier()),    \n",
    "    (\"LOGISTIC\", LogisticRegression())\n",
    "]\n",
    "\n",
    "Results = {\n",
    "\n",
    "}\n",
    "\n",
    "for (name, _clf) in classifiers:\n",
    "\n",
    "    for rbm_layer in range(0, 6):\n",
    "        comb = []\n",
    "\n",
    "        comb.append((f\"mms{j}\", MinMaxScaler()))\n",
    "        # Constant\n",
    "        for j in range(0, rbm_layer):\n",
    "            comb.append((f\"rbm{j}\", BernoulliRBM(n_components = int(X_train.shape[1] * RBM_MULTIPLIER), learning_rate = 0.01, n_iter = 10, verbose = 0)))\n",
    "\n",
    "            if j == rbm_layer - 1:\n",
    "                comb.append((f\"mms{j}\", MinMaxScaler()))\n",
    "\n",
    "\n",
    "        \n",
    "        comb.append((name, _clf))\n",
    "        predictor = Pipeline(comb)\n",
    "\n",
    "        predictor.fit(X_train, y_train)\n",
    "        y_pred = predictor.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred) * 100\n",
    "        if name not in Results:\n",
    "            Results[name] = {}\n",
    "        Results[name][rbm_layer] = accuracy\n",
    "        print(f\"{name}\\tConstant\\tLayer: {rbm_layer}\\tAccuracy: {accuracy}\")\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ADA BOOST': {0: 85.23965141612202,\n",
      "               1: 79.38453159041394,\n",
      "               2: 76.93355119825708,\n",
      "               3: 69.96187363834423,\n",
      "               4: 75.12254901960785,\n",
      "               5: 72.68518518518519},\n",
      " 'DECISION TREE': {0: 97.1541394335512,\n",
      "                   1: 97.18137254901961,\n",
      "                   2: 96.77287581699346,\n",
      "                   3: 96.70479302832244,\n",
      "                   4: 96.71840958605664,\n",
      "                   5: 96.50054466230938},\n",
      " 'KNN': {0: 95.35675381263616,\n",
      "         1: 94.79847494553377,\n",
      "         2: 94.44444444444444,\n",
      "         3: 94.25381263616558,\n",
      "         4: 94.14488017429193,\n",
      "         5: 93.80446623093682},\n",
      " 'LINEAR SVM': {0: 82.77505446623094,\n",
      "                1: 53.47222222222222,\n",
      "                2: 50.65359477124183,\n",
      "                3: 54.47984749455338,\n",
      "                4: 54.738562091503276,\n",
      "                5: 55.392156862745104},\n",
      " 'LOGISTIC': {0: 76.10294117647058,\n",
      "              1: 56.141067538126364,\n",
      "              2: 50.885076252723316,\n",
      "              3: 54.724945533769066,\n",
      "              4: 55.392156862745104,\n",
      "              5: 57.27124183006536},\n",
      " 'MLP': {0: 92.08877995642702,\n",
      "         1: 57.938453159041394,\n",
      "         2: 59.912854030501094,\n",
      "         3: 57.44825708061002,\n",
      "         4: 58.55119825708061,\n",
      "         5: 53.07734204793029},\n",
      " 'RANDOM FOREST': {0: 97.75326797385621,\n",
      "                   1: 96.89542483660131,\n",
      "                   2: 96.5958605664488,\n",
      "                   3: 96.6367102396514,\n",
      "                   4: 96.47331154684096,\n",
      "                   5: 96.5958605664488},\n",
      " 'RBF SVM': {0: 90.16884531590415,\n",
      "             1: 56.495098039215684,\n",
      "             2: 55.9640522875817,\n",
      "             3: 51.85185185185185,\n",
      "             4: 54.69771241830066,\n",
      "             5: 56.03213507625272}}\n"
     ]
    }
   ],
   "source": [
    "pprint(Results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BuildGenericModel(input_dimension, output_dimension, layerType, Kernel_Count = 64, Layer_Count = 2, Dense_Flag = False, Bidirectional_Flag = False):\n",
    "    PredictorModel = Sequential()\n",
    "    PredictorModel.add(layers.InputLayer((input_dimension, 1)))\n",
    "\n",
    "    if Dense_Flag:\n",
    "        # No Return Sequences for Dense Layer\n",
    "        for i in range(1, Layer_Count):\n",
    "            PredictorModel.add(layerType(Kernel_Count))\n",
    "\n",
    "        # Final Layer\n",
    "        PredictorModel.add(layerType(Kernel_Count))\n",
    "        \n",
    "    elif Bidirectional_Flag:\n",
    "        # Return Sequences (Only Adds if More than 1 Layers)\n",
    "        for i in range(1, Layer_Count):\n",
    "            PredictorModel.add(layerType)\n",
    "\n",
    "        # Add a Final SimpleRNN Layer at End of Bidirectional Layers\n",
    "        PredictorModel.add(layers.SimpleRNN(Kernel_Count))\n",
    "\n",
    "    else:\n",
    "        # Return Sequences (Only Adds if More than 1 Layers)\n",
    "        for i in range(1, Layer_Count):\n",
    "            PredictorModel.add(layerType(Kernel_Count, return_sequences = True))\n",
    "        \n",
    "        # Final Layer\n",
    "        PredictorModel.add(layerType(Kernel_Count))\n",
    "\n",
    "    # Flatten Layer\n",
    "    PredictorModel.add(layers.Flatten()) \n",
    "\n",
    "    # Output Dimension\n",
    "    PredictorModel.add(layers.Dense(output_dimension, activation = \"softmax\"))\n",
    "\n",
    "    # Compile Model\n",
    "    PredictorModel.compile(loss = \"categorical_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])\n",
    "\n",
    "    return PredictorModel\n",
    "\n",
    "def buildModels(X_train_shape, Y_train_shape, Kernel = 64, Layer_Count = 2):\n",
    "    LSTMModel = BuildGenericModel(X_train_shape[1], Y_train_shape[1], layers.LSTM, Kernel, Layer_Count)\n",
    "    GRUModel = BuildGenericModel(X_train_shape[1], Y_train_shape[1], layers.GRU, Kernel, Layer_Count)\n",
    "    SimpleRNNModel = BuildGenericModel(X_train_shape[1], Y_train_shape[1], layers.SimpleRNN, Kernel, Layer_Count)\n",
    "    BiLSTMModel = BuildGenericModel(X_train_shape[1], Y_train_shape[1], layers.Bidirectional(layers.LSTM(Kernel, return_sequences = True)), Kernel, Layer_Count, Bidirectional_Flag = True)\n",
    "    BiGRUModel = BuildGenericModel(X_train_shape[1], Y_train_shape[1], layers.Bidirectional(layers.GRU(Kernel, return_sequences = True)), Kernel, Layer_Count, Bidirectional_Flag = True)\n",
    "    BiSimpleRNNModel = BuildGenericModel(X_train_shape[1], Y_train_shape[1], layers.Bidirectional(layers.SimpleRNN(Kernel, return_sequences = True)), Kernel, Layer_Count, Bidirectional_Flag = True)\n",
    "    DenseModel = BuildGenericModel(X_train_shape[1], Y_train_shape[1], layers.Dense, Kernel, Layer_Count, Dense_Flag = True)\n",
    "\n",
    "    return (LSTMModel, GRUModel, SimpleRNNModel, BiLSTMModel, BiGRUModel, BiSimpleRNNModel, DenseModel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tf_X_train = minmax_scale(X_train, feature_range = (0, 1))\n",
    "tf_X_test = minmax_scale(X_test, feature_range = (0, 1))\n",
    "\n",
    "tf_y_train = to_categorical(y_train)\n",
    "tf_y_test = to_categorical(y_test)\n",
    "\n",
    "LSTM_Predictor, GRU_Predictor, RNN_Predictor, Bi_LSTM_Predictor, Bi_GRU_Predictor, Bi_RNN_Predictor, Dense_Predictor = buildModels(tf_X_train.shape, tf_y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_EPOCHS = 10\n",
    "BATCH_SIZE = 1024\n",
    "\n",
    "classifiers = [\n",
    "    (\"LSTM\", LSTM_Predictor), \n",
    "    (\"GRU\", GRU_Predictor), \n",
    "    (\"RNN\", RNN_Predictor), \n",
    "    (\"BI LSTM\", Bi_LSTM_Predictor), \n",
    "    (\"BI GRU\", Bi_GRU_Predictor), \n",
    "    (\"BI RNN\", Bi_RNN_Predictor), \n",
    "    (\"DENSE\", Dense_Predictor)\n",
    "]\n",
    "\n",
    "Results = {}\n",
    "for name, _ in classifiers:\n",
    "    Results[name] = {\n",
    "        \"CONSTANT\" : {\n",
    "\n",
    "        },\n",
    "        \"INCREASING\" : {\n",
    "\n",
    "        },\n",
    "        \"DECREASING\" : {\n",
    "\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "29/29 [==============================] - 17s 317ms/step - loss: 1.1831 - accuracy: 0.4428\n",
      "Epoch 2/10\n",
      "29/29 [==============================] - 10s 338ms/step - loss: 1.1051 - accuracy: 0.4714\n",
      "Epoch 3/10\n",
      "29/29 [==============================] - 11s 386ms/step - loss: 1.0873 - accuracy: 0.4825\n",
      "Epoch 4/10\n",
      "29/29 [==============================] - 12s 410ms/step - loss: 1.0765 - accuracy: 0.4813\n",
      "Epoch 5/10\n",
      "29/29 [==============================] - 12s 413ms/step - loss: 1.0710 - accuracy: 0.4796\n",
      "Epoch 6/10\n",
      "29/29 [==============================] - 12s 399ms/step - loss: 1.0603 - accuracy: 0.4823\n",
      "Epoch 7/10\n",
      "29/29 [==============================] - 12s 406ms/step - loss: 1.0471 - accuracy: 0.4889\n",
      "Epoch 8/10\n",
      "29/29 [==============================] - 12s 412ms/step - loss: 1.0447 - accuracy: 0.5089\n",
      "Epoch 9/10\n",
      "29/29 [==============================] - 12s 408ms/step - loss: 1.0216 - accuracy: 0.5261\n",
      "Epoch 10/10\n",
      "29/29 [==============================] - 12s 429ms/step - loss: 1.0117 - accuracy: 0.5417\n",
      "230/230 [==============================] - 4s 12ms/step\n",
      "LSTM\tConstant\tLayer: 0\tAccuracy: 53.86710239651416\n",
      "Epoch 1/10\n",
      "29/29 [==============================] - 19s 402ms/step - loss: 1.1725 - accuracy: 0.4527\n",
      "Epoch 2/10\n",
      "29/29 [==============================] - 12s 410ms/step - loss: 1.1086 - accuracy: 0.4572\n",
      "Epoch 3/10\n",
      "29/29 [==============================] - 12s 410ms/step - loss: 1.1012 - accuracy: 0.4707\n",
      "Epoch 4/10\n",
      "29/29 [==============================] - 12s 408ms/step - loss: 1.0876 - accuracy: 0.4773\n",
      "Epoch 5/10\n",
      "29/29 [==============================] - 12s 415ms/step - loss: 1.0705 - accuracy: 0.4825\n",
      "Epoch 6/10\n",
      "29/29 [==============================] - 12s 409ms/step - loss: 1.0679 - accuracy: 0.4808\n",
      "Epoch 7/10\n",
      "29/29 [==============================] - 12s 418ms/step - loss: 1.0630 - accuracy: 0.4829\n",
      "Epoch 8/10\n",
      "29/29 [==============================] - 12s 423ms/step - loss: 1.0558 - accuracy: 0.4843\n",
      "Epoch 9/10\n",
      "29/29 [==============================] - 13s 437ms/step - loss: 1.0438 - accuracy: 0.4931\n",
      "Epoch 10/10\n",
      "29/29 [==============================] - 12s 416ms/step - loss: 1.0338 - accuracy: 0.4909\n",
      "230/230 [==============================] - 4s 13ms/step\n",
      "LSTM\tINCREASING\tLayer: 0\tAccuracy: 50.68082788671025\n",
      "Epoch 1/10\n",
      "29/29 [==============================] - 19s 405ms/step - loss: 1.1740 - accuracy: 0.4334\n",
      "Epoch 2/10\n",
      "29/29 [==============================] - 12s 414ms/step - loss: 1.1064 - accuracy: 0.4607\n",
      "Epoch 3/10\n",
      "29/29 [==============================] - 12s 418ms/step - loss: 1.0935 - accuracy: 0.4818\n",
      "Epoch 4/10\n",
      "29/29 [==============================] - 12s 408ms/step - loss: 1.0709 - accuracy: 0.4718\n",
      "Epoch 5/10\n",
      "29/29 [==============================] - 12s 398ms/step - loss: 1.0604 - accuracy: 0.4800\n",
      "Epoch 6/10\n",
      "29/29 [==============================] - 12s 405ms/step - loss: 1.0558 - accuracy: 0.4850\n",
      "Epoch 7/10\n",
      "29/29 [==============================] - 12s 409ms/step - loss: 1.0410 - accuracy: 0.4832\n",
      "Epoch 8/10\n",
      "29/29 [==============================] - 12s 402ms/step - loss: 1.0399 - accuracy: 0.4922\n",
      "Epoch 9/10\n",
      "29/29 [==============================] - 12s 424ms/step - loss: 1.0414 - accuracy: 0.4974\n",
      "Epoch 10/10\n",
      "29/29 [==============================] - 12s 404ms/step - loss: 1.0222 - accuracy: 0.5131\n",
      "230/230 [==============================] - 5s 13ms/step\n",
      "LSTM\tDECREASING\tLayer: 0\tAccuracy: 53.10457516339869\n",
      "Epoch 1/10\n",
      "29/29 [==============================] - 21s 406ms/step - loss: 1.1693 - accuracy: 0.4313\n",
      "Epoch 2/10\n",
      "29/29 [==============================] - 12s 428ms/step - loss: 1.1016 - accuracy: 0.4637\n",
      "Epoch 3/10\n",
      "29/29 [==============================] - 12s 417ms/step - loss: 1.0796 - accuracy: 0.4737\n",
      "Epoch 4/10\n",
      "29/29 [==============================] - 12s 417ms/step - loss: 1.0720 - accuracy: 0.4796\n",
      "Epoch 5/10\n",
      "29/29 [==============================] - 12s 428ms/step - loss: 1.0662 - accuracy: 0.4781\n",
      "Epoch 6/10\n",
      "29/29 [==============================] - 12s 416ms/step - loss: 1.0612 - accuracy: 0.4810\n",
      "Epoch 7/10\n",
      "29/29 [==============================] - 12s 408ms/step - loss: 1.0572 - accuracy: 0.4852\n",
      "Epoch 8/10\n",
      "29/29 [==============================] - 12s 430ms/step - loss: 1.0547 - accuracy: 0.4905\n",
      "Epoch 9/10\n",
      "29/29 [==============================] - 12s 415ms/step - loss: 1.0479 - accuracy: 0.5012\n",
      "Epoch 10/10\n",
      "29/29 [==============================] - 12s 429ms/step - loss: 1.0457 - accuracy: 0.5039\n",
      "230/230 [==============================] - 4s 13ms/step\n",
      "LSTM\tConstant\tLayer: 1\tAccuracy: 50.040849673202615\n",
      "Epoch 1/10\n",
      "29/29 [==============================] - 19s 408ms/step - loss: 1.1928 - accuracy: 0.4305\n",
      "Epoch 2/10\n",
      "29/29 [==============================] - 12s 418ms/step - loss: 1.1103 - accuracy: 0.4572\n",
      "Epoch 3/10\n",
      "29/29 [==============================] - 13s 460ms/step - loss: 1.1045 - accuracy: 0.4574\n",
      "Epoch 4/10\n",
      "29/29 [==============================] - 12s 426ms/step - loss: 1.0848 - accuracy: 0.4814\n",
      "Epoch 5/10\n",
      "29/29 [==============================] - 14s 469ms/step - loss: 1.0699 - accuracy: 0.4694\n",
      "Epoch 6/10\n",
      "29/29 [==============================] - 13s 451ms/step - loss: 1.0574 - accuracy: 0.4723\n",
      "Epoch 7/10\n",
      "29/29 [==============================] - 13s 459ms/step - loss: 1.0483 - accuracy: 0.4765\n",
      "Epoch 8/10\n",
      "29/29 [==============================] - 13s 442ms/step - loss: 1.0197 - accuracy: 0.5034\n",
      "Epoch 9/10\n",
      "29/29 [==============================] - 12s 415ms/step - loss: 1.0492 - accuracy: 0.4949\n",
      "Epoch 10/10\n",
      "29/29 [==============================] - 12s 427ms/step - loss: 1.0530 - accuracy: 0.5085\n",
      "230/230 [==============================] - 5s 13ms/step\n",
      "LSTM\tINCREASING\tLayer: 1\tAccuracy: 50.476579520697165\n",
      "Epoch 1/10\n",
      "29/29 [==============================] - 20s 414ms/step - loss: 1.1842 - accuracy: 0.4352\n",
      "Epoch 2/10\n",
      "29/29 [==============================] - 12s 416ms/step - loss: 1.1018 - accuracy: 0.4696\n",
      "Epoch 3/10\n",
      "29/29 [==============================] - 12s 424ms/step - loss: 1.0831 - accuracy: 0.4805\n",
      "Epoch 4/10\n",
      "29/29 [==============================] - 12s 421ms/step - loss: 1.0678 - accuracy: 0.4687\n",
      "Epoch 5/10\n",
      "29/29 [==============================] - 12s 409ms/step - loss: 1.0592 - accuracy: 0.4728\n",
      "Epoch 6/10\n",
      "29/29 [==============================] - 12s 406ms/step - loss: 1.0551 - accuracy: 0.4820\n",
      "Epoch 7/10\n",
      "29/29 [==============================] - 12s 417ms/step - loss: 1.0465 - accuracy: 0.4855\n",
      "Epoch 8/10\n",
      "29/29 [==============================] - 12s 413ms/step - loss: 1.0369 - accuracy: 0.4856\n",
      "Epoch 9/10\n",
      "29/29 [==============================] - 12s 431ms/step - loss: 1.0300 - accuracy: 0.4968\n",
      "Epoch 10/10\n",
      "29/29 [==============================] - 12s 419ms/step - loss: 1.0323 - accuracy: 0.5130\n",
      "230/230 [==============================] - 5s 16ms/step\n",
      "LSTM\tDECREASING\tLayer: 1\tAccuracy: 53.10457516339869\n",
      "Epoch 1/10\n",
      "29/29 [==============================] - 22s 491ms/step - loss: 1.1708 - accuracy: 0.4429\n",
      "Epoch 2/10\n",
      "29/29 [==============================] - 14s 484ms/step - loss: 1.1066 - accuracy: 0.4528\n",
      "Epoch 3/10\n",
      "29/29 [==============================] - 14s 469ms/step - loss: 1.1047 - accuracy: 0.4529\n",
      "Epoch 4/10\n",
      "29/29 [==============================] - 14s 478ms/step - loss: 1.1014 - accuracy: 0.4531\n",
      "Epoch 5/10\n",
      "29/29 [==============================] - 14s 491ms/step - loss: 1.0965 - accuracy: 0.4800\n",
      "Epoch 6/10\n",
      "29/29 [==============================] - 15s 501ms/step - loss: 1.0901 - accuracy: 0.4891\n",
      "Epoch 7/10\n",
      "29/29 [==============================] - 14s 470ms/step - loss: 1.0855 - accuracy: 0.4930\n",
      "Epoch 8/10\n",
      "29/29 [==============================] - 14s 471ms/step - loss: 1.0720 - accuracy: 0.5105\n",
      "Epoch 9/10\n",
      "29/29 [==============================] - 14s 474ms/step - loss: 1.0700 - accuracy: 0.5047\n",
      "Epoch 10/10\n",
      "29/29 [==============================] - 14s 467ms/step - loss: 1.0619 - accuracy: 0.5151\n",
      "230/230 [==============================] - 5s 16ms/step\n",
      "LSTM\tConstant\tLayer: 2\tAccuracy: 38.23529411764706\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\Alaric\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\Alaric\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\Alaric\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\Alaric\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\training.py\", line 1050, in train_step\n        y_pred = self(x, training=True)\n    File \"c:\\Users\\Alaric\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\Alaric\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 25, 1), found shape=(None, 50)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 44\u001b[0m\n\u001b[0;32m     42\u001b[0m current_model \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mclone_model(_clf)\n\u001b[0;32m     43\u001b[0m current_model\u001b[38;5;241m.\u001b[39mcompile(loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m\"\u001b[39m, optimizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m\"\u001b[39m, metrics \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m---> 44\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mcurrent_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcopy_tf_X_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtf_y_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mTRAIN_EPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mmcp_save\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     45\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(current_model\u001b[38;5;241m.\u001b[39mpredict(tf_X_test), axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     46\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m accuracy_score(y_test, y_pred) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Alaric\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filek2nb79b1.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\Users\\Alaric\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\Alaric\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\Alaric\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\Alaric\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\training.py\", line 1050, in train_step\n        y_pred = self(x, training=True)\n    File \"c:\\Users\\Alaric\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\Alaric\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 25, 1), found shape=(None, 50)\n"
     ]
    }
   ],
   "source": [
    "for (name, _clf) in classifiers:\n",
    "\n",
    "    for rbm_layer in range(0, 6):\n",
    "        comb = []\n",
    "\n",
    "        # Constant\n",
    "        for j in range(0, rbm_layer):\n",
    "            comb.append((f\"mms{j}\", MinMaxScaler()))\n",
    "            comb.append((f\"rbm{j}\", BernoulliRBM(n_components = X_train.shape[1], learning_rate = 0.01, n_iter = 10, verbose = 0)))\n",
    "\n",
    "        predictor = Pipeline(comb)\n",
    "        if rbm_layer > 1:\n",
    "            copy_tf_X_train = predictor.fit_transform(tf_X_train)\n",
    "        else:\n",
    "            copy_tf_X_train = tf_X_train.copy()\n",
    "\n",
    "        mcp_save = ModelCheckpoint(f\"{name}_Constant_Layer_{rbm_layer}.keras\", save_best_only = True, monitor = \"accuracy\", mode = \"max\")\n",
    "        current_model = tf.keras.models.clone_model(_clf)\n",
    "        current_model.compile(loss = \"categorical_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])\n",
    "        history = current_model.fit(copy_tf_X_train, tf_y_train, batch_size = BATCH_SIZE, epochs = TRAIN_EPOCHS, callbacks = [mcp_save])\n",
    "        y_pred = np.argmax(current_model.predict(tf_X_test), axis = 1)\n",
    "        accuracy = accuracy_score(y_test, y_pred) * 100\n",
    "        Results[name][\"CONSTANT\"][rbm_layer] = {}\n",
    "        Results[name][\"CONSTANT\"][rbm_layer][\"accuracy\"] = accuracy\n",
    "        Results[name][\"CONSTANT\"][rbm_layer][\"history\"] = history.history\n",
    "        print(f\"{name}\\tConstant\\tLayer: {rbm_layer}\\tAccuracy: {accuracy}\")\n",
    "        \n",
    "        # Increasing\n",
    "        comb = []\n",
    "        for j in range(0, rbm_layer):\n",
    "            comb.append((f\"mms{j}\", MinMaxScaler()))\n",
    "            comb.append((f\"rbm{j}\", BernoulliRBM(n_components = X_train.shape[1] * (j + 1), learning_rate = 0.01, n_iter = 10, verbose = 0)))\n",
    "\n",
    "        predictor = Pipeline(comb)\n",
    "\n",
    "        if rbm_layer > 1:\n",
    "            copy_tf_X_train = predictor.fit_transform(tf_X_train)\n",
    "        else:\n",
    "            copy_tf_X_train = tf_X_train.copy()\n",
    "\n",
    "        mcp_save = ModelCheckpoint(f\"{name}_Increasing_Layer_{rbm_layer}.keras\", save_best_only = True, monitor = \"accuracy\", mode = \"max\")\n",
    "        current_model = tf.keras.models.clone_model(_clf)\n",
    "        current_model.compile(loss = \"categorical_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])\n",
    "        history = current_model.fit(copy_tf_X_train, tf_y_train, batch_size = BATCH_SIZE, epochs = TRAIN_EPOCHS, callbacks = [mcp_save])\n",
    "        y_pred = np.argmax(current_model.predict(tf_X_test), axis = 1)\n",
    "        accuracy = accuracy_score(y_test, y_pred) * 100\n",
    "        Results[name][\"INCREASING\"][rbm_layer] = {} \n",
    "        Results[name][\"INCREASING\"][rbm_layer][\"accuracy\"] = accuracy\n",
    "        Results[name][\"INCREASING\"][rbm_layer][\"history\"] = history.history\n",
    "        print(f\"{name}\\tINCREASING\\tLayer: {rbm_layer}\\tAccuracy: {accuracy}\")\n",
    "\n",
    "        # Decreasing\n",
    "        comb = []\n",
    "        for j in range(0, rbm_layer):\n",
    "            comb.append((f\"mms{j}\", MinMaxScaler()))\n",
    "            comb.append((f\"rbm{j}\", BernoulliRBM(n_components = X_train.shape[1] * rbm_layer - j, learning_rate = 0.01, n_iter = 10, verbose = 0)))\n",
    "\n",
    "        predictor = Pipeline(comb)\n",
    "\n",
    "        if rbm_layer > 1:\n",
    "            copy_tf_X_train = predictor.fit_transform(tf_X_train)\n",
    "        else:\n",
    "            copy_tf_X_train = tf_X_train.copy()\n",
    "\n",
    "        mcp_save = ModelCheckpoint(f\"{name}_Decreasing_Layer_{rbm_layer}.keras\", save_best_only = True, monitor = \"accuracy\", mode = \"max\")\n",
    "        current_model = tf.keras.models.clone_model(_clf)\n",
    "        current_model.compile(loss = \"categorical_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])\n",
    "        history = current_model.fit(copy_tf_X_train, tf_y_train, batch_size = BATCH_SIZE, epochs = TRAIN_EPOCHS, callbacks = [mcp_save])\n",
    "        y_pred = np.argmax(current_model.predict(tf_X_test), axis = 1)\n",
    "        accuracy = accuracy_score(y_test, y_pred) * 100\n",
    "        Results[name][\"DECREASING\"][rbm_layer] = {} \n",
    "        Results[name][\"DECREASING\"][rbm_layer][\"accuracy\"] = accuracy\n",
    "        Results[name][\"DECREASING\"][rbm_layer][\"history\"] = history.history\n",
    "        print(f\"{name}\\tDECREASING\\tLayer: {rbm_layer}\\tAccuracy: {accuracy}\")\n",
    "\n",
    "with open(\"TensorflowAccuracySaves.pkl\", \"wb\") as f:\n",
    "    pickle.dump(Results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjUAAAGdCAYAAADqsoKGAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/H5lhTAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA4fUlEQVR4nO3df3RU9YH//9fk14QomaSZJkMwgIEK5YfQDSULW74rkpKwLZizrELlEyBLaeUr2jaCyreWNHj2pKxdTqjLipvll6cewR5r3Y/uwcUoVCyIJ5EV3TYrWSI/kwCaSQiQwMz9/gFz4zSZkJvMr4Tn45x7Dtz7vnfel+ucefn+cd82wzAMAQAADHAxka4AAABAMBBqAADAoECoAQAAgwKhBgAADAqEGgAAMCgQagAAwKBAqAEAAIMCoQYAAAwKcZGuQLh4vV6dOXNGQ4cOlc1mi3R1AABALxiGodbWVmVmZiompue2mFsm1Jw5c0ZZWVmRrgYAAOiDkydP6o477uixzC0TaoYOHSrp+j9KcnJyhGsDAAB6o6WlRVlZWebveE9umVDj63JKTk4m1AAAMMD0ZugIA4UBAMCgQKgBAACDAqEGAAAMCoQaAAAwKBBqAADAoECoAQAAgwKhBgAADAqEGgAAMCgQagAAwKBAqAEAAIMCoQYAAAwKhBoAADAo3DILWg5U51rbtfMP9WrruBbpqgAA0KPRX71d/+cvR0bs8wk1UW7nH+r1z+8ci3Q1AAC4qf/nrq8SahBYY8sVSdKM0Wn6xoiUyFYGAIAejEq7LaKfT6iJcs2Xr0qSvnt3ph7MHRHh2gAAEL0YKBzl3Jeuh5qUpPgI1wQAgOhGqIlyX1zqkCSlDCHUAADQE0JNlPN1PzloqQEAoEeEmihmGIbZ/ZSalBDh2gAAEN0INVHs8lWPOjxeSYypAQDgZgg1Uaz5RitNQmyMhsTHRrg2AABEN0JNFPOFGkdSvGw2W4RrAwBAdCPURLHmy8x8AgCgtwg1UYx31AAA0HuEmihmTucewswnAABuhlATxZppqQEAoNcINVGMMTUAAPQeoSaKMaYGAIDe61Oo2bx5s0aNGqXExETl5ubq8OHDvTpv165dstlsKiws9Nu/bNky2Ww2v62goMCvzPz58zVixAglJiZq2LBhKioq0pkzZ/pS/QHDt+6Tg7cJAwBwU5ZDze7du1VSUqLS0lLV1NRo8uTJys/PV1NTU4/n1dfXa/Xq1Zo5c2a3xwsKCnT27Flze+mll/yOz5o1Sy+//LJqa2v1yiuvqK6uTn/3d39ntfoDijmmhu4nAABuynKo2bhxo1asWKHi4mKNHz9eW7ZsUVJSkrZt2xbwHI/Ho8WLF6usrEzZ2dndlrHb7XK5XOaWmprqd/wnP/mJ/vIv/1IjR47UjBkz9OSTT+rQoUO6evWq1VsYMNyX6X4CAKC3LIWajo4OVVdXKy8vr/MCMTHKy8vTwYMHA563fv16paena/ny5QHL7Nu3T+np6Ro7dqxWrlypCxcuBCz7+eef68UXX9SMGTMUH9/9D357e7taWlr8toGmmcUsAQDoNUuh5vz58/J4PMrIyPDbn5GRoYaGhm7POXDggLZu3arKysqA1y0oKNALL7ygqqoqbdiwQfv379fcuXPl8Xj8yj3xxBO67bbblJaWphMnTui1114LeM3y8nI5HA5zy8rKsnCn0cE3+8lB9xMAADcV0tlPra2tKioqUmVlpZxOZ8ByixYt0vz58zVp0iQVFhbq9ddf1wcffKB9+/b5lVuzZo0+/PBD/ed//qdiY2O1ZMkSGYbR7TXXrl0rt9ttbidPngzmrYXclaseXbnKCt0AAPRWnJXCTqdTsbGxamxs9Nvf2Ngol8vVpXxdXZ3q6+s1b948c5/Xe/2HOi4uTrW1tRo9enSX87Kzs+V0OnXs2DHNnj3b7/OdTqfuuusuff3rX1dWVpYOHTqk6dOnd7mG3W6X3W63cntRxTeeJjbGptvtlh4TAAC3JEstNQkJCcrJyVFVVZW5z+v1qqqqqttgMW7cOB09elRHjhwxt/nz52vWrFk6cuRIwC6hU6dO6cKFCxo2bFjAuvjCUXt7u5VbGDC+PPOJFboBALg5y00AJSUlWrp0qaZOnapp06apoqJCbW1tKi4uliQtWbJEw4cPV3l5uRITEzVx4kS/81NSUiTJ3H/x4kWVlZVpwYIFcrlcqqur0+OPP64xY8YoPz9fkvT+++/rgw8+0Le+9S2lpqaqrq5OP/vZzzR69Ohuw9Rg0Gy+o4auJwAAesNyqFm4cKHOnTundevWqaGhQVOmTNGePXvMwcMnTpxQTEzvG4BiY2P10UcfaefOnWpublZmZqbmzJmjp59+2uw+SkpK0m9/+1uVlpaqra1Nw4YNU0FBgZ566qkB3cXUE99ilryjBgCA3rEZgUbaDjItLS1yOBxyu91KTk6OdHVu6uUPTurxVz7SvePStW3ZNyNdHQAAIsLK7zdrP0UpFrMEAMAaQk2U+uLGQGHG1AAA0DuEmijVOfuJtwkDANAbhJoo5fZ1P9FSAwBArxBqopTZUkOoAQCgVwg1Uaoz1ND9BABAbxBqopSb99QAAGAJoSZK+d4oTPcTAAC9Q6iJQh3XvGrr8Ehi9hMAAL1FqIlCvq4nm00amsgK3QAA9AahJgr5pnM7hsQrJoYVugEA6A1CTRTqfPEe42kAAOgtQk0UajaXSGA8DQAAvUWoiULNTOcGAMAyQk0UYjo3AADWEWqiEGNqAACwjlAThZp9s58YUwMAQK8RaqKQr6Umle4nAAB6jVAThcx1nwg1AAD0GqEmCnWOqaH7CQCA3iLURKHOMTW01AAA0FuEmijE7CcAAKwj1ESZax6vWq9ckySlMPsJAIBeI9REmZYbgUaSklmhGwCAXiPURBnf24SHJsYpLpbHAwBAb/GrGWWamc4NAECfEGqijLnuE9O5AQCwhFATZcyZT7TUAABgCaEmyvhCjYPp3AAAWEKoiTKMqQEAoG8INVHGfWNMTSrvqAEAwBJCTZTxtdTQ/QQAgDWEmijTOVCYlhoAAKwg1EQZc0wNLTUAAFjSp1CzefNmjRo1SomJicrNzdXhw4d7dd6uXbtks9lUWFjot3/ZsmWy2Wx+W0FBgXm8vr5ey5cv15133qkhQ4Zo9OjRKi0tVUdHR1+qH9V8Y2oYKAwAgDWWFxfavXu3SkpKtGXLFuXm5qqiokL5+fmqra1Venp6wPPq6+u1evVqzZw5s9vjBQUF2r59u/l3u91u/vlPf/qTvF6vnn/+eY0ZM0Yff/yxVqxYoba2Nv3yl7+0egtRjdlPAAD0jeWWmo0bN2rFihUqLi7W+PHjtWXLFiUlJWnbtm0Bz/F4PFq8eLHKysqUnZ3dbRm73S6Xy2Vuqamp5jFf4JkzZ46ys7M1f/58rV69Wr/97W+tVj+qeb2G3OZAYcbUAABghaVQ09HRoerqauXl5XVeICZGeXl5OnjwYMDz1q9fr/T0dC1fvjxgmX379ik9PV1jx47VypUrdeHChR7r4na79ZWvfCXg8fb2drW0tPht0a71yjUZxvU/M/sJAABrLIWa8+fPy+PxKCMjw29/RkaGGhoauj3nwIED2rp1qyorKwNet6CgQC+88IKqqqq0YcMG7d+/X3PnzpXH4+m2/LFjx/Tss8/qhz/8YcBrlpeXy+FwmFtWVlYv7jCymi9fH09zW0KsEuIYww0AgBWWx9RY0draqqKiIlVWVsrpdAYst2jRIvPPkyZN0t13363Ro0dr3759mj17tl/Z06dPq6CgQPfff79WrFgR8Jpr165VSUmJ+feWlpaoDzZfMJ0bAIA+sxRqnE6nYmNj1djY6Le/sbFRLperS/m6ujrV19dr3rx55j6v13v9g+PiVFtbq9GjR3c5Lzs7W06nU8eOHfMLNWfOnNGsWbM0Y8YM/eu//muPdbXb7X6DjQcC3wrddD0BAGCdpT6OhIQE5eTkqKqqytzn9XpVVVWl6dOndyk/btw4HT16VEeOHDG3+fPna9asWTpy5EjAlpNTp07pwoULGjZsmLnv9OnTuueee5STk6Pt27crJmbwdc+4mfkEAECfWe5+Kikp0dKlSzV16lRNmzZNFRUVamtrU3FxsSRpyZIlGj58uMrLy5WYmKiJEyf6nZ+SkiJJ5v6LFy+qrKxMCxYskMvlUl1dnR5//HGNGTNG+fn5kjoDzciRI/XLX/5S586dM6/XXQvRQOV7mzDrPgEAYJ3lULNw4UKdO3dO69atU0NDg6ZMmaI9e/aYg4dPnDhhqRUlNjZWH330kXbu3Knm5mZlZmZqzpw5evrpp83uo7179+rYsWM6duyY7rjjDr/zDd90oUHAF2octNQAAGCZzRhMqaAHLS0tcjgccrvdSk5OjnR1ulX2fz/R9vfq9f/eM1qPF4yLdHUAAIg4K7/fg29gygDmvsSYGgAA+opQE0U6F7NkTA0AAFYRaqKIOaWblhoAACwj1ESRzpYaQg0AAFYRaqKImzcKAwDQZ4SaKGEYRmdLDd1PAABYRqiJEq3t1+TxXp9dzzIJAABYR6iJEr6up8T4GCXGx0a4NgAADDyEmijhe5sw07kBAOgbQk2UaL58fTo342kAAOgbQk2UaOZtwgAA9AuhJkrwNmEAAPqHUBMl3JfofgIAoD8INVHC1/3EEgkAAPQNoSZK0P0EAED/EGqiBAOFAQDoH0JNlHD7pnTzNmEAAPqEUBMlGFMDAED/EGqixBe8URgAgH4h1EQBwzA6u59oqQEAoE8INVHgUodHVz3XV+gm1AAA0DeEmijgm86dEBujIazQDQBAnxBqokDzl94mbLPZIlwbAAAGJkJNFHDzjhoAAPqNUBMFeJswAAD9R6iJAryjBgCA/iPURIFm3iYMAEC/EWqiAGNqAADoP0JNFOhczJIxNQAA9BWhJgr4up8cdD8BANBnhJoo0Ez3EwAA/UaoiQLNLGYJAEC/EWqiQDOLWQIA0G+EmihgvqeGMTUAAPQZoSbCrlz1qP2aVxItNQAA9EefQs3mzZs1atQoJSYmKjc3V4cPH+7Vebt27ZLNZlNhYaHf/mXLlslms/ltBQUFfmX+4R/+QTNmzFBSUpJSUlL6Uu2o5GuliYux6XZ7XIRrAwDAwGU51OzevVslJSUqLS1VTU2NJk+erPz8fDU1NfV4Xn19vVavXq2ZM2d2e7ygoEBnz541t5deesnveEdHh+6//36tXLnSapWj2pfH07BCNwAAfWc51GzcuFErVqxQcXGxxo8fry1btigpKUnbtm0LeI7H49HixYtVVlam7OzsbsvY7Xa5XC5zS01N9TteVlamn/zkJ5o0aZLVKkc1xtMAABAclkJNR0eHqqurlZeX13mBmBjl5eXp4MGDAc9bv3690tPTtXz58oBl9u3bp/T0dI0dO1YrV67UhQsXrFSti/b2drW0tPht0Yi3CQMAEByWQs358+fl8XiUkZHhtz8jI0MNDQ3dnnPgwAFt3bpVlZWVAa9bUFCgF154QVVVVdqwYYP279+vuXPnyuPxWKmen/LycjkcDnPLysrq87VCyc1ilgAABEVIR6a2traqqKhIlZWVcjqdAcstWrTI/POkSZN09913a/To0dq3b59mz57dp89eu3atSkpKzL+3tLREZbAxu5+Y+QQAQL9YCjVOp1OxsbFqbGz029/Y2CiXy9WlfF1dnerr6zVv3jxzn9d7ffpyXFycamtrNXr06C7nZWdny+l06tixY30ONXa7XXa7vU/nhlPzZd4mDABAMFjqfkpISFBOTo6qqqrMfV6vV1VVVZo+fXqX8uPGjdPRo0d15MgRc5s/f75mzZqlI0eOBGw5OXXqlC5cuKBhw4ZZvJ2Bh3WfAAAIDsvdTyUlJVq6dKmmTp2qadOmqaKiQm1tbSouLpYkLVmyRMOHD1d5ebkSExM1ceJEv/N975jx7b948aLKysq0YMECuVwu1dXV6fHHH9eYMWOUn59vnnfixAl9/vnnOnHihDwej44cOSJJGjNmjG6//fa+3HtUaL7EEgkAAASD5VCzcOFCnTt3TuvWrVNDQ4OmTJmiPXv2mIOHT5w4oZiY3jcAxcbG6qOPPtLOnTvV3NyszMxMzZkzR08//bRf99G6deu0c+dO8+/f+MY3JEnvvPOO7rnnHqu3ETWY0g0AQHDYDMMwIl2JcGhpaZHD4ZDb7VZycnKkq2Oau+ld/fFsi3b+/TT99V1fjXR1AACIKlZ+v1n7KcLcl5jSDQBAMBBqIsyc/cSYGgAA+oVQE0Ht1zy61HH9BYO8URgAgP4h1ESQ+0YrTYxNGsoK3QAA9AuhJoLcX5r5FBPDCt0AAPQHoSaCOsfT0PUEAEB/EWoiiHfUAAAQPISaCOJtwgAABA+hJoLc5mKWhBoAAPqLUBNBX5gtNYypAQCgvwg1EcSYGgAAgodQE0G8TRgAgOAh1ESQ7z01hBoAAPqPUBNBzZd9i1kypgYAgP4i1ERQMy01AAAEDaEmgjq7n2ipAQCgvwg1EXLV41Vr+zVJvKcGAIBgINRESMuNmU+SlEyoAQCg3wg1EeKbzp2cGKdYVugGAKDfCDUR0sx4GgAAgopQEyHuyyxmCQBAMBFqIoQlEgAACC5CTYR8QfcTAABBRaiJELdvhW5aagAACApCTYSwmCUAAMFFqIkQxtQAABBchJoI6WypYUwNAADBQKiJEN+YmlS6nwAACApCTYQwpgYAgOAi1ERI55gaup8AAAgGQk0EeLyGWq7QUgMAQDARaiKg9cpVGcb1PzP7CQCA4CDURICv6+l2e5ziY3kEAAAEA7+oEeAbJEwrDQAAwdOnULN582aNGjVKiYmJys3N1eHDh3t13q5du2Sz2VRYWOi3f9myZbLZbH5bQUGBX5nPP/9cixcvVnJyslJSUrR8+XJdvHixL9WPuC8usUI3AADBZjnU7N69WyUlJSotLVVNTY0mT56s/Px8NTU19XhefX29Vq9erZkzZ3Z7vKCgQGfPnjW3l156ye/44sWL9cknn2jv3r16/fXX9fvf/14/+MEPrFY/KrgvMUgYAIBgsxxqNm7cqBUrVqi4uFjjx4/Xli1blJSUpG3btgU8x+PxaPHixSorK1N2dna3Zex2u1wul7mlpqaax/74xz9qz549+rd/+zfl5ubqW9/6lp599lnt2rVLZ86csXoLEddsLmbJdG4AAILFUqjp6OhQdXW18vLyOi8QE6O8vDwdPHgw4Hnr169Xenq6li9fHrDMvn37lJ6errFjx2rlypW6cOGCeezgwYNKSUnR1KlTzX15eXmKiYnR+++/3+312tvb1dLS4rdFC3NMDS01AAAEjaVQc/78eXk8HmVkZPjtz8jIUENDQ7fnHDhwQFu3blVlZWXA6xYUFOiFF15QVVWVNmzYoP3792vu3LnyeDySpIaGBqWnp/udExcXp6985SsBP7e8vFwOh8PcsrKyrNxqSPlmP6UwUBgAgKCJC+XFW1tbVVRUpMrKSjmdzoDlFi1aZP550qRJuvvuuzV69Gjt27dPs2fP7tNnr127ViUlJebfW1paoibYuG+01KSymCUAAEFjKdQ4nU7FxsaqsbHRb39jY6NcLleX8nV1daqvr9e8efPMfV6v9/oHx8WptrZWo0eP7nJedna2nE6njh07ptmzZ8vlcnUZiHzt2jV9/vnn3X6udH2Mjt1ut3J7YeMbU0P3EwAAwWOp+ykhIUE5OTmqqqoy93m9XlVVVWn69Oldyo8bN05Hjx7VkSNHzG3+/PmaNWuWjhw5ErDl5NSpU7pw4YKGDRsmSZo+fbqam5tVXV1tlnn77bfl9XqVm5tr5RaigrmYJd1PAAAEjeXup5KSEi1dulRTp07VtGnTVFFRoba2NhUXF0uSlixZouHDh6u8vFyJiYmaOHGi3/kpKSmSZO6/ePGiysrKtGDBArlcLtXV1enxxx/XmDFjlJ+fL0n6+te/roKCAq1YsUJbtmzR1atXtWrVKi1atEiZmZn9uf+I6JzSTfcTAADBYjnULFy4UOfOndO6devU0NCgKVOmaM+ePebg4RMnTigmpvcNQLGxsfroo4+0c+dONTc3KzMzU3PmzNHTTz/t13304osvatWqVZo9e7ZiYmK0YMEC/epXv7Ja/ahgttTQ/QQAQNDYDMO3tOLg1tLSIofDIbfbreTk5IjVw+s1NOan/yGvIR3+/2YrPTkxYnUBACDaWfn9Zu2nMLvYcU3eGzEymTE1AAAEDaEmzJrbrnc9DYmPVWJ8bIRrAwDA4EGoCbPmyyxmCQBAKBBqwsz3NmEHXU8AAAQVoSbMmPkEAEBoEGrCzM0K3QAAhAShJszMxSxpqQEAIKgINWHW2f1ESw0AAMFEqAkzWmoAAAgNQk2YuX1Tupn9BABAUBFqwoyWGgAAQoNQE2a+MTUOZj8BABBUhJowo6UGAIDQINSEkWEYnWNqCDUAAAQVoSaM2jo8uuq5vkQ3L98DACC4CDVh1HzjbcIJcTFKjOefHgCAYOKXNYzM8TRD4mWz2SJcGwAABhdCTRi5WcwSAICQIdSEUWdLDeNpAAAINkJNGDUz8wkAgJAh1IQR76gBACB0CDVh5GaFbgAAQoZQE0a+Kd0OFrMEACDoCDVhRPcTAAChQ6gJI99ilsx+AgAg+Ag1YeSmpQYAgJAh1ITRF4ypAQAgZAg1YWIYRmf3Ey01AAAEHaEmTK5c9arjmlcSU7oBAAgFQk2Y+N4mHBdj020JsRGuDQAAgw+hJky+PJ2bFboBAAg+Qk2Y+EINg4QBAAgNQk2YuG90P6UyngYAgJAg1IQJbxMGACC0CDVh4pvO7eBtwgAAhESfQs3mzZs1atQoJSYmKjc3V4cPH+7Vebt27ZLNZlNhYWHAMg899JBsNpsqKir89tfU1Ojb3/62UlJSlJaWph/84Ae6ePFiX6ofEbTUAAAQWpZDze7du1VSUqLS0lLV1NRo8uTJys/PV1NTU4/n1dfXa/Xq1Zo5c2bAMq+++qoOHTqkzMxMv/1nzpxRXl6exowZo/fff1979uzRJ598omXLllmtfsT4xtSkMFAYAICQsBxqNm7cqBUrVqi4uFjjx4/Xli1blJSUpG3btgU8x+PxaPHixSorK1N2dna3ZU6fPq1HHnlEL774ouLj/X/4X3/9dcXHx2vz5s0aO3asvvnNb2rLli165ZVXdOzYMau3EBG01AAAEFqWQk1HR4eqq6uVl5fXeYGYGOXl5engwYMBz1u/fr3S09O1fPnybo97vV4VFRVpzZo1mjBhQpfj7e3tSkhIUExMZ3WHDBkiSTpw4EC312xvb1dLS4vfFknmuk/MfgIAICQshZrz58/L4/EoIyPDb39GRoYaGhq6PefAgQPaunWrKisrA153w4YNiouL06OPPtrt8XvvvVcNDQ165pln1NHRoS+++EJPPvmkJOns2bPdnlNeXi6Hw2FuWVlZvbnFkDFbauh+AgAgJEI6+6m1tVVFRUWqrKyU0+nstkx1dbU2bdqkHTt2BHzT7oQJE7Rz50790z/9k5KSkuRyuXTnnXcqIyPDr/Xmy9auXSu3221uJ0+eDNp99YWbxSwBAAipOCuFnU6nYmNj1djY6Le/sbFRLperS/m6ujrV19dr3rx55j6v9/qijnFxcaqtrdW7776rpqYmjRgxwizj8Xj02GOPqaKiQvX19ZKkBx98UA8++KAaGxt12223yWazaePGjQHH6Njtdtntdiu3F1KdLTV0PwEAEAqWQk1CQoJycnJUVVVlTsv2er2qqqrSqlWrupQfN26cjh496rfvqaeeUmtrqzZt2qSsrCwVFRX5jdGRpPz8fBUVFam4uLjLNX1dX9u2bVNiYqK+/e1vW7mFiLhy1aPLVz2SJActNQAAhISlUCNJJSUlWrp0qaZOnapp06apoqJCbW1tZgBZsmSJhg8frvLyciUmJmrixIl+56ekpEiSuT8tLU1paWl+ZeLj4+VyuTR27Fhz3z//8z9rxowZuv3227V3716tWbNGv/jFL8zrRbOWG11PMTZpqN3yPzkAAOgFy7+wCxcu1Llz57Ru3To1NDRoypQp2rNnj9mCcuLEiYDjXPrj8OHDKi0t1cWLFzVu3Dg9//zzKioqCvrnhELn24TjFRPDCt0AAISCzTAMI9KVCIeWlhY5HA653W4lJyeH9bMPH/9cDzx/UNnO2/T26nvC+tkAAAxkVn6/WfspDJrNd9QwngYAgFAh1ISBr/uJd9QAABA6hJowcJtLJDCdGwCAUCHUhEHzjcUsHbTUAAAQMoSaMGAxSwAAQo9QEwas+wQAQOgRasLA1/3EmBoAAEKHUBMGvpYapnQDABA6hJowoPsJAIDQI9SEgfsyU7oBAAg1Qk2IXfV4dbH9miRaagAACCVCTYj5WmlsNimZUAMAQMgQakLMN54mOTFesazQDQBAyBBqQsxtTuemlQYAgFAi1IQYM58AAAgPQk2Idb6jhplPAACEEqEmxJov01IDAEA4EGpCrPkSY2oAAAgHQk2IMaYGAIDwINSEmK/7iTE1AACEFqEmxMzuJ1pqAAAIKUJNiHWu+0SoAQAglAg1IWaOqSHUAAAQUoSaEPN1PzmGMKYGAIBQItSEkMdrqOXK9RW6U2mpAQAgpAg1IdRyYzyNJDkYKAwAQEgRakLIN517qD1OcbH8UwMAEEr80oaQOZ6GricAAEKOUBNCzUznBgAgbAg1IdT54j1mPgEAEGqEmhDyvaOG7icAAEKPUBNCLGYJAED4EGpCiCUSAAAIH0JNCDGmBgCA8OlTqNm8ebNGjRqlxMRE5ebm6vDhw706b9euXbLZbCosLAxY5qGHHpLNZlNFRYXf/v/5n//RfffdJ6fTqeTkZH3rW9/SO++805fqh41v9hNjagAACD3LoWb37t0qKSlRaWmpampqNHnyZOXn56upqanH8+rr67V69WrNnDkzYJlXX31Vhw4dUmZmZpdj3/3ud3Xt2jW9/fbbqq6u1uTJk/Xd735XDQ0NVm8hbBhTAwBA+FgONRs3btSKFStUXFys8ePHa8uWLUpKStK2bdsCnuPxeLR48WKVlZUpOzu72zKnT5/WI488ohdffFHx8f4h4Pz58/r000/15JNP6u6779bXvvY1/eIXv9ClS5f08ccfW72FsPGNqUm9je4nAABCzVKo6ejoUHV1tfLy8jovEBOjvLw8HTx4MOB569evV3p6upYvX97tca/Xq6KiIq1Zs0YTJkzocjwtLU1jx47VCy+8oLa2Nl27dk3PP/+80tPTlZOT0+0129vb1dLS4reFW+eYGlpqAAAItTgrhc+fPy+Px6OMjAy//RkZGfrTn/7U7TkHDhzQ1q1bdeTIkYDX3bBhg+Li4vToo492e9xms+mtt95SYWGhhg4dqpiYGKWnp2vPnj1KTU3t9pzy8nKVlZX17sZCwOs1zJYaxtQAABB6IZ391NraqqKiIlVWVsrpdHZbprq6Wps2bdKOHTtks9m6LWMYhh5++GGlp6fr3Xff1eHDh1VYWKh58+bp7Nmz3Z6zdu1aud1uczt58mTQ7qs3WtuvyWtc/zMrdAMAEHqWWmqcTqdiY2PV2Njot7+xsVEul6tL+bq6OtXX12vevHnmPq/Xe/2D4+JUW1urd999V01NTRoxYoRZxuPx6LHHHlNFRYXq6+v19ttv6/XXX9cXX3yh5ORkSdK//Mu/aO/evdq5c6eefPLJLp9tt9tlt9ut3F5QuW8MEk5KiJU9LjZi9QAA4FZhKdQkJCQoJydHVVVV5rRsr9erqqoqrVq1qkv5cePG6ejRo377nnrqKbW2tmrTpk3KyspSUVGR3xgdScrPz1dRUZGKi4slSZcuXZJ0ffzOl8XExJghKdo0X2Y8DQAA4WQp1EhSSUmJli5dqqlTp2ratGmqqKhQW1ubGUCWLFmi4cOHq7y8XImJiZo4caLf+SkpKZJk7k9LS1NaWppfmfj4eLlcLo0dO1aSNH36dKWmpmrp0qVat26dhgwZosrKSh0/flzf+c53LN90OHxhrvvEzCcAAMLBcqhZuHChzp07p3Xr1qmhoUFTpkzRnj17zMHDJ06c6NKi0l9Op1N79uzRT3/6U9177726evWqJkyYoNdee02TJ08O6mcFCzOfAAAIL5thGEakKxEOLS0tcjgccrvd5ricUHrhYL3WvfaJ5k506bn/0/20cwAA0DMrv9+s/RQi5tuEmc4NAEBYEGpCxBdqHCxmCQBAWBBqQsSc/URLDQAAYUGoCRE3i1kCABBWhJoQab7sG1ND9xMAAOFAqAkRc0o33U8AAIQFoSZE3JeZ/QQAQDgRakLAMIzOKd3MfgIAICwINSHQ1uHRtRtLdNNSAwBAeBBqQuCLtuvjaexxMUqMZ4VuAADCgVATAoynAQAg/Ag1IcB4GgAAwo9QEwK+twk7aKkBACBsCDUh0MzbhAEACDtCTQgwpgYAgPAj1IRA59uEGVMDAEC4EGpCwOx+oqUGAICwIdSEgLmYJbOfAAAIG0JNCLhpqQEAIOwINSHgm9LN7CcAAMKHUBMCvjE1vKcGAIDwIdQEmd8K3cx+AgAgbAg1QXb5qkcdHq8kup8AAAgnQk2Q+Vpp4mNtSkpghW4AAMKFUBNk5niaIQmy2WwRrg0AALcOQk2QmTOfGCQMAEBYEWqCzM1ilgAARAShJsiaWcwSAICIINQE2ZfH1AAAgPAh1ASZb0xNKi01AACEFaEmyFj3CQCAyCDUBFnnEgl0PwEAEE6EmiBjMUsAACKDUBNkzXQ/AQAQEYSaIDNDDbOfAAAIqz6Fms2bN2vUqFFKTExUbm6uDh8+3Kvzdu3aJZvNpsLCwoBlHnroIdlsNlVUVJj79u3bJ5vN1u32wQcf9OUWQoY3CgMAEBmWQ83u3btVUlKi0tJS1dTUaPLkycrPz1dTU1OP59XX12v16tWaOXNmwDKvvvqqDh06pMzMTL/9M2bM0NmzZ/2273//+7rzzjs1depUq7cQMleuenTl6vUVuh2EGgAAwspyqNm4caNWrFih4uJijR8/Xlu2bFFSUpK2bdsW8ByPx6PFixerrKxM2dnZ3ZY5ffq0HnnkEb344ouKj/cPBAkJCXK5XOaWlpam1157TcXFxVG1aKT7xtuEY2NsGmqPi3BtAAC4tVgKNR0dHaqurlZeXl7nBWJilJeXp4MHDwY8b/369UpPT9fy5cu7Pe71elVUVKQ1a9ZowoQJN63Hv//7v+vChQsqLi4OWKa9vV0tLS1+W6h1vk04PqrCFgAAtwJLoeb8+fPyeDzKyMjw25+RkaGGhoZuzzlw4IC2bt2qysrKgNfdsGGD4uLi9Oijj/aqHlu3blV+fr7uuOOOgGXKy8vlcDjMLSsrq1fX7o/mS0znBgAgUkI6+6m1tVVFRUWqrKyU0+nstkx1dbU2bdqkHTt29Kp149SpU3rzzTcDtvr4rF27Vm6329xOnjzZp3uwwreYJeNpAAAIP0sDP5xOp2JjY9XY2Oi3v7GxUS6Xq0v5uro61dfXa968eeY+r/f6QNq4uDjV1tbq3XffVVNTk0aMGGGW8Xg8euyxx1RRUaH6+nq/a27fvl1paWmaP39+j3W12+2y2+1Wbq/fzCUSaKkBACDsLIWahIQE5eTkqKqqypyW7fV6VVVVpVWrVnUpP27cOB09etRv31NPPaXW1lZt2rRJWVlZKioq8hujI0n5+fkqKirqMmbGMAxt375dS5Ys6TKYOBp0LmbJO2oAAAg3y1N0SkpKtHTpUk2dOlXTpk1TRUWF2trazACyZMkSDR8+XOXl5UpMTNTEiRP9zk9JSZEkc39aWprS0tL8ysTHx8vlcmns2LF++99++20dP35c3//+961WOyw6132KvsAFAMBgZznULFy4UOfOndO6devU0NCgKVOmaM+ePebg4RMnTigmJjRDdbZu3aoZM2Zo3LhxIbl+f/nG1PA2YQAAws9mGIYR6UqEQ0tLixwOh9xut5KTk0PyGQ+/WKM3jp5V2fwJWjpjVEg+AwCAW4mV32/WfgqiLy6xRAIAAJFCqAmiL798DwAAhBehJoh8yySkMPsJAICwI9QEEW8UBgAgcgg1QdJxzau2Do8kxtQAABAJhJog8XU92WzS0ERCDQAA4UaoCRL3jbcJJyfGKzaGFboBAAg3Qk2Q+GY+0fUEAEBkEGqCpDPUMPMJAIBIINQESecSCbTUAAAQCYSaIGnmbcIAAEQUoSZI3LTUAAAQUYSaIPGt++RgTA0AABFBqAkSc6AwLTUAAEQEoSZIOtd9ItQAABAJhJog4T01AABEFqEmSJpvvFHYMYQxNQAARAKhJkhoqQEAILIINUFwzeNV65VrkhgoDABApBBqgqDlRqCRJAehBgCAiCDUBIHvbcJD7XGKi+WfFACASOAXOAjMdZ9uo5UGAIBIIdQEgdt88R4znwAAiBRCTRD4pnMz8wkAgMgh1ASBbzo3g4QBAIgcQk0QfME7agAAiDhCTRC4b8x+YkwNAACRQ6gJgmYWswQAIOIINUHAmBoAACKPUBMEnS01dD8BABAphJogMMfU0P0EAEDEEGqCwGypofsJAICIIdT0k9dryH0j1DhoqQEAIGIINf3UeuWaDOP6n5nSDQBA5PQp1GzevFmjRo1SYmKicnNzdfjw4V6dt2vXLtlsNhUWFgYs89BDD8lms6mioqLLsTfeeEO5ubkaMmSIUlNTe7xOuPiWSLgtIVYJcWREAAAixfKv8O7du1VSUqLS0lLV1NRo8uTJys/PV1NTU4/n1dfXa/Xq1Zo5c2bAMq+++qoOHTqkzMzMLsdeeeUVFRUVqbi4WP/1X/+l9957Tw8++KDV6gdd8yVmPgEAEA0sh5qNGzdqxYoVKi4u1vjx47VlyxYlJSVp27ZtAc/xeDxavHixysrKlJ2d3W2Z06dP65FHHtGLL76o+Hj/sSnXrl3Tj370Iz3zzDN66KGHdNddd2n8+PF64IEHrFY/6HyDhHlHDQAAkWUp1HR0dKi6ulp5eXmdF4iJUV5eng4ePBjwvPXr1ys9PV3Lly/v9rjX61VRUZHWrFmjCRMmdDleU1Oj06dPKyYmRt/4xjc0bNgwzZ07Vx9//HHAz2xvb1dLS4vfFgp3pA7Ro7O/pgem3hGS6wMAgN6xFGrOnz8vj8ejjIwMv/0ZGRlqaGjo9pwDBw5o69atqqysDHjdDRs2KC4uTo8++mi3x//3f/9XkvTzn/9cTz31lF5//XWlpqbqnnvu0eeff97tOeXl5XI4HOaWlZXVm1u0bPRXb1fJt+/Ssr+6MyTXBwAAvRPSka2tra0qKipSZWWlnE5nt2Wqq6u1adMm7dixQzabrdsyXq9XkvTTn/5UCxYsUE5OjrZv3y6bzabf/OY33Z6zdu1aud1uczt58mRwbgoAAESlOCuFnU6nYmNj1djY6Le/sbFRLperS/m6ujrV19dr3rx55j5fQImLi1Ntba3effddNTU1acSIEWYZj8ejxx57TBUVFaqvr9ewYcMkSePHjzfL2O12ZWdn68SJE93W1W63y263W7k9AAAwgFlqqUlISFBOTo6qqqrMfV6vV1VVVZo+fXqX8uPGjdPRo0d15MgRc5s/f75mzZqlI0eOKCsrS0VFRfroo4/8ymRmZmrNmjV68803JUk5OTmy2+2qra01r3316lXV19dr5MiRfb13AAAwiFhqqZGkkpISLV26VFOnTtW0adNUUVGhtrY2FRcXS5KWLFmi4cOHq7y8XImJiZo4caLf+SkpKZJk7k9LS1NaWppfmfj4eLlcLo0dO1aSlJycrIceekilpaXKysrSyJEj9cwzz0iS7r//fqu3AAAABiHLoWbhwoU6d+6c1q1bp4aGBk2ZMkV79uwxBw+fOHFCMTHBH6rzzDPPKC4uTkVFRbp8+bJyc3P19ttvKzU1NeifBQAABh6bYfhe8j+4tbS0yOFwyO12Kzk5OdLVAQAAvWDl95v3+gMAgEGBUAMAAAYFQg0AABgUCDUAAGBQINQAAIBBgVADAAAGBUINAAAYFCy/fG+g8r2Op6WlJcI1AQAAveX73e7Na/VumVDT2toqScrKyopwTQAAgFWtra1yOBw9lrll3ijs9Xp15swZDR06VDabLajXbmlpUVZWlk6ePDno31bMvQ5et9L9cq+D1610v7fKvRqGodbWVmVmZt50GaZbpqUmJiZGd9xxR0g/Izk5eVD/h/Vl3OvgdSvdL/c6eN1K93sr3OvNWmh8GCgMAAAGBUINAAAYFAg1QWC321VaWiq73R7pqoQc9zp43Ur3y70OXrfS/d5K99pbt8xAYQAAMLjRUgMAAAYFQg0AABgUCDUAAGBQINQAAIBBgVDTS5s3b9aoUaOUmJio3NxcHT58uMfyv/nNbzRu3DglJiZq0qRJ+o//+I8w1bTvysvL9c1vflNDhw5Venq6CgsLVVtb2+M5O3bskM1m89sSExPDVOP++fnPf96l7uPGjevxnIH4XCVp1KhRXe7VZrPp4Ycf7rb8QHquv//97zVv3jxlZmbKZrPpd7/7nd9xwzC0bt06DRs2TEOGDFFeXp4+/fTTm17X6nc+XHq636tXr+qJJ57QpEmTdNtttykzM1NLlizRmTNnerxmX74L4XCzZ7ts2bIu9S4oKLjpdaPx2d7sXrv7/tpsNj3zzDMBrxmtzzWUCDW9sHv3bpWUlKi0tFQ1NTWaPHmy8vPz1dTU1G35P/zhD/re976n5cuX68MPP1RhYaEKCwv18ccfh7nm1uzfv18PP/ywDh06pL179+rq1auaM2eO2traejwvOTlZZ8+eNbfPPvssTDXuvwkTJvjV/cCBAwHLDtTnKkkffPCB333u3btXknT//fcHPGegPNe2tjZNnjxZmzdv7vb4P/7jP+pXv/qVtmzZovfff1+33Xab8vPzdeXKlYDXtPqdD6ee7vfSpUuqqanRz372M9XU1Oi3v/2tamtrNX/+/Jte18p3IVxu9mwlqaCgwK/eL730Uo/XjNZne7N7/fI9nj17Vtu2bZPNZtOCBQt6vG40PteQMnBT06ZNMx5++GHz7x6Px8jMzDTKy8u7Lf/AAw8Y3/nOd/z25ebmGj/84Q9DWs9ga2pqMiQZ+/fvD1hm+/bthsPhCF+lgqi0tNSYPHlyr8sPludqGIbxox/9yBg9erTh9Xq7PT5Qn6sk49VXXzX/7vV6DZfLZTzzzDPmvubmZsNutxsvvfRSwOtY/c5Hyp/fb3cOHz5sSDI+++yzgGWsfhciobt7Xbp0qXHfffdZus5AeLa9ea733Xefce+99/ZYZiA812CjpeYmOjo6VF1drby8PHNfTEyM8vLydPDgwW7POXjwoF95ScrPzw9YPlq53W5J0le+8pUey128eFEjR45UVlaW7rvvPn3yySfhqF5QfPrpp8rMzFR2drYWL16sEydOBCw7WJ5rR0eHfv3rX+vv//7ve1zcdSA/V5/jx4+roaHB77k5HA7l5uYGfG59+c5HM7fbLZvNppSUlB7LWfkuRJN9+/YpPT1dY8eO1cqVK3XhwoWAZQfLs21sbNQbb7yh5cuX37TsQH2ufUWouYnz58/L4/EoIyPDb39GRoYaGhq6PaehocFS+Wjk9Xr14x//WH/1V3+liRMnBiw3duxYbdu2Ta+99pp+/etfy+v1asaMGTp16lQYa9s3ubm52rFjh/bs2aPnnntOx48f18yZM9Xa2tpt+cHwXCXpd7/7nZqbm7Vs2bKAZQbyc/0y37Ox8tz68p2PVleuXNETTzyh733vez0ueGj1uxAtCgoK9MILL6iqqkobNmzQ/v37NXfuXHk8nm7LD5Znu3PnTg0dOlR/+7d/22O5gfpc++OWWaUb1jz88MP6+OOPb9r/On36dE2fPt38+4wZM/T1r39dzz//vJ5++ulQV7Nf5s6da/757rvvVm5urkaOHKmXX365V/8HNFBt3bpVc+fOVWZmZsAyA/m54rqrV6/qgQcekGEYeu6553osO1C/C4sWLTL/PGnSJN19990aPXq09u3bp9mzZ0ewZqG1bds2LV68+KaD9wfqc+0PWmpuwul0KjY2Vo2NjX77Gxsb5XK5uj3H5XJZKh9tVq1apddff13vvPOO7rjjDkvnxsfH6xvf+IaOHTsWotqFTkpKiu66666AdR/oz1WSPvvsM7311lv6/ve/b+m8gfpcfc/GynPry3c+2vgCzWeffaa9e/f22ErTnZt9F6JVdna2nE5nwHoPhmf77rvvqra21vJ3WBq4z9UKQs1NJCQkKCcnR1VVVeY+r9erqqoqv/+T/bLp06f7lZekvXv3BiwfLQzD0KpVq/Tqq6/q7bff1p133mn5Gh6PR0ePHtWwYcNCUMPQunjxourq6gLWfaA+1y/bvn270tPT9Z3vfMfSeQP1ud55551yuVx+z62lpUXvv/9+wOfWl+98NPEFmk8//VRvvfWW0tLSLF/jZt+FaHXq1ClduHAhYL0H+rOVrre05uTkaPLkyZbPHajP1ZJIj1QeCHbt2mXY7XZjx44dxn//938bP/jBD4yUlBSjoaHBMAzDKCoqMp588kmz/HvvvWfExcUZv/zlL40//vGPRmlpqREfH28cPXo0UrfQKytXrjQcDoexb98+4+zZs+Z26dIls8yf32tZWZnx5ptvGnV1dUZ1dbWxaNEiIzEx0fjkk08icQuWPPbYY8a+ffuM48ePG++9956Rl5dnOJ1Oo6mpyTCMwfNcfTwejzFixAjjiSee6HJsID/X1tZW48MPPzQ+/PBDQ5KxceNG48MPPzRn+/ziF78wUlJSjNdee8346KOPjPvuu8+48847jcuXL5vXuPfee41nn33W/PvNvvOR1NP9dnR0GPPnzzfuuOMO48iRI37f4/b2dvMaf36/N/suREpP99ra2mqsXr3aOHjwoHH8+HHjrbfeMv7iL/7C+NrXvmZcuXLFvMZAebY3++/YMAzD7XYbSUlJxnPPPdftNQbKcw0lQk0vPfvss8aIESOMhIQEY9q0acahQ4fMY3/9139tLF261K/8yy+/bNx1111GQkKCMWHCBOONN94Ic42tk9Tttn37drPMn9/rj3/8Y/PfJSMjw/ibv/kbo6amJvyV74OFCxcaw4YNMxISEozhw4cbCxcuNI4dO2YeHyzP1efNN980JBm1tbVdjg3k5/rOO+90+9+t7368Xq/xs5/9zMjIyDDsdrsxe/bsLv8GI0eONEpLS/329fSdj6Se7vf48eMBv8fvvPOOeY0/v9+bfRcipad7vXTpkjFnzhzjq1/9qhEfH2+MHDnSWLFiRZdwMlCe7c3+OzYMw3j++eeNIUOGGM3Nzd1eY6A811CyGYZhhLQpCAAAIAwYUwMAAAYFQg0AABgUCDUAAGBQINQAAIBBgVADAAAGBUINAAAYFAg1AABgUCDUAACAQYFQAwAABgVCDQAAGBQINQAAYFAg1AAAgEHh/we+6iZi+otpQwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history[\"accuracy\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m230/230\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.45601851851851855"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = LSTMClassif.predict(X_test)\n",
    "y_pred = np.argmax(y_pred, axis = 1)\n",
    "accuracy_score(y_pred, y_test)\n",
    "# .45 - Correct RBM Size, 10 Iter\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m918/918\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - accuracy: 0.4580 - loss: 1.1095\n",
      "Epoch 2/100\n",
      "\u001b[1m918/918\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.5038 - loss: 1.0420\n",
      "Epoch 3/100\n",
      "\u001b[1m918/918\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.6517 - loss: 0.8817\n",
      "Epoch 4/100\n",
      "\u001b[1m688/918\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.8010 - loss: 0.5502"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mLSTMClassif\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# LSTMPipe.fit(X_train, y_train)\u001b[39;00m\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/scikeras/wrappers.py:1501\u001b[0m, in \u001b[0;36mKerasClassifier.fit\u001b[0;34m(self, X, y, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m     sample_weight \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m sample_weight\n\u001b[1;32m   1500\u001b[0m     sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(class_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_weight, y\u001b[38;5;241m=\u001b[39my)\n\u001b[0;32m-> 1501\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/scikeras/wrappers.py:770\u001b[0m, in \u001b[0;36mBaseWrapper.fit\u001b[0;34m(self, X, y, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m    765\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m    766\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit__epochs\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepochs)\n\u001b[1;32m    767\u001b[0m )\n\u001b[1;32m    768\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minitial_epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minitial_epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m--> 770\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    771\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    772\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    773\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    774\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwarm_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwarm_start\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    775\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    776\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    778\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/scikeras/wrappers.py:938\u001b[0m, in \u001b[0;36mBaseWrapper._fit\u001b[0;34m(self, X, y, sample_weight, warm_start, epochs, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    934\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_encoder_\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[1;32m    936\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_model_compatibility(y)\n\u001b[0;32m--> 938\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_keras_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    939\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    940\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    941\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    942\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwarm_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwarm_start\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/scikeras/wrappers.py:535\u001b[0m, in \u001b[0;36mBaseWrapper._fit_keras_model\u001b[0;34m(self, X, y, sample_weight, warm_start, epochs, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    533\u001b[0m         hist \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_\u001b[38;5;241m.\u001b[39mfit(x\u001b[38;5;241m=\u001b[39mX, y\u001b[38;5;241m=\u001b[39my, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_args)\n\u001b[1;32m    534\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 535\u001b[0m     hist \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m warm_start \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhistory_\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m initial_epoch \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhistory_ \u001b[38;5;241m=\u001b[39m defaultdict(\u001b[38;5;28mlist\u001b[39m)\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:314\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[1;32m    313\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 314\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    315\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[1;32m    316\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1500\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1498\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1500\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1501\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1503\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1504\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1505\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1506\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1508\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1509\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1510\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1514\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1515\u001b[0m   )\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "LSTMClassif.fit(X_train, y_train)\n",
    "# LSTMPipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m230/230\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 37ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "50.422113289760354"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y_pred = LSTMPipe.predict(X_test)\n",
    "y_pred = LSTMClassif.predict(X_test)\n",
    "accuracy_score(y_test, y_pred) * 100\n",
    "# LSTM Only = 89%\n",
    "# LSTM (10 epochs) + 1 RBM = 50.42"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
